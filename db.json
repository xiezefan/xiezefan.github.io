{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"source/Dockerfile","path":"Dockerfile","modified":0,"renderable":0},{"_id":"themes/yilia/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/yilia/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":0,"renderable":1},{"_id":"themes/yilia/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/yilia/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/yilia/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/yilia/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/coderwall.png","path":"img/coderwall.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/delicious.png","path":"img/delicious.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/facebook.png","path":"img/facebook.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/github.png","path":"img/github.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/google.png","path":"img/google.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/img-err.png","path":"img/img-err.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/img-loading.png","path":"img/img-loading.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/linkedin.png","path":"img/linkedin.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/pinboard.png","path":"img/pinboard.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/pinterest.png","path":"img/pinterest.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/rss.png","path":"img/rss.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/stackoverflow.png","path":"img/stackoverflow.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/twitter.png","path":"img/twitter.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/weibo.png","path":"img/weibo.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/js/instagram.js","path":"js/instagram.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/js/jquery.lazyload.js","path":"js/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/yilia/source/css/fonts/fontawesome-webfont.svgz","path":"css/fonts/fontawesome-webfont.svgz","modified":0,"renderable":1},{"_id":"themes/yilia/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/yilia/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/yilia/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/yilia/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/yilia/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"2c0f6791f654ed73c45d44fc21542dc78d70ddf4","modified":1539280070621},{"_id":"source/Dockerfile","hash":"275276f91447fd5140271f31fe8bcfeb8cfe2acf","modified":1539280070622},{"_id":"themes/yilia/README.md","hash":"ff1e89ec8f4bbfc1d4cd6d02cfd8588e737a3fd2","modified":1539280070628},{"_id":"themes/yilia/_config.yml","hash":"8e42061757c3c95a46f071ab0aaba124dc3213f2","modified":1551011775086},{"_id":"themes/yilia/package.json","hash":"99e419b9d09ef18345ad4fa0e46767a68f53ab46","modified":1539280070633},{"_id":"source/_posts/HashMap-HashTable-diff.md","hash":"cac276390f8ff79459f29c6ddce57bb1da60b236","modified":1539280070622},{"_id":"source/_posts/String-StringBuffer-StringBuilder-diff.md","hash":"92746a7dda8245945292b4c4541ec357a612f36c","modified":1539280070622},{"_id":"source/_posts/agenda-start.md","hash":"1b39978eb23756db433ea4d5c1de6a0928f830a3","modified":1539280070622},{"_id":"source/_posts/android-annotations-start.md","hash":"d8ff93c665399ff05e966cefd765fa4aa574d6ff","modified":1539280070624},{"_id":"source/_posts/elk_in_action_analyze_nginx_logs.md","hash":"9c9be67ccdf146aef317b0f954e5bc9e69768737","modified":1539310197708},{"_id":"source/_posts/elk_in_action_grok_start.md","hash":"eb2bbee0b157270bf3bf884b060dc04fe5e1d98c","modified":1539280070624},{"_id":"source/_posts/final-finally-finalize-diff.md","hash":"0ede9e6101c04b82e335d160e216c33184ca90db","modified":1539280070624},{"_id":"source/_posts/finally-lose.md","hash":"8e4c33929065478f3342f6f6a28e7c06ed89b773","modified":1539280070624},{"_id":"source/_posts/java-constructor-base.md","hash":"d3222833dae3df04904200d54199b5a718b4e523","modified":1539280070625},{"_id":"source/_posts/linux-install-sdk-and-maven.md","hash":"3391538f58f630d932dcdf43205e8119544f9640","modified":1539280070625},{"_id":"source/_posts/maven-start.md","hash":"79e454980447ce17f5baea8b01b3e7db3520a715","modified":1539280070625},{"_id":"source/_posts/maven_module_with_git_sub_module.md","hash":"78e52f0073ef4d5b14e0cfb3e347a94e6aaac9a1","modified":1539280070625},{"_id":"source/_posts/mqtt-start.md","hash":"113fc380304abb203ffba3ef193559e0ae4f96a1","modified":1539280070625},{"_id":"source/_posts/nginx-502-bug-trace.md","hash":"a601e05a977618d78a2077a3ff73a7f67af52f07","modified":1539310193869},{"_id":"source/_posts/mysql-utf8mb4.md","hash":"e8a415ff6fbc90300375f8200e65f4301207a2f8","modified":1539280070625},{"_id":"source/_posts/pubu_im_start.md","hash":"234c3a688a4f244c014190faf9c825ecb926b891","modified":1539310194508},{"_id":"source/_posts/redis_cluster_research_1.md","hash":"578390eea46b0c076848512e6049f791264c9ded","modified":1539280070626},{"_id":"source/_posts/redis_cluster_research_2.md","hash":"3653932cbeaff70836dace393f6779c09a4fab58","modified":1539310195310},{"_id":"source/_posts/spring-test-start.md","hash":"2395a6950d6c4ef60de0fd0b374385a109c6c611","modified":1539280070627},{"_id":"source/_posts/sleep-wait-diff.md","hash":"19a68277e7a3d85c3ff4642e49989f564d75d638","modified":1539280070626},{"_id":"source/_posts/tip-linux-common-command.md","hash":"65cc96fd57febaaca9a380fc77506341184b6fc1","modified":1539280070627},{"_id":"source/_posts/redis_in_action_ziplist.md","hash":"06dde430355082e08641531b32a22907a1696811","modified":1539310196027},{"_id":"source/_posts/tip-sublime-text-ubuntu.md","hash":"e3bef2834cebac4fe32d3590f2bbb3226cefe1f7","modified":1539310197028},{"_id":"source/_posts/tip-git.md","hash":"d25b4128cfd0195647b4ff21e020f9c627916a44","modified":1539280070627},{"_id":"themes/yilia/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1539280070631},{"_id":"themes/yilia/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1539280070632},{"_id":"themes/yilia/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1539280070632},{"_id":"themes/yilia/layout/layout.ejs","hash":"3bc1bba131445a07be002f490c70cd242bf8efce","modified":1539280070632},{"_id":"themes/yilia/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1539280070632},{"_id":"themes/yilia/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1539280070632},{"_id":"themes/yilia/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1539280070632},{"_id":"themes/yilia/scripts/fancybox.js","hash":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1539280070633},{"_id":"themes/yilia/layout/_partial/after-footer.ejs","hash":"aa0e9b5aeb97bd7424b28145be1e46f189f033c1","modified":1539280070628},{"_id":"themes/yilia/layout/_partial/archive-post.ejs","hash":"a27cc79336c2cf5402ae2aa01ee3a5126fb41924","modified":1539280070628},{"_id":"themes/yilia/layout/_partial/archive.ejs","hash":"d7de6421497ffaf65e4f5fe4bed71fcea51fde80","modified":1539280070628},{"_id":"themes/yilia/layout/_partial/article.ejs","hash":"06bfe6b4c1ee5c32b1019e1255acc501f74c99d6","modified":1539280070629},{"_id":"themes/yilia/layout/_partial/footer.ejs","hash":"9c100195784056b1e88acfcd9dd7d7e34a03c7ea","modified":1551011817680},{"_id":"themes/yilia/layout/_partial/head.ejs","hash":"9906b19ee6cddb0045b1129abe4b43936a3bdef6","modified":1539280070629},{"_id":"themes/yilia/layout/_partial/header.ejs","hash":"6387a93dad7c3d778eb91e3821852fbf6813880c","modified":1539280070629},{"_id":"themes/yilia/layout/_partial/left-col.ejs","hash":"c44354f5c2000cbdc37a7a9bdbacf3646f1da225","modified":1539280070629},{"_id":"themes/yilia/layout/_partial/mobile-nav.ejs","hash":"4fa71db4df6d5c076004c66777edd71c24aba647","modified":1539280070630},{"_id":"themes/yilia/source/css/_extend.styl","hash":"222fbe6d222531d61c1ef0f868c90f747b1c2ced","modified":1539280070633},{"_id":"themes/yilia/source/css/_variables.styl","hash":"5e37a6571caf87149af83ac1cc0cdef99f117350","modified":1539280070636},{"_id":"themes/yilia/source/css/style.styl","hash":"5012d8d66a4448fe373f078c0eadc0e42559f668","modified":1539280070639},{"_id":"themes/yilia/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1539280070639},{"_id":"themes/yilia/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1539280070639},{"_id":"themes/yilia/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1539280070639},{"_id":"themes/yilia/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1539280070640},{"_id":"themes/yilia/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1539280070640},{"_id":"themes/yilia/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1539280070640},{"_id":"themes/yilia/source/fancybox/jquery.fancybox.css","hash":"fea04e517da359d3f99fe1a72f1c9725638a797e","modified":1539280070641},{"_id":"themes/yilia/source/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1539280070642},{"_id":"themes/yilia/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1539280070642},{"_id":"themes/yilia/source/img/coderwall.png","hash":"fa84676c4d654e040e51fd34bfcd9f9348cd5331","modified":1539280070642},{"_id":"themes/yilia/source/img/delicious.png","hash":"9553a5f5189e4a953e04a58a49dbfa74b86b73dd","modified":1539280070642},{"_id":"themes/yilia/source/img/facebook.png","hash":"d19ad7a0903daf26817afd8753cd97e0cc714f54","modified":1539280070643},{"_id":"themes/yilia/source/img/github.png","hash":"b84d03b32fa388dcbf149296ebd16dce6223d48d","modified":1539280070643},{"_id":"themes/yilia/source/img/google.png","hash":"61a21fec7346fa3400b747ac9a201cf3d5bc013d","modified":1539280070643},{"_id":"themes/yilia/source/img/img-err.png","hash":"23a63ea26eb3c1d5e677d9883cf36cc1a1a1228b","modified":1539280070643},{"_id":"themes/yilia/source/img/img-loading.png","hash":"a9cd5cd11866824f31e3d1c5e23badfeb3f73031","modified":1539280070643},{"_id":"themes/yilia/source/img/linkedin.png","hash":"e203138fb53c257cb214e97f4e30091b9c568d2c","modified":1539280070643},{"_id":"themes/yilia/source/img/pinboard.png","hash":"0891fbb6d092fa012bf936019923383d84c6aeb0","modified":1539280070643},{"_id":"themes/yilia/source/img/pinterest.png","hash":"9c72917f8779c083157c6ce7a5d62ed4874f0630","modified":1539280070644},{"_id":"themes/yilia/source/img/rss.png","hash":"430fd47340e75214c081abd05cd7410cf7c71b86","modified":1539280070644},{"_id":"themes/yilia/source/img/stackoverflow.png","hash":"da5dfe9043055c95e479d49c78cd3b020de608f2","modified":1539280070644},{"_id":"themes/yilia/source/img/twitter.png","hash":"14dbb8e62d056525253bc0de13acd1723da7a934","modified":1539280070644},{"_id":"themes/yilia/source/img/weibo.png","hash":"280dae3fd38086158b4a1b57edb94c06b1a5014b","modified":1539280070644},{"_id":"themes/yilia/source/js/instagram.js","hash":"9c3fa2f07724b20f6f2b05bc4f2d01ea0633001d","modified":1539280070645},{"_id":"themes/yilia/source/js/jquery.lazyload.js","hash":"c11a2e7b330d16d06feabd0a8477099adf9d6799","modified":1539280070645},{"_id":"themes/yilia/source/js/main.js","hash":"dd10c8763d80b593608c513cf2104cab70758770","modified":1539280070645},{"_id":"themes/yilia/source/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1539280070645},{"_id":"themes/yilia/layout/_partial/post/category.ejs","hash":"4fe41872f010c32fe34da0fa176398712baa03a2","modified":1539280070630},{"_id":"themes/yilia/layout/_partial/post/date.ejs","hash":"c0c988334e857a77ba455a056dfa21809e7e76a5","modified":1539280070630},{"_id":"themes/yilia/layout/_partial/post/duoshuo.ejs","hash":"e8399025ed3b980aedb821c92855889f5f12fd5b","modified":1539280070630},{"_id":"themes/yilia/layout/_partial/post/livere.ejs","hash":"b3148e3852f509223db46a3aa875f461166d516a","modified":1539280070631},{"_id":"themes/yilia/layout/_partial/post/nav.ejs","hash":"d19dee2082528e1844bed3aa4e4bd59f15fd7a7a","modified":1539280070631},{"_id":"themes/yilia/layout/_partial/post/share.ejs","hash":"da39b4ba0c0ce4e1932fd45c5aee10e8aca41f28","modified":1539280070631},{"_id":"themes/yilia/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1539280070631},{"_id":"themes/yilia/layout/_partial/post/title.ejs","hash":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1539280070631},{"_id":"themes/yilia/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1539280070636},{"_id":"themes/yilia/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1539280070636},{"_id":"themes/yilia/source/css/_partial/archive.styl","hash":"81624b9d5a510cc5f47f10bd1e6a0f8ea218844f","modified":1539280070634},{"_id":"themes/yilia/source/css/_partial/article.styl","hash":"09e9b4d13482ad8415029e3c1c1452fcee0f8947","modified":1539280070634},{"_id":"themes/yilia/source/css/_partial/footer.styl","hash":"16fa9293ad5060e5de45272a3189ac25c0332a13","modified":1539280070634},{"_id":"themes/yilia/source/css/_partial/header.styl","hash":"85ab11e082f4dd86dde72bed653d57ec5381f30c","modified":1539280070634},{"_id":"themes/yilia/source/css/_partial/highlight.styl","hash":"3f74436516ef030f82db2d33f44fd401a86743a1","modified":1539280070635},{"_id":"themes/yilia/source/css/_partial/instagram.styl","hash":"d1a61bc91761f4c90972e08187da7e378d79c41d","modified":1539280070635},{"_id":"themes/yilia/source/css/_partial/main.styl","hash":"8270847ee5eaa87d7c3b040a9b6ef048288ffbc1","modified":1539280070635},{"_id":"themes/yilia/source/css/_partial/mobile.styl","hash":"3a1926c78a17519150063e155ac32d5a6545eb99","modified":1539280070635},{"_id":"themes/yilia/source/css/_partial/page.styl","hash":"0b5b20b33142dee8509cfebe7dbb1bd89150bad8","modified":1539280070635},{"_id":"themes/yilia/source/css/_partial/share.styl","hash":"6ac15a6815b1bbdbea89d3fe933c2821aa80b926","modified":1539280070635},{"_id":"themes/yilia/source/css/_partial/tagcloud.styl","hash":"b619224bdc05be2b3809daddaa7a8d78cae457b3","modified":1539280070636},{"_id":"themes/yilia/source/css/fonts/fontawesome-webfont.eot","hash":"3ce87b82c7a4ffdf65e96765c2ffda10b1a283c6","modified":1539280070637},{"_id":"themes/yilia/source/css/fonts/fontawesome-webfont.svgz","hash":"4bfdd33ed702e32ae01399fcc2652377f78e7626","modified":1539280070637},{"_id":"themes/yilia/source/css/fonts/fontawesome-webfont.ttf","hash":"1480b8101b02da9bc4c60341b5e185e63e585064","modified":1539280070638},{"_id":"themes/yilia/source/css/fonts/fontawesome-webfont.woff","hash":"cafc4ac5761a0a252d33dce4ea3952cf9a38d832","modified":1539280070638},{"_id":"themes/yilia/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1539280070640},{"_id":"themes/yilia/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1539280070640},{"_id":"themes/yilia/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1539280070641},{"_id":"themes/yilia/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1539280070641},{"_id":"themes/yilia/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1539280070641},{"_id":"themes/yilia/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1539280070641},{"_id":"themes/yilia/source/css/fonts/fontawesome-webfont.svg","hash":"23a6f5b2ff76de9cb3cf1e886194c67647fd868a","modified":1539280070637},{"_id":"public/2017/04/09/elk_in_action_grok_start/index.html","hash":"fc01ffeabd09b87effac1298fd94ecc3eb687e71","modified":1539310216567},{"_id":"public/2015/10/24/pubu_im_start/index.html","hash":"106e0e96d2e3a602bfcd9d8de651eba7b3ccdc26","modified":1539310216567},{"_id":"public/2015/01/06/spring-test-start/index.html","hash":"87a0ef1105828b727244a04c7d46ca3d229b62d2","modified":1539310216567},{"_id":"public/2015/01/03/linux-install-sdk-and-maven/index.html","hash":"4ce44df49e2abd0bdddbc624bd640d2cb0dec993","modified":1539310216567},{"_id":"public/2014/12/29/mqtt-start/index.html","hash":"fa38e6f19bba949d61c8f02bdca0302dc37651b3","modified":1539310216567},{"_id":"public/2014/10/05/tip-linux-common-command/index.html","hash":"ee5836ba1d49b7b31aeecd0923058a1fc47b6419","modified":1539310216567},{"_id":"public/2014/10/05/tip-sublime-text-ubuntu/index.html","hash":"95a58cac36699a16016b9e186ec35cd718451a0d","modified":1539310216567},{"_id":"public/2014/10/05/tip-git/index.html","hash":"794f3679c077ed9938c5c211f358ec5b6c5a891f","modified":1539310216567},{"_id":"public/2014/05/19/String-StringBuffer-StringBuilder-diff/index.html","hash":"ff3ac5244be4c973f48875fad31e0f9c9fc0dac4","modified":1539310216567},{"_id":"public/2014/05/19/java-constructor-base/index.html","hash":"a03c046867ea2d7d1ac4d828595ddd2a7be97235","modified":1539310216567},{"_id":"public/2014/05/19/final-finally-finalize-diff/index.html","hash":"6b68aff3bfc92b7b8f10de87645e46f063868667","modified":1539310216567},{"_id":"public/2014/05/19/sleep-wait-diff/index.html","hash":"e61108dd8fb41640eadab2d2d0f4bd22fc87e252","modified":1539310216568},{"_id":"public/2014/05/19/finally-lose/index.html","hash":"308adb83c73fa00ccabd4b347fe8e8c8c1bf1ff4","modified":1539310216568},{"_id":"public/2014/05/19/HashMap-HashTable-diff/index.html","hash":"4b485959721dfcfc10fd192f988ae5dca7994bd9","modified":1539310216568},{"_id":"public/2014/05/13/maven-start/index.html","hash":"6f575238e7383f551d3ee49be81535b14e40758f","modified":1539310216568},{"_id":"public/categories/nodejs/index.html","hash":"1144c193bba9829ee0b6fe447e5ea4045c1077e2","modified":1539310216568},{"_id":"public/categories/android/index.html","hash":"6c0688791030cc90e860d8a6536a3e5b5c2e219a","modified":1539310216568},{"_id":"public/categories/elk/index.html","hash":"e217cbffcbe80cfcfae7e8f4063a2a0bbb241fea","modified":1539310216568},{"_id":"public/categories/linux/index.html","hash":"02c35879fbd022dd2a87fe37637be755ab86cc12","modified":1539310216568},{"_id":"public/categories/maven/index.html","hash":"fa1a88384d625e91ef3e748727ece43b880b1c17","modified":1539310216568},{"_id":"public/categories/mqtt/index.html","hash":"c55870d7e42c25427991e140ed8c5de222e7ae98","modified":1539310216568},{"_id":"public/categories/issue-trace/index.html","hash":"030673008de37754b36d9066561f2f323e26d533","modified":1539310216568},{"_id":"public/categories/tools/index.html","hash":"afbfab0510881d705c0ecc22d709ce031e675de4","modified":1539310216568},{"_id":"public/categories/mysql/index.html","hash":"404e7aeccbe3b604a4f8b12968b60535c6f0dcf0","modified":1539310216568},{"_id":"public/categories/Database/index.html","hash":"577247e30c73e565b3fabe7ef3f80dc15a046cb8","modified":1539310216568},{"_id":"public/categories/tips/index.html","hash":"f41404f7facba1e8fd27aa01da0ab0dad3040f56","modified":1539310216568},{"_id":"public/categories/redis/index.html","hash":"90d3604e985f902b6157ac76c2afb8dcc0c7e3c1","modified":1539310216568},{"_id":"public/page/3/index.html","hash":"9db1fc8e763cf0492441c41a069f736c746e8dbd","modified":1539310216568},{"_id":"public/tags/java/index.html","hash":"a86afb3d1aa6458170824fc7983509294be5125a","modified":1539310216568},{"_id":"public/tags/agenda/index.html","hash":"e819a4b120d5f1b5ebcc7eb2ab2dde8cbaf07f5c","modified":1539310216568},{"_id":"public/tags/android/index.html","hash":"2d912ca235591b0e07bbe33a824465718ee048b4","modified":1539310216569},{"_id":"public/tags/elk/index.html","hash":"cbeb6f182be3336af03cb114c40af60c01ab9d81","modified":1539310216569},{"_id":"public/tags/gork/index.html","hash":"8ad6266a055235b36552113b98151e5fcd296116","modified":1539310216569},{"_id":"public/tags/linux/index.html","hash":"139a62014feeb8debbdb892f7e015e6eb0580938","modified":1539310216569},{"_id":"public/tags/maven/index.html","hash":"92c2e770c5011e879f68e2d665c59e6317ec1ff1","modified":1539310216569},{"_id":"public/tags/jdk/index.html","hash":"7931bccbaf793e344386d127983f183ed5e781e2","modified":1539310216569},{"_id":"public/tags/git/index.html","hash":"0a36913a97dfb12f53bf712867ab5164bedbc993","modified":1539310216569},{"_id":"public/tags/mqtt/index.html","hash":"b0a997543149a7ecc9fc84bba693d3364741c51e","modified":1539310216569},{"_id":"public/tags/im/index.html","hash":"7a42110184ccb17ce192350284b0657df0b34130","modified":1539310216570},{"_id":"public/tags/nginx/index.html","hash":"c678a718ef509aa3b196efaa8ef6985bf72b5583","modified":1539310216570},{"_id":"public/tags/keepalive/index.html","hash":"b93525840ae024dc4cdf229610509839b07e9565","modified":1539310216570},{"_id":"public/tags/tools/index.html","hash":"272ed5036540afdad12a17bc2763cd26c7d9ba98","modified":1539310216570},{"_id":"public/tags/mysql/index.html","hash":"7bf84347be73e07d3dd28e0a73270dc6c0ccf8d9","modified":1539310216570},{"_id":"public/tags/redis/index.html","hash":"250cd8e23fedd08570350ac715d6f055347a17e1","modified":1539310216570},{"_id":"public/tags/spring-test/index.html","hash":"1704b4766543cd0b75f7e405d9a518c3424d10ed","modified":1539310216570},{"_id":"public/tags/sublime-text/index.html","hash":"bf8e570bd4fe36b38d05761ccf130cf5048e315f","modified":1539310216570},{"_id":"public/tags/ziplist/index.html","hash":"946a7be807c59e659bfab015e89a39f67a4b5e48","modified":1539310216570},{"_id":"public/archives/page/3/index.html","hash":"5ad662e5423cb64205d54c951c49334ff29d08fb","modified":1539310216571},{"_id":"public/archives/2014/page/2/index.html","hash":"ad5e1fd00ed3ed2dd3bbb5c18189f9d1680665f6","modified":1539310216571},{"_id":"public/archives/2014/05/index.html","hash":"cabcad8cb7ac8873d6adba110f94601a6181dd13","modified":1539310216571},{"_id":"public/archives/2014/10/index.html","hash":"42f42099ebd1f5e58f08306f9f876b0895462ac5","modified":1539310216571},{"_id":"public/archives/2014/12/index.html","hash":"af4f32b032d41d385e0f8333177cc157d5642e31","modified":1539310216571},{"_id":"public/archives/2015/01/index.html","hash":"594de6980d4293fa33c8c4dcb815a92718aa41fe","modified":1539310216571},{"_id":"public/archives/2015/02/index.html","hash":"700e73598be60604f15a0263dcc5ddd4b66fe51a","modified":1539310216571},{"_id":"public/archives/2015/07/index.html","hash":"b45fb9801454442641678e9d4992f14f9568d7f2","modified":1539310216571},{"_id":"public/archives/2015/10/index.html","hash":"c11a29fdd59dfcef68ebcdd92bcc022287209761","modified":1539310216571},{"_id":"public/archives/2015/12/index.html","hash":"a2afa599c6f9bcf1a4541cbfadaca1613928ac46","modified":1539310216571},{"_id":"public/archives/2016/index.html","hash":"5c98c8a1f6efbc2ab24264a5f9191c1c1887d2c0","modified":1539310216571},{"_id":"public/archives/2016/08/index.html","hash":"ad77151cf73e3128cd9d9c55373ce17945025ae6","modified":1539310216571},{"_id":"public/archives/2017/index.html","hash":"2fa7ce4c87faf9faae05fe27ba156f84d0ab7768","modified":1539310216571},{"_id":"public/archives/2017/04/index.html","hash":"a4c62024517bd32d7ba72f6e8d640cf76a0d68c7","modified":1539310216571},{"_id":"public/archives/2017/05/index.html","hash":"48f6a32b02c9d7245546e2d0b0fe607c293f73a5","modified":1539310216571},{"_id":"public/archives/2017/09/index.html","hash":"1831b9f1b7c38d94d459dd6951ed3cbdc224e578","modified":1539310216571},{"_id":"public/2017/09/27/nginx-502-bug-trace/index.html","hash":"916cffa24fc19e767c15fb53c6aee918bae536a3","modified":1539310216572},{"_id":"public/2017/04/09/elk_in_action_analyze_nginx_logs/index.html","hash":"c9d0304241f0dd56fc6ec68b900175da3565a945","modified":1539310216572},{"_id":"public/2017/05/01/redis_in_action_ziplist/index.html","hash":"4f7c72ee03e9ed9db548810dcb91e31696d2c0ff","modified":1539310216572},{"_id":"public/2016/08/13/maven_module_with_git_sub_module/index.html","hash":"8aa3ae2ac1aac38265f8df8febd5638fc610adbe","modified":1539310216572},{"_id":"public/2015/12/13/redis_cluster_research_2/index.html","hash":"18ea513bca51e4191c0aa907b9368e9c0a5a643c","modified":1539310216572},{"_id":"public/2015/12/03/redis_cluster_research_1/index.html","hash":"9bda8e04d0983bb615302c4baf49a5b6ef83ffbd","modified":1539310216572},{"_id":"public/2015/07/07/android-annotations-start/index.html","hash":"93adb674f4fc9ff018293295ef020853a241d1db","modified":1539310216572},{"_id":"public/2015/02/03/mysql-utf8mb4/index.html","hash":"74a73c31570671a6693ba9055f0388570a81f16c","modified":1539310216572},{"_id":"public/2014/12/29/agenda-start/index.html","hash":"399f9077e58b1e7f4fd25870faf8772d7a7a897e","modified":1539310216572},{"_id":"public/categories/java/index.html","hash":"7a9f39c94f7d7a8de000a47e6046289ab0ecbece","modified":1539310216572},{"_id":"public/index.html","hash":"27421174d0c90db83a811663a68a6f9708652943","modified":1539310216572},{"_id":"public/page/2/index.html","hash":"008eef161cf98bb912aa24d8b239a6ac0a61613a","modified":1539310216572},{"_id":"public/archives/index.html","hash":"7402c4ba07266a791b7a439acc0f00a89e9dc2f1","modified":1539310216572},{"_id":"public/archives/page/2/index.html","hash":"b36747ba912b924b4e12d463eb49fb7c43c0db60","modified":1539310216572},{"_id":"public/archives/2014/index.html","hash":"6ea26bace75e87723e81862005bfdeefe594b33f","modified":1539310216572},{"_id":"public/archives/2015/index.html","hash":"6d716bc5fefe16821ba07ef424649bb40d076df2","modified":1539310216572},{"_id":"public/CNAME","hash":"2c0f6791f654ed73c45d44fc21542dc78d70ddf4","modified":1539310216581},{"_id":"public/Dockerfile","hash":"275276f91447fd5140271f31fe8bcfeb8cfe2acf","modified":1539310216581},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1539310216582},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1539310216582},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1539310216582},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1539310216582},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1539310216582},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1539310216582},{"_id":"public/img/coderwall.png","hash":"fa84676c4d654e040e51fd34bfcd9f9348cd5331","modified":1539310216582},{"_id":"public/img/delicious.png","hash":"9553a5f5189e4a953e04a58a49dbfa74b86b73dd","modified":1539310216582},{"_id":"public/img/facebook.png","hash":"d19ad7a0903daf26817afd8753cd97e0cc714f54","modified":1539310216582},{"_id":"public/img/github.png","hash":"b84d03b32fa388dcbf149296ebd16dce6223d48d","modified":1539310216582},{"_id":"public/img/google.png","hash":"61a21fec7346fa3400b747ac9a201cf3d5bc013d","modified":1539310216582},{"_id":"public/img/img-err.png","hash":"23a63ea26eb3c1d5e677d9883cf36cc1a1a1228b","modified":1539310216582},{"_id":"public/img/img-loading.png","hash":"a9cd5cd11866824f31e3d1c5e23badfeb3f73031","modified":1539310216582},{"_id":"public/img/linkedin.png","hash":"e203138fb53c257cb214e97f4e30091b9c568d2c","modified":1539310216582},{"_id":"public/img/pinboard.png","hash":"0891fbb6d092fa012bf936019923383d84c6aeb0","modified":1539310216582},{"_id":"public/img/pinterest.png","hash":"9c72917f8779c083157c6ce7a5d62ed4874f0630","modified":1539310216582},{"_id":"public/img/rss.png","hash":"430fd47340e75214c081abd05cd7410cf7c71b86","modified":1539310216582},{"_id":"public/img/stackoverflow.png","hash":"da5dfe9043055c95e479d49c78cd3b020de608f2","modified":1539310216582},{"_id":"public/img/twitter.png","hash":"14dbb8e62d056525253bc0de13acd1723da7a934","modified":1539310216582},{"_id":"public/img/weibo.png","hash":"280dae3fd38086158b4a1b57edb94c06b1a5014b","modified":1539310216582},{"_id":"public/css/fonts/fontawesome-webfont.eot","hash":"3ce87b82c7a4ffdf65e96765c2ffda10b1a283c6","modified":1539310216582},{"_id":"public/css/fonts/fontawesome-webfont.svgz","hash":"4bfdd33ed702e32ae01399fcc2652377f78e7626","modified":1539310216582},{"_id":"public/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1539310216582},{"_id":"public/css/fonts/fontawesome-webfont.woff","hash":"cafc4ac5761a0a252d33dce4ea3952cf9a38d832","modified":1539310216583},{"_id":"public/css/fonts/fontawesome-webfont.ttf","hash":"1480b8101b02da9bc4c60341b5e185e63e585064","modified":1539310216583},{"_id":"public/css/fonts/fontawesome-webfont.svg","hash":"23a6f5b2ff76de9cb3cf1e886194c67647fd868a","modified":1539310216826},{"_id":"public/fancybox/jquery.fancybox.css","hash":"fea04e517da359d3f99fe1a72f1c9725638a797e","modified":1539310216830},{"_id":"public/js/instagram.js","hash":"9c3fa2f07724b20f6f2b05bc4f2d01ea0633001d","modified":1539310216830},{"_id":"public/js/main.js","hash":"dd10c8763d80b593608c513cf2104cab70758770","modified":1539310216830},{"_id":"public/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1539310216830},{"_id":"public/js/jquery.lazyload.js","hash":"c11a2e7b330d16d06feabd0a8477099adf9d6799","modified":1539310216830},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1539310216830},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1539310216830},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1539310216830},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1539310216830},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1539310216830},{"_id":"public/css/style.css","hash":"55ef0cfac5e19e47f6c654fe5784b183182911d4","modified":1539310216830},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1539310216836},{"_id":"public/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1539310216840},{"_id":"source/_posts/druid_data_ingestion_different.md","hash":"90ae3062934bcbff1ff2fba190f8bf65d261161b","modified":1551011775082}],"Category":[{"name":"java","_id":"cjn5dk44a0002l939wusdwq2s"},{"name":"nodejs","_id":"cjn5dk44i000cl9391jtnbkeg"},{"name":"android","_id":"cjn5dk44l000kl93954pjgumq"},{"name":"elk","_id":"cjn5dk44n000sl939fj0ey1dp"},{"name":"linux","_id":"cjn5dk44r0016l939wg8md1nd"},{"name":"maven","_id":"cjn5dk44u001fl9390c55rlcd"},{"name":"mqtt","_id":"cjn5dk44x001ll939r8fw2v7a"},{"name":"issue-trace","_id":"cjn5dk44y001sl939bidmy4kw"},{"name":"tools","_id":"cjn5dk44z001xl939mf7y6fsx"},{"name":"mysql","_id":"cjn5dk44z0020l939n8fjd4no"},{"name":"Database","_id":"cjn5dk4500025l939ieiqnv4k"},{"name":"tips","_id":"cjn5dk450002al939jiy9rquc"},{"name":"redis","_id":"cjn5dk45d0037l939xcbeati3"},{"name":"druid","_id":"cjsiweti50001su39luukrzy4"}],"Data":[],"Page":[],"Post":[{"layout":"post","title":"HashMap,HashTable区别","date":"2014-05-18T16:00:00.000Z","description":"实际应用中，我们并不经常需要保证HashMap这些底层代码的同步，交由上层逻辑去控制同步。所以，大多数时候建议使用HashMap","_content":"\n实际应用中，我们并不经常需要保证HashMap这些底层代码的同步，交由上层逻辑去控制同步。所以，大多数时候建议使用HashMap.\n\n<!-- more -->\n\n## HashMap,HashTable区别\n\n### HashTable\n特点：线程同步 \n\n### HashMap\n特定：\n\n* 线程不同步，但可以通过 ``` Collections.synchronizedMap(HashMap map) ``` 实现线程同步。\n* 允许Key，value值为空。\n* 优于HashTable的Hash算法，使Hash值更广泛的分布到数组的不同位置。\n* 更优的效率\n\n实际应用中，我们并不经常需要保证HashMap这些底层代码的同步，交由上层逻辑去控制同步。所以，大多数时候建议使用HashMap.\n","source":"_posts/HashMap-HashTable-diff.md","raw":"---\nlayout: post\ntitle: \"HashMap,HashTable区别\"\ndate: 2014-05-19\ncategories:\n- java\ntags:\n- java\ndescription: 实际应用中，我们并不经常需要保证HashMap这些底层代码的同步，交由上层逻辑去控制同步。所以，大多数时候建议使用HashMap\n\n---\n\n实际应用中，我们并不经常需要保证HashMap这些底层代码的同步，交由上层逻辑去控制同步。所以，大多数时候建议使用HashMap.\n\n<!-- more -->\n\n## HashMap,HashTable区别\n\n### HashTable\n特点：线程同步 \n\n### HashMap\n特定：\n\n* 线程不同步，但可以通过 ``` Collections.synchronizedMap(HashMap map) ``` 实现线程同步。\n* 允许Key，value值为空。\n* 优于HashTable的Hash算法，使Hash值更广泛的分布到数组的不同位置。\n* 更优的效率\n\n实际应用中，我们并不经常需要保证HashMap这些底层代码的同步，交由上层逻辑去控制同步。所以，大多数时候建议使用HashMap.\n","slug":"HashMap-HashTable-diff","published":1,"updated":"2018-10-11T17:47:50.622Z","comments":1,"photos":[],"link":"","_id":"cjn5dk4430000l9398i90y5kz","content":"<p>实际应用中，我们并不经常需要保证HashMap这些底层代码的同步，交由上层逻辑去控制同步。所以，大多数时候建议使用HashMap.</p>\n<a id=\"more\"></a>\n<h2 id=\"HashMap-HashTable区别\"><a href=\"#HashMap-HashTable区别\" class=\"headerlink\" title=\"HashMap,HashTable区别\"></a>HashMap,HashTable区别</h2><h3 id=\"HashTable\"><a href=\"#HashTable\" class=\"headerlink\" title=\"HashTable\"></a>HashTable</h3><p>特点：线程同步 </p>\n<h3 id=\"HashMap\"><a href=\"#HashMap\" class=\"headerlink\" title=\"HashMap\"></a>HashMap</h3><p>特定：</p>\n<ul>\n<li>线程不同步，但可以通过 <code>Collections.synchronizedMap(HashMap map)</code> 实现线程同步。</li>\n<li>允许Key，value值为空。</li>\n<li>优于HashTable的Hash算法，使Hash值更广泛的分布到数组的不同位置。</li>\n<li>更优的效率</li>\n</ul>\n<p>实际应用中，我们并不经常需要保证HashMap这些底层代码的同步，交由上层逻辑去控制同步。所以，大多数时候建议使用HashMap.</p>\n","site":{"data":{}},"excerpt":"<p>实际应用中，我们并不经常需要保证HashMap这些底层代码的同步，交由上层逻辑去控制同步。所以，大多数时候建议使用HashMap.</p>","more":"<h2 id=\"HashMap-HashTable区别\"><a href=\"#HashMap-HashTable区别\" class=\"headerlink\" title=\"HashMap,HashTable区别\"></a>HashMap,HashTable区别</h2><h3 id=\"HashTable\"><a href=\"#HashTable\" class=\"headerlink\" title=\"HashTable\"></a>HashTable</h3><p>特点：线程同步 </p>\n<h3 id=\"HashMap\"><a href=\"#HashMap\" class=\"headerlink\" title=\"HashMap\"></a>HashMap</h3><p>特定：</p>\n<ul>\n<li>线程不同步，但可以通过 <code>Collections.synchronizedMap(HashMap map)</code> 实现线程同步。</li>\n<li>允许Key，value值为空。</li>\n<li>优于HashTable的Hash算法，使Hash值更广泛的分布到数组的不同位置。</li>\n<li>更优的效率</li>\n</ul>\n<p>实际应用中，我们并不经常需要保证HashMap这些底层代码的同步，交由上层逻辑去控制同步。所以，大多数时候建议使用HashMap.</p>"},{"layout":"post","title":"String，StringBuffer，StringBuilder的区别","date":"2014-05-18T16:00:00.000Z","desciption":"String，StringBuffer，StringBuilder的区别","_content":"\n### String\nString值是不可变的，每次对String的操作都会生出一个新的String对象。如果频繁改动的话，效率会很低，产生太多的垃圾会触发JVM的垃圾回收，影响系统性能。  \n另外 `String s = new String(\"abc\") ` 会生出两个对象, 因为括号里面的\"abc\"算一。\n\n<!-- more -->\n\n### StringBuffer\n可变长度的字符串缓存区，特定是在append与insert操作的时候，速度会比String快很多。并且在多线程下是安全的。如果大量频繁的字符串操作，考虑使用该类。  \n\n\n### StringBuilder\n5.0后新增的方法，在多线程下不保证同步（即线程不安全），但速度会比StringBuffer快。所以，在单线程的环境下，建议使用StringBuilder。 \n\n### 总结\n一般情况下，对字符串的操作速度 StringBuilder > StringBuffer > String。  \n* 字符串操作少的情况，使用 String\n* 单线程，字符串操作多的情况， 使用StringBuilder\n* 多线程，字符串操作多的情况， 使用StringBuffer\n\n### 额外的注意\n`String s = a + b ` 的情况 ，实际上JVM的处理是这样` String c = (new StringBuilder(String.valueOf(a))).append(b).toString() `  \n如此一来每次字符串操作都会生出一个StringBuffer对象。效率多少会有点影响的。\n","source":"_posts/String-StringBuffer-StringBuilder-diff.md","raw":"---\nlayout: post\ntitle: \"String，StringBuffer，StringBuilder的区别\"\ndate: 2014-05-19\ncategories:\n- java\ntags:\n- java\ndesciption: String，StringBuffer，StringBuilder的区别\n\n---\n\n### String\nString值是不可变的，每次对String的操作都会生出一个新的String对象。如果频繁改动的话，效率会很低，产生太多的垃圾会触发JVM的垃圾回收，影响系统性能。  \n另外 `String s = new String(\"abc\") ` 会生出两个对象, 因为括号里面的\"abc\"算一。\n\n<!-- more -->\n\n### StringBuffer\n可变长度的字符串缓存区，特定是在append与insert操作的时候，速度会比String快很多。并且在多线程下是安全的。如果大量频繁的字符串操作，考虑使用该类。  \n\n\n### StringBuilder\n5.0后新增的方法，在多线程下不保证同步（即线程不安全），但速度会比StringBuffer快。所以，在单线程的环境下，建议使用StringBuilder。 \n\n### 总结\n一般情况下，对字符串的操作速度 StringBuilder > StringBuffer > String。  \n* 字符串操作少的情况，使用 String\n* 单线程，字符串操作多的情况， 使用StringBuilder\n* 多线程，字符串操作多的情况， 使用StringBuffer\n\n### 额外的注意\n`String s = a + b ` 的情况 ，实际上JVM的处理是这样` String c = (new StringBuilder(String.valueOf(a))).append(b).toString() `  \n如此一来每次字符串操作都会生出一个StringBuffer对象。效率多少会有点影响的。\n","slug":"String-StringBuffer-StringBuilder-diff","published":1,"updated":"2018-10-11T17:47:50.622Z","comments":1,"photos":[],"link":"","_id":"cjn5dk4480001l939lzgva60p","content":"<h3 id=\"String\"><a href=\"#String\" class=\"headerlink\" title=\"String\"></a>String</h3><p>String值是不可变的，每次对String的操作都会生出一个新的String对象。如果频繁改动的话，效率会很低，产生太多的垃圾会触发JVM的垃圾回收，影响系统性能。<br>另外 <code>String s = new String(&quot;abc&quot;)</code> 会生出两个对象, 因为括号里面的”abc”算一。</p>\n<a id=\"more\"></a>\n<h3 id=\"StringBuffer\"><a href=\"#StringBuffer\" class=\"headerlink\" title=\"StringBuffer\"></a>StringBuffer</h3><p>可变长度的字符串缓存区，特定是在append与insert操作的时候，速度会比String快很多。并且在多线程下是安全的。如果大量频繁的字符串操作，考虑使用该类。  </p>\n<h3 id=\"StringBuilder\"><a href=\"#StringBuilder\" class=\"headerlink\" title=\"StringBuilder\"></a>StringBuilder</h3><p>5.0后新增的方法，在多线程下不保证同步（即线程不安全），但速度会比StringBuffer快。所以，在单线程的环境下，建议使用StringBuilder。 </p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>一般情况下，对字符串的操作速度 StringBuilder &gt; StringBuffer &gt; String。  </p>\n<ul>\n<li>字符串操作少的情况，使用 String</li>\n<li>单线程，字符串操作多的情况， 使用StringBuilder</li>\n<li>多线程，字符串操作多的情况， 使用StringBuffer</li>\n</ul>\n<h3 id=\"额外的注意\"><a href=\"#额外的注意\" class=\"headerlink\" title=\"额外的注意\"></a>额外的注意</h3><p><code>String s = a + b</code> 的情况 ，实际上JVM的处理是这样<code>String c = (new StringBuilder(String.valueOf(a))).append(b).toString()</code><br>如此一来每次字符串操作都会生出一个StringBuffer对象。效率多少会有点影响的。</p>\n","site":{"data":{}},"excerpt":"<h3 id=\"String\"><a href=\"#String\" class=\"headerlink\" title=\"String\"></a>String</h3><p>String值是不可变的，每次对String的操作都会生出一个新的String对象。如果频繁改动的话，效率会很低，产生太多的垃圾会触发JVM的垃圾回收，影响系统性能。<br>另外 <code>String s = new String(&quot;abc&quot;)</code> 会生出两个对象, 因为括号里面的”abc”算一。</p>","more":"<h3 id=\"StringBuffer\"><a href=\"#StringBuffer\" class=\"headerlink\" title=\"StringBuffer\"></a>StringBuffer</h3><p>可变长度的字符串缓存区，特定是在append与insert操作的时候，速度会比String快很多。并且在多线程下是安全的。如果大量频繁的字符串操作，考虑使用该类。  </p>\n<h3 id=\"StringBuilder\"><a href=\"#StringBuilder\" class=\"headerlink\" title=\"StringBuilder\"></a>StringBuilder</h3><p>5.0后新增的方法，在多线程下不保证同步（即线程不安全），但速度会比StringBuffer快。所以，在单线程的环境下，建议使用StringBuilder。 </p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>一般情况下，对字符串的操作速度 StringBuilder &gt; StringBuffer &gt; String。  </p>\n<ul>\n<li>字符串操作少的情况，使用 String</li>\n<li>单线程，字符串操作多的情况， 使用StringBuilder</li>\n<li>多线程，字符串操作多的情况， 使用StringBuffer</li>\n</ul>\n<h3 id=\"额外的注意\"><a href=\"#额外的注意\" class=\"headerlink\" title=\"额外的注意\"></a>额外的注意</h3><p><code>String s = a + b</code> 的情况 ，实际上JVM的处理是这样<code>String c = (new StringBuilder(String.valueOf(a))).append(b).toString()</code><br>如此一来每次字符串操作都会生出一个StringBuffer对象。效率多少会有点影响的。</p>"},{"layout":"post","title":"Agenda笔记","date":"2014-12-28T16:00:00.000Z","_content":"\n[Agenda][1]是类似Quarzt的轻量级持久化任务调度框架, 数据存储再mongodb上, 部署与学习十分简单.\n第三方开发者还为Agenda提供了一个简易的UI界面 [Agenda UI][2]. 提供简单的可视化界面.\n\n<!-- more -->\n\n### Base\nAgenda 将任务对象保存再mongo里面, 任务对象包含任务的name, 附带数据, 定时规则等.\n我们可以动态对任务进行CRUD操作. Agenda提供对应API.\n\n虽然Agenda本身提供的对Job的操作比较简单, 但因为Agenda的Job都是存储再mongo之中,所以我们可以通过直接操作monogo实现的Job的更新与删除.\n\n### Start\n简单的添加任务操作:\n```\nvar job = agenda.create('testJob', {key: \"value\"});\njob.repeatEvery('5 seconds');\njob.save(function(err) {\n    console.log(\"Job successfully saved\");\n});\n```\n程序开始时,我们需要创建agenda对象,指定事件响应函数,并开始执行任务调用.\n\n```\nvar agenda = new Agenda({db: { address: 'localhost:27017/agenda-example'});\nagenda.define('testJob',  function(job) {\n    console.log(\"Job execute, now is \" + new Date()  + \" Data=\" + JSON.stringify(job.attrs.data));\n});\nagenda.run();\n```\n\n\n#### 数据存储\nAgenda使用mongodb。\n\n```\n// 指定使用的mongodb，默认使用agendaJobs集合\nvar agenda = new Agenda({db: { address: 'localhost:27017/agenda-example'}});\n\n// 如果需要指定其他集合\nvar agenda = new Agenda({db: { address: 'localhost:27017/agenda-test', collection: 'agendaJobs' }});\n```\n\n#### 指定循环规制\n\n```\n// 直接构造的agenda对象的时候指定\nvar agenda = new Agenda({processEvery: '1 minute'});\n// 1分钟循环一次\nagenda.processEvery('1 minute');\n\n```\n\n#### 指定任务最大并发数\n\n```\n// 构造时指定\nvar agenda = new Agenda({maxConcurrency: 20});\n// 直接指定\nagenda.maxConcurrency(20);\n```\n\n#### 指定默认并发数\n\n```\n// 构造时指定\nagenda.defaultConcurrency(5);\n// 直接指定\nvar agenda = new Agenda({defaultConcurrency: 5});\n```\n\n#### 设置任务最大响应时间\n指定任务从开始执行到调用finish的时间（指调用done函数），这能有效的解决任务奔溃或者超时\n\n\n```\n// 构造时指定\nvar agenda = new Agenda({defaultLockLifetime: 10000});\n// 直接指定\nagenda.defaultLockLifetime(10000);\n```\n\n\n### 定义任务处理器\n\n#### 定义任务行为\n当执行的任务为异步方法的时候，需要再方法最后调用done()\n如果为同步方法，则省略声明done\n\n影响任务行为的参数：\n\n* concurrency 指定最大任务并发数\n* lockLifetime 锁生存时间,指定异步调用时最长等待时间\n* priority 优先级(lowest|low|normal|high|highest|number)\n\n\n```\n// 执行任务为异步方法\nagenda.define('job_name', function(job, done) {\n    doSomething(function() {\n        done();\n    });\n});\n\n// 执行任务为同步方法\nagenda.define('say hello', function(job) {\n  console.log(\"Hello!\");\n});\n```\n\n#### 定时任务\n\n指定任务重复的规制,支持数字, cron表达式, 甚至如10 minutes等可读性较高的表达式\n\n```\njob.repeatEvery('10 minutes');\njob.repeatEvery('*/10 * * * * * *');\n```\n\n指定特定的重复时间\n\n```\n// 每天15:30\njob.repeatAt('3:30pm');\n```\n指定只执行一次的的任务\n\n```\njob.schedule('3:30pm');\n```\n\nnow\n马上执行某事件\n```\nagenda.now('do the hokey pokey');\n```\n\n\n  [1]: https://github.com/rschmukler/agenda\n  [2]: https://github.com/moudy/agenda-ui","source":"_posts/agenda-start.md","raw":"---\nlayout: post\ntitle: \"Agenda笔记\"\ndate: 2014-12-29\ncategories:\n- nodejs\ntags:\n- agenda\n\n---\n\n[Agenda][1]是类似Quarzt的轻量级持久化任务调度框架, 数据存储再mongodb上, 部署与学习十分简单.\n第三方开发者还为Agenda提供了一个简易的UI界面 [Agenda UI][2]. 提供简单的可视化界面.\n\n<!-- more -->\n\n### Base\nAgenda 将任务对象保存再mongo里面, 任务对象包含任务的name, 附带数据, 定时规则等.\n我们可以动态对任务进行CRUD操作. Agenda提供对应API.\n\n虽然Agenda本身提供的对Job的操作比较简单, 但因为Agenda的Job都是存储再mongo之中,所以我们可以通过直接操作monogo实现的Job的更新与删除.\n\n### Start\n简单的添加任务操作:\n```\nvar job = agenda.create('testJob', {key: \"value\"});\njob.repeatEvery('5 seconds');\njob.save(function(err) {\n    console.log(\"Job successfully saved\");\n});\n```\n程序开始时,我们需要创建agenda对象,指定事件响应函数,并开始执行任务调用.\n\n```\nvar agenda = new Agenda({db: { address: 'localhost:27017/agenda-example'});\nagenda.define('testJob',  function(job) {\n    console.log(\"Job execute, now is \" + new Date()  + \" Data=\" + JSON.stringify(job.attrs.data));\n});\nagenda.run();\n```\n\n\n#### 数据存储\nAgenda使用mongodb。\n\n```\n// 指定使用的mongodb，默认使用agendaJobs集合\nvar agenda = new Agenda({db: { address: 'localhost:27017/agenda-example'}});\n\n// 如果需要指定其他集合\nvar agenda = new Agenda({db: { address: 'localhost:27017/agenda-test', collection: 'agendaJobs' }});\n```\n\n#### 指定循环规制\n\n```\n// 直接构造的agenda对象的时候指定\nvar agenda = new Agenda({processEvery: '1 minute'});\n// 1分钟循环一次\nagenda.processEvery('1 minute');\n\n```\n\n#### 指定任务最大并发数\n\n```\n// 构造时指定\nvar agenda = new Agenda({maxConcurrency: 20});\n// 直接指定\nagenda.maxConcurrency(20);\n```\n\n#### 指定默认并发数\n\n```\n// 构造时指定\nagenda.defaultConcurrency(5);\n// 直接指定\nvar agenda = new Agenda({defaultConcurrency: 5});\n```\n\n#### 设置任务最大响应时间\n指定任务从开始执行到调用finish的时间（指调用done函数），这能有效的解决任务奔溃或者超时\n\n\n```\n// 构造时指定\nvar agenda = new Agenda({defaultLockLifetime: 10000});\n// 直接指定\nagenda.defaultLockLifetime(10000);\n```\n\n\n### 定义任务处理器\n\n#### 定义任务行为\n当执行的任务为异步方法的时候，需要再方法最后调用done()\n如果为同步方法，则省略声明done\n\n影响任务行为的参数：\n\n* concurrency 指定最大任务并发数\n* lockLifetime 锁生存时间,指定异步调用时最长等待时间\n* priority 优先级(lowest|low|normal|high|highest|number)\n\n\n```\n// 执行任务为异步方法\nagenda.define('job_name', function(job, done) {\n    doSomething(function() {\n        done();\n    });\n});\n\n// 执行任务为同步方法\nagenda.define('say hello', function(job) {\n  console.log(\"Hello!\");\n});\n```\n\n#### 定时任务\n\n指定任务重复的规制,支持数字, cron表达式, 甚至如10 minutes等可读性较高的表达式\n\n```\njob.repeatEvery('10 minutes');\njob.repeatEvery('*/10 * * * * * *');\n```\n\n指定特定的重复时间\n\n```\n// 每天15:30\njob.repeatAt('3:30pm');\n```\n指定只执行一次的的任务\n\n```\njob.schedule('3:30pm');\n```\n\nnow\n马上执行某事件\n```\nagenda.now('do the hokey pokey');\n```\n\n\n  [1]: https://github.com/rschmukler/agenda\n  [2]: https://github.com/moudy/agenda-ui","slug":"agenda-start","published":1,"updated":"2018-10-11T17:47:50.622Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44b0004l939kyyr2a32","content":"<p><a href=\"https://github.com/rschmukler/agenda\" target=\"_blank\" rel=\"noopener\">Agenda</a>是类似Quarzt的轻量级持久化任务调度框架, 数据存储再mongodb上, 部署与学习十分简单.<br>第三方开发者还为Agenda提供了一个简易的UI界面 <a href=\"https://github.com/moudy/agenda-ui\" target=\"_blank\" rel=\"noopener\">Agenda UI</a>. 提供简单的可视化界面.</p>\n<a id=\"more\"></a>\n<h3 id=\"Base\"><a href=\"#Base\" class=\"headerlink\" title=\"Base\"></a>Base</h3><p>Agenda 将任务对象保存再mongo里面, 任务对象包含任务的name, 附带数据, 定时规则等.<br>我们可以动态对任务进行CRUD操作. Agenda提供对应API.</p>\n<p>虽然Agenda本身提供的对Job的操作比较简单, 但因为Agenda的Job都是存储再mongo之中,所以我们可以通过直接操作monogo实现的Job的更新与删除.</p>\n<h3 id=\"Start\"><a href=\"#Start\" class=\"headerlink\" title=\"Start\"></a>Start</h3><p>简单的添加任务操作:<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">var job = agenda.create(&apos;testJob&apos;, &#123;key: &quot;value&quot;&#125;);</span><br><span class=\"line\">job.repeatEvery(&apos;5 seconds&apos;);</span><br><span class=\"line\">job.save(function(err) &#123;</span><br><span class=\"line\">    console.log(&quot;Job successfully saved&quot;);</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure></p>\n<p>程序开始时,我们需要创建agenda对象,指定事件响应函数,并开始执行任务调用.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">var agenda = new Agenda(&#123;db: &#123; address: &apos;localhost:27017/agenda-example&apos;&#125;);</span><br><span class=\"line\">agenda.define(&apos;testJob&apos;,  function(job) &#123;</span><br><span class=\"line\">    console.log(&quot;Job execute, now is &quot; + new Date()  + &quot; Data=&quot; + JSON.stringify(job.attrs.data));</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">agenda.run();</span><br></pre></td></tr></table></figure>\n<h4 id=\"数据存储\"><a href=\"#数据存储\" class=\"headerlink\" title=\"数据存储\"></a>数据存储</h4><p>Agenda使用mongodb。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 指定使用的mongodb，默认使用agendaJobs集合</span><br><span class=\"line\">var agenda = new Agenda(&#123;db: &#123; address: &apos;localhost:27017/agenda-example&apos;&#125;&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">// 如果需要指定其他集合</span><br><span class=\"line\">var agenda = new Agenda(&#123;db: &#123; address: &apos;localhost:27017/agenda-test&apos;, collection: &apos;agendaJobs&apos; &#125;&#125;);</span><br></pre></td></tr></table></figure>\n<h4 id=\"指定循环规制\"><a href=\"#指定循环规制\" class=\"headerlink\" title=\"指定循环规制\"></a>指定循环规制</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 直接构造的agenda对象的时候指定</span><br><span class=\"line\">var agenda = new Agenda(&#123;processEvery: &apos;1 minute&apos;&#125;);</span><br><span class=\"line\">// 1分钟循环一次</span><br><span class=\"line\">agenda.processEvery(&apos;1 minute&apos;);</span><br></pre></td></tr></table></figure>\n<h4 id=\"指定任务最大并发数\"><a href=\"#指定任务最大并发数\" class=\"headerlink\" title=\"指定任务最大并发数\"></a>指定任务最大并发数</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 构造时指定</span><br><span class=\"line\">var agenda = new Agenda(&#123;maxConcurrency: 20&#125;);</span><br><span class=\"line\">// 直接指定</span><br><span class=\"line\">agenda.maxConcurrency(20);</span><br></pre></td></tr></table></figure>\n<h4 id=\"指定默认并发数\"><a href=\"#指定默认并发数\" class=\"headerlink\" title=\"指定默认并发数\"></a>指定默认并发数</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 构造时指定</span><br><span class=\"line\">agenda.defaultConcurrency(5);</span><br><span class=\"line\">// 直接指定</span><br><span class=\"line\">var agenda = new Agenda(&#123;defaultConcurrency: 5&#125;);</span><br></pre></td></tr></table></figure>\n<h4 id=\"设置任务最大响应时间\"><a href=\"#设置任务最大响应时间\" class=\"headerlink\" title=\"设置任务最大响应时间\"></a>设置任务最大响应时间</h4><p>指定任务从开始执行到调用finish的时间（指调用done函数），这能有效的解决任务奔溃或者超时</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 构造时指定</span><br><span class=\"line\">var agenda = new Agenda(&#123;defaultLockLifetime: 10000&#125;);</span><br><span class=\"line\">// 直接指定</span><br><span class=\"line\">agenda.defaultLockLifetime(10000);</span><br></pre></td></tr></table></figure>\n<h3 id=\"定义任务处理器\"><a href=\"#定义任务处理器\" class=\"headerlink\" title=\"定义任务处理器\"></a>定义任务处理器</h3><h4 id=\"定义任务行为\"><a href=\"#定义任务行为\" class=\"headerlink\" title=\"定义任务行为\"></a>定义任务行为</h4><p>当执行的任务为异步方法的时候，需要再方法最后调用done()<br>如果为同步方法，则省略声明done</p>\n<p>影响任务行为的参数：</p>\n<ul>\n<li>concurrency 指定最大任务并发数</li>\n<li>lockLifetime 锁生存时间,指定异步调用时最长等待时间</li>\n<li>priority 优先级(lowest|low|normal|high|highest|number)</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 执行任务为异步方法</span><br><span class=\"line\">agenda.define(&apos;job_name&apos;, function(job, done) &#123;</span><br><span class=\"line\">    doSomething(function() &#123;</span><br><span class=\"line\">        done();</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">// 执行任务为同步方法</span><br><span class=\"line\">agenda.define(&apos;say hello&apos;, function(job) &#123;</span><br><span class=\"line\">  console.log(&quot;Hello!&quot;);</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<h4 id=\"定时任务\"><a href=\"#定时任务\" class=\"headerlink\" title=\"定时任务\"></a>定时任务</h4><p>指定任务重复的规制,支持数字, cron表达式, 甚至如10 minutes等可读性较高的表达式</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">job.repeatEvery(&apos;10 minutes&apos;);</span><br><span class=\"line\">job.repeatEvery(&apos;*/10 * * * * * *&apos;);</span><br></pre></td></tr></table></figure>\n<p>指定特定的重复时间</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 每天15:30</span><br><span class=\"line\">job.repeatAt(&apos;3:30pm&apos;);</span><br></pre></td></tr></table></figure>\n<p>指定只执行一次的的任务</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">job.schedule(&apos;3:30pm&apos;);</span><br></pre></td></tr></table></figure>\n<p>now<br>马上执行某事件<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">agenda.now(&apos;do the hokey pokey&apos;);</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"<p><a href=\"https://github.com/rschmukler/agenda\" target=\"_blank\" rel=\"noopener\">Agenda</a>是类似Quarzt的轻量级持久化任务调度框架, 数据存储再mongodb上, 部署与学习十分简单.<br>第三方开发者还为Agenda提供了一个简易的UI界面 <a href=\"https://github.com/moudy/agenda-ui\" target=\"_blank\" rel=\"noopener\">Agenda UI</a>. 提供简单的可视化界面.</p>","more":"<h3 id=\"Base\"><a href=\"#Base\" class=\"headerlink\" title=\"Base\"></a>Base</h3><p>Agenda 将任务对象保存再mongo里面, 任务对象包含任务的name, 附带数据, 定时规则等.<br>我们可以动态对任务进行CRUD操作. Agenda提供对应API.</p>\n<p>虽然Agenda本身提供的对Job的操作比较简单, 但因为Agenda的Job都是存储再mongo之中,所以我们可以通过直接操作monogo实现的Job的更新与删除.</p>\n<h3 id=\"Start\"><a href=\"#Start\" class=\"headerlink\" title=\"Start\"></a>Start</h3><p>简单的添加任务操作:<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">var job = agenda.create(&apos;testJob&apos;, &#123;key: &quot;value&quot;&#125;);</span><br><span class=\"line\">job.repeatEvery(&apos;5 seconds&apos;);</span><br><span class=\"line\">job.save(function(err) &#123;</span><br><span class=\"line\">    console.log(&quot;Job successfully saved&quot;);</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure></p>\n<p>程序开始时,我们需要创建agenda对象,指定事件响应函数,并开始执行任务调用.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">var agenda = new Agenda(&#123;db: &#123; address: &apos;localhost:27017/agenda-example&apos;&#125;);</span><br><span class=\"line\">agenda.define(&apos;testJob&apos;,  function(job) &#123;</span><br><span class=\"line\">    console.log(&quot;Job execute, now is &quot; + new Date()  + &quot; Data=&quot; + JSON.stringify(job.attrs.data));</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">agenda.run();</span><br></pre></td></tr></table></figure>\n<h4 id=\"数据存储\"><a href=\"#数据存储\" class=\"headerlink\" title=\"数据存储\"></a>数据存储</h4><p>Agenda使用mongodb。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 指定使用的mongodb，默认使用agendaJobs集合</span><br><span class=\"line\">var agenda = new Agenda(&#123;db: &#123; address: &apos;localhost:27017/agenda-example&apos;&#125;&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">// 如果需要指定其他集合</span><br><span class=\"line\">var agenda = new Agenda(&#123;db: &#123; address: &apos;localhost:27017/agenda-test&apos;, collection: &apos;agendaJobs&apos; &#125;&#125;);</span><br></pre></td></tr></table></figure>\n<h4 id=\"指定循环规制\"><a href=\"#指定循环规制\" class=\"headerlink\" title=\"指定循环规制\"></a>指定循环规制</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 直接构造的agenda对象的时候指定</span><br><span class=\"line\">var agenda = new Agenda(&#123;processEvery: &apos;1 minute&apos;&#125;);</span><br><span class=\"line\">// 1分钟循环一次</span><br><span class=\"line\">agenda.processEvery(&apos;1 minute&apos;);</span><br></pre></td></tr></table></figure>\n<h4 id=\"指定任务最大并发数\"><a href=\"#指定任务最大并发数\" class=\"headerlink\" title=\"指定任务最大并发数\"></a>指定任务最大并发数</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 构造时指定</span><br><span class=\"line\">var agenda = new Agenda(&#123;maxConcurrency: 20&#125;);</span><br><span class=\"line\">// 直接指定</span><br><span class=\"line\">agenda.maxConcurrency(20);</span><br></pre></td></tr></table></figure>\n<h4 id=\"指定默认并发数\"><a href=\"#指定默认并发数\" class=\"headerlink\" title=\"指定默认并发数\"></a>指定默认并发数</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 构造时指定</span><br><span class=\"line\">agenda.defaultConcurrency(5);</span><br><span class=\"line\">// 直接指定</span><br><span class=\"line\">var agenda = new Agenda(&#123;defaultConcurrency: 5&#125;);</span><br></pre></td></tr></table></figure>\n<h4 id=\"设置任务最大响应时间\"><a href=\"#设置任务最大响应时间\" class=\"headerlink\" title=\"设置任务最大响应时间\"></a>设置任务最大响应时间</h4><p>指定任务从开始执行到调用finish的时间（指调用done函数），这能有效的解决任务奔溃或者超时</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 构造时指定</span><br><span class=\"line\">var agenda = new Agenda(&#123;defaultLockLifetime: 10000&#125;);</span><br><span class=\"line\">// 直接指定</span><br><span class=\"line\">agenda.defaultLockLifetime(10000);</span><br></pre></td></tr></table></figure>\n<h3 id=\"定义任务处理器\"><a href=\"#定义任务处理器\" class=\"headerlink\" title=\"定义任务处理器\"></a>定义任务处理器</h3><h4 id=\"定义任务行为\"><a href=\"#定义任务行为\" class=\"headerlink\" title=\"定义任务行为\"></a>定义任务行为</h4><p>当执行的任务为异步方法的时候，需要再方法最后调用done()<br>如果为同步方法，则省略声明done</p>\n<p>影响任务行为的参数：</p>\n<ul>\n<li>concurrency 指定最大任务并发数</li>\n<li>lockLifetime 锁生存时间,指定异步调用时最长等待时间</li>\n<li>priority 优先级(lowest|low|normal|high|highest|number)</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 执行任务为异步方法</span><br><span class=\"line\">agenda.define(&apos;job_name&apos;, function(job, done) &#123;</span><br><span class=\"line\">    doSomething(function() &#123;</span><br><span class=\"line\">        done();</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">// 执行任务为同步方法</span><br><span class=\"line\">agenda.define(&apos;say hello&apos;, function(job) &#123;</span><br><span class=\"line\">  console.log(&quot;Hello!&quot;);</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<h4 id=\"定时任务\"><a href=\"#定时任务\" class=\"headerlink\" title=\"定时任务\"></a>定时任务</h4><p>指定任务重复的规制,支持数字, cron表达式, 甚至如10 minutes等可读性较高的表达式</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">job.repeatEvery(&apos;10 minutes&apos;);</span><br><span class=\"line\">job.repeatEvery(&apos;*/10 * * * * * *&apos;);</span><br></pre></td></tr></table></figure>\n<p>指定特定的重复时间</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// 每天15:30</span><br><span class=\"line\">job.repeatAt(&apos;3:30pm&apos;);</span><br></pre></td></tr></table></figure>\n<p>指定只执行一次的的任务</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">job.schedule(&apos;3:30pm&apos;);</span><br></pre></td></tr></table></figure>\n<p>now<br>马上执行某事件<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">agenda.now(&apos;do the hokey pokey&apos;);</span><br></pre></td></tr></table></figure></p>"},{"layout":"post","title":"Android 封装SDK时常用的注解","date":"2015-07-06T16:00:00.000Z","_content":"\n工作中，我们经常需要将功能模块封装成库供合作厂商调用， 如何写好一个健壮的Android Library有很多讲究，使用注解可以对SDK暴露给开发者的接口做出一些限制，从而尽可能地避免开发者错误地使用API。 下面我们介绍几种封装SDK时常用到的注解。\n\n<!-- more -->\n\n### IntDef与StringDef\n\n我们有时候会使用int常量或者String常量来代替枚举， 特别在你编写SDK的时候，你可以通过IntDef或者StringDef来限制接口可接受的参数。  \n\n比如，有一个 `disableChannel`的接口，用来关闭指定的`channel` 。 我们可以先定义自己的注解`@RequirePayChannel`\n\n``` java\npublic static final int CHANNEL_UNIONPAY = 0x11000;\npublic static final int CHANNEL_ALIPAY = 0x12000;\npublic static final int CHANNEL_WECHAT = 0x13000;\n\n@Retention(RetentionPolicy.SOURCE)\n@IntDef({CHANNEL_UNIONPAY,CHANNEL_ALIPAY,CHANNEL_WECHAT})\npublic @interface RequirePayChannel {}\n```\n\n这样，你便可以通过`@RequirePayChannel`来指定disableChannel()的可接受参数\n\n``` java\npublic void enableChannel(@RequirePayChannel int channel) {\n\t// do something\n}\n```\n\n这样，一些IDE还会自动提供给你建议参数。如果填入指点范围之外的参数，将会出现错误提示并无法编译通过。\n![错误提示2][2]\n值得一说的是， 在这里，我们使用到了`@Retention(RetentionPolicy.SOURCE)`。 它指定了编译器在处理Animation时候的处理方法。 默认编译器会将常量替换成对应的数值，如果没指定该注解，你编译完成后将得到这样的class文件:\n\n![反编译RequirePayChannel][1]\n\n这样会导致IDE不能提示到有意义的信息。并且一定要指定为特定的int数值，否则也无法编译通过。\n![错误提示3][3]\n所以，应该指定`Retention`让编译器不对该注解做额外的优化处理。\n\n### DrawableRes, StringRes 与 DimenRes\n\n当我们在编写指定资源文件的接口时，可以通过资源注解来指定该方法接受的资源类型。 指定错误的资源将不能编译通过。 下面代码中，我们使用`@DrawableRes`来表明`setLogo`方法只支持Drawable资源的ID。\n\n```java\npublic void setLogo(@DrawableRes int resurceId) {\n    // do something\n}\n\n```\n当我们提供错误的资源，IDE将会报错。\n![错误提示4][4]  \n\n`@StringRes` 与 `@DimenRes` 的使用方法也类似。\n\n### NonNull 与 Nullable\n\n将一个空值传入一个方法中可能引发潜在的Crash。 我们应该极力避免这种情况， @NonNull 可以指定参数是否接受空值，当我们传入一个空值的时候，IDE会给出响应的警告。 我们可以这样使用它：\n\n```java\npublic void setContext(@NonNull Context context) {\n    // do something\n}\n```\n当我们对其传入一个空值的时候，将会显示警告（但代码仍然能通过编译）\n![错误提示5][5]  \n\n`@Nullable` 用于修饰参数或者方法的返回值可能为空，提醒开发者主要空值检查。\n\n```\n@Nullable\npublic Context getContext() {return null;}\n```\n\n![错误提示6][6]  \n\n\n\n\n[1]: http://7jpp6b.com1.z0.glb.clouddn.com/blog/int_def_anination_class.png\n[2]: http://7jpp6b.com1.z0.glb.clouddn.com/blog/int_def_error_tip.png\n[3]: http://7jpp6b.com1.z0.glb.clouddn.com/blog/int_def_error_tip2.png\n[4]: http://7jpp6b.com1.z0.glb.clouddn.com/blog/drawable_res_error_tip.png\n[5]: http://7jpp6b.com1.z0.glb.clouddn.com/blog/non_null_waring_tip.png\n[6]: http://7jpp6b.com1.z0.glb.clouddn.com/blog/nullable_waring_tip.png\n","source":"_posts/android-annotations-start.md","raw":"---\nlayout: post\ntitle: \"Android 封装SDK时常用的注解\"\ndate: 2015-07-07\ncategories:\n- android\ntags:\n- android\n\n---\n\n工作中，我们经常需要将功能模块封装成库供合作厂商调用， 如何写好一个健壮的Android Library有很多讲究，使用注解可以对SDK暴露给开发者的接口做出一些限制，从而尽可能地避免开发者错误地使用API。 下面我们介绍几种封装SDK时常用到的注解。\n\n<!-- more -->\n\n### IntDef与StringDef\n\n我们有时候会使用int常量或者String常量来代替枚举， 特别在你编写SDK的时候，你可以通过IntDef或者StringDef来限制接口可接受的参数。  \n\n比如，有一个 `disableChannel`的接口，用来关闭指定的`channel` 。 我们可以先定义自己的注解`@RequirePayChannel`\n\n``` java\npublic static final int CHANNEL_UNIONPAY = 0x11000;\npublic static final int CHANNEL_ALIPAY = 0x12000;\npublic static final int CHANNEL_WECHAT = 0x13000;\n\n@Retention(RetentionPolicy.SOURCE)\n@IntDef({CHANNEL_UNIONPAY,CHANNEL_ALIPAY,CHANNEL_WECHAT})\npublic @interface RequirePayChannel {}\n```\n\n这样，你便可以通过`@RequirePayChannel`来指定disableChannel()的可接受参数\n\n``` java\npublic void enableChannel(@RequirePayChannel int channel) {\n\t// do something\n}\n```\n\n这样，一些IDE还会自动提供给你建议参数。如果填入指点范围之外的参数，将会出现错误提示并无法编译通过。\n![错误提示2][2]\n值得一说的是， 在这里，我们使用到了`@Retention(RetentionPolicy.SOURCE)`。 它指定了编译器在处理Animation时候的处理方法。 默认编译器会将常量替换成对应的数值，如果没指定该注解，你编译完成后将得到这样的class文件:\n\n![反编译RequirePayChannel][1]\n\n这样会导致IDE不能提示到有意义的信息。并且一定要指定为特定的int数值，否则也无法编译通过。\n![错误提示3][3]\n所以，应该指定`Retention`让编译器不对该注解做额外的优化处理。\n\n### DrawableRes, StringRes 与 DimenRes\n\n当我们在编写指定资源文件的接口时，可以通过资源注解来指定该方法接受的资源类型。 指定错误的资源将不能编译通过。 下面代码中，我们使用`@DrawableRes`来表明`setLogo`方法只支持Drawable资源的ID。\n\n```java\npublic void setLogo(@DrawableRes int resurceId) {\n    // do something\n}\n\n```\n当我们提供错误的资源，IDE将会报错。\n![错误提示4][4]  \n\n`@StringRes` 与 `@DimenRes` 的使用方法也类似。\n\n### NonNull 与 Nullable\n\n将一个空值传入一个方法中可能引发潜在的Crash。 我们应该极力避免这种情况， @NonNull 可以指定参数是否接受空值，当我们传入一个空值的时候，IDE会给出响应的警告。 我们可以这样使用它：\n\n```java\npublic void setContext(@NonNull Context context) {\n    // do something\n}\n```\n当我们对其传入一个空值的时候，将会显示警告（但代码仍然能通过编译）\n![错误提示5][5]  \n\n`@Nullable` 用于修饰参数或者方法的返回值可能为空，提醒开发者主要空值检查。\n\n```\n@Nullable\npublic Context getContext() {return null;}\n```\n\n![错误提示6][6]  \n\n\n\n\n[1]: http://7jpp6b.com1.z0.glb.clouddn.com/blog/int_def_anination_class.png\n[2]: http://7jpp6b.com1.z0.glb.clouddn.com/blog/int_def_error_tip.png\n[3]: http://7jpp6b.com1.z0.glb.clouddn.com/blog/int_def_error_tip2.png\n[4]: http://7jpp6b.com1.z0.glb.clouddn.com/blog/drawable_res_error_tip.png\n[5]: http://7jpp6b.com1.z0.glb.clouddn.com/blog/non_null_waring_tip.png\n[6]: http://7jpp6b.com1.z0.glb.clouddn.com/blog/nullable_waring_tip.png\n","slug":"android-annotations-start","published":1,"updated":"2018-10-11T17:47:50.624Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44c0005l9394xox6043","content":"<p>工作中，我们经常需要将功能模块封装成库供合作厂商调用， 如何写好一个健壮的Android Library有很多讲究，使用注解可以对SDK暴露给开发者的接口做出一些限制，从而尽可能地避免开发者错误地使用API。 下面我们介绍几种封装SDK时常用到的注解。</p>\n<a id=\"more\"></a>\n<h3 id=\"IntDef与StringDef\"><a href=\"#IntDef与StringDef\" class=\"headerlink\" title=\"IntDef与StringDef\"></a>IntDef与StringDef</h3><p>我们有时候会使用int常量或者String常量来代替枚举， 特别在你编写SDK的时候，你可以通过IntDef或者StringDef来限制接口可接受的参数。  </p>\n<p>比如，有一个 <code>disableChannel</code>的接口，用来关闭指定的<code>channel</code> 。 我们可以先定义自己的注解<code>@RequirePayChannel</code></p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> CHANNEL_UNIONPAY = <span class=\"number\">0x11000</span>;</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> CHANNEL_ALIPAY = <span class=\"number\">0x12000</span>;</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> CHANNEL_WECHAT = <span class=\"number\">0x13000</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Retention</span>(RetentionPolicy.SOURCE)</span><br><span class=\"line\"><span class=\"meta\">@IntDef</span>(&#123;CHANNEL_UNIONPAY,CHANNEL_ALIPAY,CHANNEL_WECHAT&#125;)</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"meta\">@interface</span> RequirePayChannel &#123;&#125;</span><br></pre></td></tr></table></figure>\n<p>这样，你便可以通过<code>@RequirePayChannel</code>来指定disableChannel()的可接受参数</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">enableChannel</span><span class=\"params\">(@RequirePayChannel <span class=\"keyword\">int</span> channel)</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"comment\">// do something</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这样，一些IDE还会自动提供给你建议参数。如果填入指点范围之外的参数，将会出现错误提示并无法编译通过。<br><img src=\"http://7jpp6b.com1.z0.glb.clouddn.com/blog/int_def_error_tip.png\" alt=\"错误提示2\"><br>值得一说的是， 在这里，我们使用到了<code>@Retention(RetentionPolicy.SOURCE)</code>。 它指定了编译器在处理Animation时候的处理方法。 默认编译器会将常量替换成对应的数值，如果没指定该注解，你编译完成后将得到这样的class文件:</p>\n<p><img src=\"http://7jpp6b.com1.z0.glb.clouddn.com/blog/int_def_anination_class.png\" alt=\"反编译RequirePayChannel\"></p>\n<p>这样会导致IDE不能提示到有意义的信息。并且一定要指定为特定的int数值，否则也无法编译通过。<br><img src=\"http://7jpp6b.com1.z0.glb.clouddn.com/blog/int_def_error_tip2.png\" alt=\"错误提示3\"><br>所以，应该指定<code>Retention</code>让编译器不对该注解做额外的优化处理。</p>\n<h3 id=\"DrawableRes-StringRes-与-DimenRes\"><a href=\"#DrawableRes-StringRes-与-DimenRes\" class=\"headerlink\" title=\"DrawableRes, StringRes 与 DimenRes\"></a>DrawableRes, StringRes 与 DimenRes</h3><p>当我们在编写指定资源文件的接口时，可以通过资源注解来指定该方法接受的资源类型。 指定错误的资源将不能编译通过。 下面代码中，我们使用<code>@DrawableRes</code>来表明<code>setLogo</code>方法只支持Drawable资源的ID。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setLogo</span><span class=\"params\">(@DrawableRes <span class=\"keyword\">int</span> resurceId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// do something</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>当我们提供错误的资源，IDE将会报错。<br><img src=\"http://7jpp6b.com1.z0.glb.clouddn.com/blog/drawable_res_error_tip.png\" alt=\"错误提示4\">  </p>\n<p><code>@StringRes</code> 与 <code>@DimenRes</code> 的使用方法也类似。</p>\n<h3 id=\"NonNull-与-Nullable\"><a href=\"#NonNull-与-Nullable\" class=\"headerlink\" title=\"NonNull 与 Nullable\"></a>NonNull 与 Nullable</h3><p>将一个空值传入一个方法中可能引发潜在的Crash。 我们应该极力避免这种情况， @NonNull 可以指定参数是否接受空值，当我们传入一个空值的时候，IDE会给出响应的警告。 我们可以这样使用它：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setContext</span><span class=\"params\">(@NonNull Context context)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// do something</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>当我们对其传入一个空值的时候，将会显示警告（但代码仍然能通过编译）<br><img src=\"http://7jpp6b.com1.z0.glb.clouddn.com/blog/non_null_waring_tip.png\" alt=\"错误提示5\">  </p>\n<p><code>@Nullable</code> 用于修饰参数或者方法的返回值可能为空，提醒开发者主要空值检查。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">@Nullable</span><br><span class=\"line\">public Context getContext() &#123;return null;&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://7jpp6b.com1.z0.glb.clouddn.com/blog/nullable_waring_tip.png\" alt=\"错误提示6\">  </p>\n","site":{"data":{}},"excerpt":"<p>工作中，我们经常需要将功能模块封装成库供合作厂商调用， 如何写好一个健壮的Android Library有很多讲究，使用注解可以对SDK暴露给开发者的接口做出一些限制，从而尽可能地避免开发者错误地使用API。 下面我们介绍几种封装SDK时常用到的注解。</p>","more":"<h3 id=\"IntDef与StringDef\"><a href=\"#IntDef与StringDef\" class=\"headerlink\" title=\"IntDef与StringDef\"></a>IntDef与StringDef</h3><p>我们有时候会使用int常量或者String常量来代替枚举， 特别在你编写SDK的时候，你可以通过IntDef或者StringDef来限制接口可接受的参数。  </p>\n<p>比如，有一个 <code>disableChannel</code>的接口，用来关闭指定的<code>channel</code> 。 我们可以先定义自己的注解<code>@RequirePayChannel</code></p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> CHANNEL_UNIONPAY = <span class=\"number\">0x11000</span>;</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> CHANNEL_ALIPAY = <span class=\"number\">0x12000</span>;</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> CHANNEL_WECHAT = <span class=\"number\">0x13000</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@Retention</span>(RetentionPolicy.SOURCE)</span><br><span class=\"line\"><span class=\"meta\">@IntDef</span>(&#123;CHANNEL_UNIONPAY,CHANNEL_ALIPAY,CHANNEL_WECHAT&#125;)</span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"meta\">@interface</span> RequirePayChannel &#123;&#125;</span><br></pre></td></tr></table></figure>\n<p>这样，你便可以通过<code>@RequirePayChannel</code>来指定disableChannel()的可接受参数</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">enableChannel</span><span class=\"params\">(@RequirePayChannel <span class=\"keyword\">int</span> channel)</span> </span>&#123;</span><br><span class=\"line\">\t<span class=\"comment\">// do something</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这样，一些IDE还会自动提供给你建议参数。如果填入指点范围之外的参数，将会出现错误提示并无法编译通过。<br><img src=\"http://7jpp6b.com1.z0.glb.clouddn.com/blog/int_def_error_tip.png\" alt=\"错误提示2\"><br>值得一说的是， 在这里，我们使用到了<code>@Retention(RetentionPolicy.SOURCE)</code>。 它指定了编译器在处理Animation时候的处理方法。 默认编译器会将常量替换成对应的数值，如果没指定该注解，你编译完成后将得到这样的class文件:</p>\n<p><img src=\"http://7jpp6b.com1.z0.glb.clouddn.com/blog/int_def_anination_class.png\" alt=\"反编译RequirePayChannel\"></p>\n<p>这样会导致IDE不能提示到有意义的信息。并且一定要指定为特定的int数值，否则也无法编译通过。<br><img src=\"http://7jpp6b.com1.z0.glb.clouddn.com/blog/int_def_error_tip2.png\" alt=\"错误提示3\"><br>所以，应该指定<code>Retention</code>让编译器不对该注解做额外的优化处理。</p>\n<h3 id=\"DrawableRes-StringRes-与-DimenRes\"><a href=\"#DrawableRes-StringRes-与-DimenRes\" class=\"headerlink\" title=\"DrawableRes, StringRes 与 DimenRes\"></a>DrawableRes, StringRes 与 DimenRes</h3><p>当我们在编写指定资源文件的接口时，可以通过资源注解来指定该方法接受的资源类型。 指定错误的资源将不能编译通过。 下面代码中，我们使用<code>@DrawableRes</code>来表明<code>setLogo</code>方法只支持Drawable资源的ID。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setLogo</span><span class=\"params\">(@DrawableRes <span class=\"keyword\">int</span> resurceId)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// do something</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>当我们提供错误的资源，IDE将会报错。<br><img src=\"http://7jpp6b.com1.z0.glb.clouddn.com/blog/drawable_res_error_tip.png\" alt=\"错误提示4\">  </p>\n<p><code>@StringRes</code> 与 <code>@DimenRes</code> 的使用方法也类似。</p>\n<h3 id=\"NonNull-与-Nullable\"><a href=\"#NonNull-与-Nullable\" class=\"headerlink\" title=\"NonNull 与 Nullable\"></a>NonNull 与 Nullable</h3><p>将一个空值传入一个方法中可能引发潜在的Crash。 我们应该极力避免这种情况， @NonNull 可以指定参数是否接受空值，当我们传入一个空值的时候，IDE会给出响应的警告。 我们可以这样使用它：</p>\n<figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">setContext</span><span class=\"params\">(@NonNull Context context)</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// do something</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>当我们对其传入一个空值的时候，将会显示警告（但代码仍然能通过编译）<br><img src=\"http://7jpp6b.com1.z0.glb.clouddn.com/blog/non_null_waring_tip.png\" alt=\"错误提示5\">  </p>\n<p><code>@Nullable</code> 用于修饰参数或者方法的返回值可能为空，提醒开发者主要空值检查。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">@Nullable</span><br><span class=\"line\">public Context getContext() &#123;return null;&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://7jpp6b.com1.z0.glb.clouddn.com/blog/nullable_waring_tip.png\" alt=\"错误提示6\">  </p>"},{"layout":"post","title":"ELK实战 - 利用Nginx日志分析API耗时","date":"2017-04-08T16:00:00.000Z","_content":"\n\n本篇主要介绍如何利用ELK分析Nginx日志，统计出API的耗时数据\n\nELK是ElasticSearch，Logstash，Kibana的简称，但我觉得这个名字已经过时了，现在叫ELKB更合适，因为Elastic家族近期迎来了一位新成员Beats，专职做数据采集工作。\n\n我们先来介绍下ELK的整体架构吧。\n\n<!-- more -->\n\n早些时候，ELK的流水线是这样\n\n```\nRaw Logs(原始日志数据) -> Logstash(数据采集与解析) -> ElasticSearch(数据存储) -> Kibana(数据展示)\n```\n\n但是该模式有一个小缺陷是Logstash，主要因为Logstash是使用Java编写的，本身启动需要JVM资源，并且在宿主机上进行日志采集并分析必然会消耗资源。\n\n后来，Elastic使用Go写了一个专门用于数据采集的工具集[Beats](https://www.elastic.co/products/beats)，其包括:\n\n现在，ELKB的流水线编程这样\n\n```\nRaw Logs(原始日志数据) -> Beats(数据采集) -> Logstash(数据解析) -> ElasticSearch(数据存储) -> Kibana(数据展示)\n```\n\n在此之前，我们先搭建好ElasticSearch与Kibana，ELK家族的有一个优良传统，就是开箱即用。网上也有很多文章详细的讲述了ELK的安装细节，所以，本文就不在安装细节方面赘述，具体的安装细节，可以参考官方文档: \n\n* [ElasticSearch 安装](https://www.elastic.co/guide/en/elasticsearch/reference/current/_installation.html)\n* [Kibana 安装](https://www.elastic.co/guide/en/kibana/current/targz.html)\n\n\n\n### Configure Filebeat \n\n我们直接进入正题，如何使用ELK来分析Nginx日志，并绘制API响应耗时的图表。\n\n首先我们看一下Nginx的日志打印设置\n\n```\nlog_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" $status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\" \"$request_time\" \"$host\" '\n                      '\"$upstream_status\" \"$upstream_addr\" \"$upstream_response_time\"' ;\n```\n\n默认情况下，我们将不同业务的Nginx访问日志写入到不同的文件里面，在我的系统里，Nginx日志被保存在`/usr/local/nginx/logs/api_acess.log`中。\n\n我们在这里，使用Beats工具中的FileBeats来收集日志Nginx日志\n\n```\nfilebeat:\n  prospectors:\n    -\n      paths:\n        - /usr/local/nginx/logs/api_acess.log\n      input_type: log\n\noutput:\n\n  logstash:\n    hosts: [\"192.168.248.216:5045\", \"192.168.248.217:5045\"]\n    loadbalance: true\n    index: <your service index>\n\nlogging:\n  files:\n    rotateeverybytes: 10485760 # = 10MB\n```\n\n以上配置文件主要是读取`/usr/local/nginx/logs/api_acess.log`的日志，并写入对应LogStash提供的TCP接口中。具体Filebeat的详细使用文档，可以参考（//TODO 文档链接）\n\n\n### Configure Logstash\n\n接下来，我们需要启动对应的LogStash服务，它主要提供以下两个功能：\n\n1. 提供5044接口给Filebeat做文件写入\n2. 解析Nginx日志，提取需要的数据结构并写入ElasticSearch\n\n```\ninput {\n  beats {\n    port => 5044\n  }\n}\n\nfilter {\n  grok {\n    patterns_dir => [\"/opt/push/logstash/patterns\"]\n    match => { 'message' => '%{IPORHOST:clientip} - %{APPKEY:appkey} \\[%{HTTPDATE:timestamp}\\] \"%{HTTPMETHOD:method} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\" %{NUMBER:http_status} %{NUMBER:response_size} %{QS:http_referer} %{QS:user_agent} %{QS:x_forwarded_for} \"%{BASE10NUM:request_time}\" \"%{HOST:request_host}\"  %{BASE10NUM:upstream_header_time} %{NUMBER:upstream_response_time:float} %{HOST:upstream_addr}:%{NUMBER:upstream_port}' }\n  }\n}\n\noutput {\n    elasticsearch {\n        hosts => [\"172.16.99.xxx:1xxxx\"]\n        manage_template => false\n        index => \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\"\n        document_type => \"%{[@metadata][type]}\"\n        flush_size => 20000\n        idle_flush_time => 10\n    }\n}\n```\n\n这里我们利用到了gork表达式。 他是Elastic公司设计专门用来解析日志的工具，具体[Gork简易入门](http://xiezefan.me/2017/04/09/elk_in_action_grok_start/)。\n\n简单说，gork表达式可以方便的组合正则表达式，提取出日志的相关数据，最终转变成JSON格式输出。以下是我专门为以上Nginx日志结构写的Gork表达式，我们可以使用Gork Debuger工具来帮我们校验Gork表达式的正确性。\n\nGork表达式需要一定的学习成本，但有了它，我们可以更方便快捷地分析日志。\n\n接下来，依次启动LagStash与FileBeat。 我们先认为的制造一点日志输出，可以看到在ElasicSearch中已经出现了响应的索引。\n\n### Configure Kibana\n\n我们在Kibana中建立该索引，可以看到，日志的关键数据已经成功被提取并存入到ElasticSearch。接下来，我们将利用Kibana来统计报表。\n\n![](http://res.xiezefan.me/images/blog/elk_in_action_kibana_chart)\n\n\n在Kibana绘制图标本身什么技术难度，关键一点是在将数据写入ElasticSearch中的时候，需要将一些关键指标转换成数值类型，我们可以在Grok转换的时候，指定生成Number类型，或者之间预定义相关业务的ElasticSearch Mapping Template。\n\n有一些绘图小技巧接下来准备独立整理一篇文章做单独分享。\n\n\n\n","source":"_posts/elk_in_action_analyze_nginx_logs.md","raw":"---\nlayout: post\ntitle: \"ELK实战 - 利用Nginx日志分析API耗时\"\ndate: 2017-04-09\ncategories:\n- elk\ntags:\n- elk\n- gork\n\n---\n\n\n本篇主要介绍如何利用ELK分析Nginx日志，统计出API的耗时数据\n\nELK是ElasticSearch，Logstash，Kibana的简称，但我觉得这个名字已经过时了，现在叫ELKB更合适，因为Elastic家族近期迎来了一位新成员Beats，专职做数据采集工作。\n\n我们先来介绍下ELK的整体架构吧。\n\n<!-- more -->\n\n早些时候，ELK的流水线是这样\n\n```\nRaw Logs(原始日志数据) -> Logstash(数据采集与解析) -> ElasticSearch(数据存储) -> Kibana(数据展示)\n```\n\n但是该模式有一个小缺陷是Logstash，主要因为Logstash是使用Java编写的，本身启动需要JVM资源，并且在宿主机上进行日志采集并分析必然会消耗资源。\n\n后来，Elastic使用Go写了一个专门用于数据采集的工具集[Beats](https://www.elastic.co/products/beats)，其包括:\n\n现在，ELKB的流水线编程这样\n\n```\nRaw Logs(原始日志数据) -> Beats(数据采集) -> Logstash(数据解析) -> ElasticSearch(数据存储) -> Kibana(数据展示)\n```\n\n在此之前，我们先搭建好ElasticSearch与Kibana，ELK家族的有一个优良传统，就是开箱即用。网上也有很多文章详细的讲述了ELK的安装细节，所以，本文就不在安装细节方面赘述，具体的安装细节，可以参考官方文档: \n\n* [ElasticSearch 安装](https://www.elastic.co/guide/en/elasticsearch/reference/current/_installation.html)\n* [Kibana 安装](https://www.elastic.co/guide/en/kibana/current/targz.html)\n\n\n\n### Configure Filebeat \n\n我们直接进入正题，如何使用ELK来分析Nginx日志，并绘制API响应耗时的图表。\n\n首先我们看一下Nginx的日志打印设置\n\n```\nlog_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" $status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\" \"$request_time\" \"$host\" '\n                      '\"$upstream_status\" \"$upstream_addr\" \"$upstream_response_time\"' ;\n```\n\n默认情况下，我们将不同业务的Nginx访问日志写入到不同的文件里面，在我的系统里，Nginx日志被保存在`/usr/local/nginx/logs/api_acess.log`中。\n\n我们在这里，使用Beats工具中的FileBeats来收集日志Nginx日志\n\n```\nfilebeat:\n  prospectors:\n    -\n      paths:\n        - /usr/local/nginx/logs/api_acess.log\n      input_type: log\n\noutput:\n\n  logstash:\n    hosts: [\"192.168.248.216:5045\", \"192.168.248.217:5045\"]\n    loadbalance: true\n    index: <your service index>\n\nlogging:\n  files:\n    rotateeverybytes: 10485760 # = 10MB\n```\n\n以上配置文件主要是读取`/usr/local/nginx/logs/api_acess.log`的日志，并写入对应LogStash提供的TCP接口中。具体Filebeat的详细使用文档，可以参考（//TODO 文档链接）\n\n\n### Configure Logstash\n\n接下来，我们需要启动对应的LogStash服务，它主要提供以下两个功能：\n\n1. 提供5044接口给Filebeat做文件写入\n2. 解析Nginx日志，提取需要的数据结构并写入ElasticSearch\n\n```\ninput {\n  beats {\n    port => 5044\n  }\n}\n\nfilter {\n  grok {\n    patterns_dir => [\"/opt/push/logstash/patterns\"]\n    match => { 'message' => '%{IPORHOST:clientip} - %{APPKEY:appkey} \\[%{HTTPDATE:timestamp}\\] \"%{HTTPMETHOD:method} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\" %{NUMBER:http_status} %{NUMBER:response_size} %{QS:http_referer} %{QS:user_agent} %{QS:x_forwarded_for} \"%{BASE10NUM:request_time}\" \"%{HOST:request_host}\"  %{BASE10NUM:upstream_header_time} %{NUMBER:upstream_response_time:float} %{HOST:upstream_addr}:%{NUMBER:upstream_port}' }\n  }\n}\n\noutput {\n    elasticsearch {\n        hosts => [\"172.16.99.xxx:1xxxx\"]\n        manage_template => false\n        index => \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\"\n        document_type => \"%{[@metadata][type]}\"\n        flush_size => 20000\n        idle_flush_time => 10\n    }\n}\n```\n\n这里我们利用到了gork表达式。 他是Elastic公司设计专门用来解析日志的工具，具体[Gork简易入门](http://xiezefan.me/2017/04/09/elk_in_action_grok_start/)。\n\n简单说，gork表达式可以方便的组合正则表达式，提取出日志的相关数据，最终转变成JSON格式输出。以下是我专门为以上Nginx日志结构写的Gork表达式，我们可以使用Gork Debuger工具来帮我们校验Gork表达式的正确性。\n\nGork表达式需要一定的学习成本，但有了它，我们可以更方便快捷地分析日志。\n\n接下来，依次启动LagStash与FileBeat。 我们先认为的制造一点日志输出，可以看到在ElasicSearch中已经出现了响应的索引。\n\n### Configure Kibana\n\n我们在Kibana中建立该索引，可以看到，日志的关键数据已经成功被提取并存入到ElasticSearch。接下来，我们将利用Kibana来统计报表。\n\n![](http://res.xiezefan.me/images/blog/elk_in_action_kibana_chart)\n\n\n在Kibana绘制图标本身什么技术难度，关键一点是在将数据写入ElasticSearch中的时候，需要将一些关键指标转换成数值类型，我们可以在Grok转换的时候，指定生成Number类型，或者之间预定义相关业务的ElasticSearch Mapping Template。\n\n有一些绘图小技巧接下来准备独立整理一篇文章做单独分享。\n\n\n\n","slug":"elk_in_action_analyze_nginx_logs","published":1,"updated":"2018-10-12T02:09:57.708Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44d0006l939drfbjx0a","content":"<p>本篇主要介绍如何利用ELK分析Nginx日志，统计出API的耗时数据</p>\n<p>ELK是ElasticSearch，Logstash，Kibana的简称，但我觉得这个名字已经过时了，现在叫ELKB更合适，因为Elastic家族近期迎来了一位新成员Beats，专职做数据采集工作。</p>\n<p>我们先来介绍下ELK的整体架构吧。</p>\n<a id=\"more\"></a>\n<p>早些时候，ELK的流水线是这样</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Raw Logs(原始日志数据) -&gt; Logstash(数据采集与解析) -&gt; ElasticSearch(数据存储) -&gt; Kibana(数据展示)</span><br></pre></td></tr></table></figure>\n<p>但是该模式有一个小缺陷是Logstash，主要因为Logstash是使用Java编写的，本身启动需要JVM资源，并且在宿主机上进行日志采集并分析必然会消耗资源。</p>\n<p>后来，Elastic使用Go写了一个专门用于数据采集的工具集<a href=\"https://www.elastic.co/products/beats\" target=\"_blank\" rel=\"noopener\">Beats</a>，其包括:</p>\n<p>现在，ELKB的流水线编程这样</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Raw Logs(原始日志数据) -&gt; Beats(数据采集) -&gt; Logstash(数据解析) -&gt; ElasticSearch(数据存储) -&gt; Kibana(数据展示)</span><br></pre></td></tr></table></figure>\n<p>在此之前，我们先搭建好ElasticSearch与Kibana，ELK家族的有一个优良传统，就是开箱即用。网上也有很多文章详细的讲述了ELK的安装细节，所以，本文就不在安装细节方面赘述，具体的安装细节，可以参考官方文档: </p>\n<ul>\n<li><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/_installation.html\" target=\"_blank\" rel=\"noopener\">ElasticSearch 安装</a></li>\n<li><a href=\"https://www.elastic.co/guide/en/kibana/current/targz.html\" target=\"_blank\" rel=\"noopener\">Kibana 安装</a></li>\n</ul>\n<h3 id=\"Configure-Filebeat\"><a href=\"#Configure-Filebeat\" class=\"headerlink\" title=\"Configure Filebeat\"></a>Configure Filebeat</h3><p>我们直接进入正题，如何使用ELK来分析Nginx日志，并绘制API响应耗时的图表。</p>\n<p>首先我们看一下Nginx的日志打印设置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">log_format  main  &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; $status $body_bytes_sent &quot;$http_referer&quot; &apos;</span><br><span class=\"line\">                      &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &quot;$request_time&quot; &quot;$host&quot; &apos;</span><br><span class=\"line\">                      &apos;&quot;$upstream_status&quot; &quot;$upstream_addr&quot; &quot;$upstream_response_time&quot;&apos; ;</span><br></pre></td></tr></table></figure>\n<p>默认情况下，我们将不同业务的Nginx访问日志写入到不同的文件里面，在我的系统里，Nginx日志被保存在<code>/usr/local/nginx/logs/api_acess.log</code>中。</p>\n<p>我们在这里，使用Beats工具中的FileBeats来收集日志Nginx日志</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">filebeat:</span><br><span class=\"line\">  prospectors:</span><br><span class=\"line\">    -</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">        - /usr/local/nginx/logs/api_acess.log</span><br><span class=\"line\">      input_type: log</span><br><span class=\"line\"></span><br><span class=\"line\">output:</span><br><span class=\"line\"></span><br><span class=\"line\">  logstash:</span><br><span class=\"line\">    hosts: [&quot;192.168.248.216:5045&quot;, &quot;192.168.248.217:5045&quot;]</span><br><span class=\"line\">    loadbalance: true</span><br><span class=\"line\">    index: &lt;your service index&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">logging:</span><br><span class=\"line\">  files:</span><br><span class=\"line\">    rotateeverybytes: 10485760 # = 10MB</span><br></pre></td></tr></table></figure>\n<p>以上配置文件主要是读取<code>/usr/local/nginx/logs/api_acess.log</code>的日志，并写入对应LogStash提供的TCP接口中。具体Filebeat的详细使用文档，可以参考（//TODO 文档链接）</p>\n<h3 id=\"Configure-Logstash\"><a href=\"#Configure-Logstash\" class=\"headerlink\" title=\"Configure Logstash\"></a>Configure Logstash</h3><p>接下来，我们需要启动对应的LogStash服务，它主要提供以下两个功能：</p>\n<ol>\n<li>提供5044接口给Filebeat做文件写入</li>\n<li>解析Nginx日志，提取需要的数据结构并写入ElasticSearch</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">input &#123;</span><br><span class=\"line\">  beats &#123;</span><br><span class=\"line\">    port =&gt; 5044</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">filter &#123;</span><br><span class=\"line\">  grok &#123;</span><br><span class=\"line\">    patterns_dir =&gt; [&quot;/opt/push/logstash/patterns&quot;]</span><br><span class=\"line\">    match =&gt; &#123; &apos;message&apos; =&gt; &apos;%&#123;IPORHOST:clientip&#125; - %&#123;APPKEY:appkey&#125; \\[%&#123;HTTPDATE:timestamp&#125;\\] &quot;%&#123;HTTPMETHOD:method&#125; %&#123;URIPATHPARAM:request&#125; HTTP/%&#123;NUMBER:httpversion&#125;&quot; %&#123;NUMBER:http_status&#125; %&#123;NUMBER:response_size&#125; %&#123;QS:http_referer&#125; %&#123;QS:user_agent&#125; %&#123;QS:x_forwarded_for&#125; &quot;%&#123;BASE10NUM:request_time&#125;&quot; &quot;%&#123;HOST:request_host&#125;&quot;  %&#123;BASE10NUM:upstream_header_time&#125; %&#123;NUMBER:upstream_response_time:float&#125; %&#123;HOST:upstream_addr&#125;:%&#123;NUMBER:upstream_port&#125;&apos; &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">output &#123;</span><br><span class=\"line\">    elasticsearch &#123;</span><br><span class=\"line\">        hosts =&gt; [&quot;172.16.99.xxx:1xxxx&quot;]</span><br><span class=\"line\">        manage_template =&gt; false</span><br><span class=\"line\">        index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class=\"line\">        document_type =&gt; &quot;%&#123;[@metadata][type]&#125;&quot;</span><br><span class=\"line\">        flush_size =&gt; 20000</span><br><span class=\"line\">        idle_flush_time =&gt; 10</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这里我们利用到了gork表达式。 他是Elastic公司设计专门用来解析日志的工具，具体<a href=\"http://xiezefan.me/2017/04/09/elk_in_action_grok_start/\" target=\"_blank\" rel=\"noopener\">Gork简易入门</a>。</p>\n<p>简单说，gork表达式可以方便的组合正则表达式，提取出日志的相关数据，最终转变成JSON格式输出。以下是我专门为以上Nginx日志结构写的Gork表达式，我们可以使用Gork Debuger工具来帮我们校验Gork表达式的正确性。</p>\n<p>Gork表达式需要一定的学习成本，但有了它，我们可以更方便快捷地分析日志。</p>\n<p>接下来，依次启动LagStash与FileBeat。 我们先认为的制造一点日志输出，可以看到在ElasicSearch中已经出现了响应的索引。</p>\n<h3 id=\"Configure-Kibana\"><a href=\"#Configure-Kibana\" class=\"headerlink\" title=\"Configure Kibana\"></a>Configure Kibana</h3><p>我们在Kibana中建立该索引，可以看到，日志的关键数据已经成功被提取并存入到ElasticSearch。接下来，我们将利用Kibana来统计报表。</p>\n<p><img src=\"http://res.xiezefan.me/images/blog/elk_in_action_kibana_chart\" alt=\"\"></p>\n<p>在Kibana绘制图标本身什么技术难度，关键一点是在将数据写入ElasticSearch中的时候，需要将一些关键指标转换成数值类型，我们可以在Grok转换的时候，指定生成Number类型，或者之间预定义相关业务的ElasticSearch Mapping Template。</p>\n<p>有一些绘图小技巧接下来准备独立整理一篇文章做单独分享。</p>\n","site":{"data":{}},"excerpt":"<p>本篇主要介绍如何利用ELK分析Nginx日志，统计出API的耗时数据</p>\n<p>ELK是ElasticSearch，Logstash，Kibana的简称，但我觉得这个名字已经过时了，现在叫ELKB更合适，因为Elastic家族近期迎来了一位新成员Beats，专职做数据采集工作。</p>\n<p>我们先来介绍下ELK的整体架构吧。</p>","more":"<p>早些时候，ELK的流水线是这样</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Raw Logs(原始日志数据) -&gt; Logstash(数据采集与解析) -&gt; ElasticSearch(数据存储) -&gt; Kibana(数据展示)</span><br></pre></td></tr></table></figure>\n<p>但是该模式有一个小缺陷是Logstash，主要因为Logstash是使用Java编写的，本身启动需要JVM资源，并且在宿主机上进行日志采集并分析必然会消耗资源。</p>\n<p>后来，Elastic使用Go写了一个专门用于数据采集的工具集<a href=\"https://www.elastic.co/products/beats\" target=\"_blank\" rel=\"noopener\">Beats</a>，其包括:</p>\n<p>现在，ELKB的流水线编程这样</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Raw Logs(原始日志数据) -&gt; Beats(数据采集) -&gt; Logstash(数据解析) -&gt; ElasticSearch(数据存储) -&gt; Kibana(数据展示)</span><br></pre></td></tr></table></figure>\n<p>在此之前，我们先搭建好ElasticSearch与Kibana，ELK家族的有一个优良传统，就是开箱即用。网上也有很多文章详细的讲述了ELK的安装细节，所以，本文就不在安装细节方面赘述，具体的安装细节，可以参考官方文档: </p>\n<ul>\n<li><a href=\"https://www.elastic.co/guide/en/elasticsearch/reference/current/_installation.html\" target=\"_blank\" rel=\"noopener\">ElasticSearch 安装</a></li>\n<li><a href=\"https://www.elastic.co/guide/en/kibana/current/targz.html\" target=\"_blank\" rel=\"noopener\">Kibana 安装</a></li>\n</ul>\n<h3 id=\"Configure-Filebeat\"><a href=\"#Configure-Filebeat\" class=\"headerlink\" title=\"Configure Filebeat\"></a>Configure Filebeat</h3><p>我们直接进入正题，如何使用ELK来分析Nginx日志，并绘制API响应耗时的图表。</p>\n<p>首先我们看一下Nginx的日志打印设置</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">log_format  main  &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; $status $body_bytes_sent &quot;$http_referer&quot; &apos;</span><br><span class=\"line\">                      &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &quot;$request_time&quot; &quot;$host&quot; &apos;</span><br><span class=\"line\">                      &apos;&quot;$upstream_status&quot; &quot;$upstream_addr&quot; &quot;$upstream_response_time&quot;&apos; ;</span><br></pre></td></tr></table></figure>\n<p>默认情况下，我们将不同业务的Nginx访问日志写入到不同的文件里面，在我的系统里，Nginx日志被保存在<code>/usr/local/nginx/logs/api_acess.log</code>中。</p>\n<p>我们在这里，使用Beats工具中的FileBeats来收集日志Nginx日志</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">filebeat:</span><br><span class=\"line\">  prospectors:</span><br><span class=\"line\">    -</span><br><span class=\"line\">      paths:</span><br><span class=\"line\">        - /usr/local/nginx/logs/api_acess.log</span><br><span class=\"line\">      input_type: log</span><br><span class=\"line\"></span><br><span class=\"line\">output:</span><br><span class=\"line\"></span><br><span class=\"line\">  logstash:</span><br><span class=\"line\">    hosts: [&quot;192.168.248.216:5045&quot;, &quot;192.168.248.217:5045&quot;]</span><br><span class=\"line\">    loadbalance: true</span><br><span class=\"line\">    index: &lt;your service index&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">logging:</span><br><span class=\"line\">  files:</span><br><span class=\"line\">    rotateeverybytes: 10485760 # = 10MB</span><br></pre></td></tr></table></figure>\n<p>以上配置文件主要是读取<code>/usr/local/nginx/logs/api_acess.log</code>的日志，并写入对应LogStash提供的TCP接口中。具体Filebeat的详细使用文档，可以参考（//TODO 文档链接）</p>\n<h3 id=\"Configure-Logstash\"><a href=\"#Configure-Logstash\" class=\"headerlink\" title=\"Configure Logstash\"></a>Configure Logstash</h3><p>接下来，我们需要启动对应的LogStash服务，它主要提供以下两个功能：</p>\n<ol>\n<li>提供5044接口给Filebeat做文件写入</li>\n<li>解析Nginx日志，提取需要的数据结构并写入ElasticSearch</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">input &#123;</span><br><span class=\"line\">  beats &#123;</span><br><span class=\"line\">    port =&gt; 5044</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">filter &#123;</span><br><span class=\"line\">  grok &#123;</span><br><span class=\"line\">    patterns_dir =&gt; [&quot;/opt/push/logstash/patterns&quot;]</span><br><span class=\"line\">    match =&gt; &#123; &apos;message&apos; =&gt; &apos;%&#123;IPORHOST:clientip&#125; - %&#123;APPKEY:appkey&#125; \\[%&#123;HTTPDATE:timestamp&#125;\\] &quot;%&#123;HTTPMETHOD:method&#125; %&#123;URIPATHPARAM:request&#125; HTTP/%&#123;NUMBER:httpversion&#125;&quot; %&#123;NUMBER:http_status&#125; %&#123;NUMBER:response_size&#125; %&#123;QS:http_referer&#125; %&#123;QS:user_agent&#125; %&#123;QS:x_forwarded_for&#125; &quot;%&#123;BASE10NUM:request_time&#125;&quot; &quot;%&#123;HOST:request_host&#125;&quot;  %&#123;BASE10NUM:upstream_header_time&#125; %&#123;NUMBER:upstream_response_time:float&#125; %&#123;HOST:upstream_addr&#125;:%&#123;NUMBER:upstream_port&#125;&apos; &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">output &#123;</span><br><span class=\"line\">    elasticsearch &#123;</span><br><span class=\"line\">        hosts =&gt; [&quot;172.16.99.xxx:1xxxx&quot;]</span><br><span class=\"line\">        manage_template =&gt; false</span><br><span class=\"line\">        index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class=\"line\">        document_type =&gt; &quot;%&#123;[@metadata][type]&#125;&quot;</span><br><span class=\"line\">        flush_size =&gt; 20000</span><br><span class=\"line\">        idle_flush_time =&gt; 10</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这里我们利用到了gork表达式。 他是Elastic公司设计专门用来解析日志的工具，具体<a href=\"http://xiezefan.me/2017/04/09/elk_in_action_grok_start/\" target=\"_blank\" rel=\"noopener\">Gork简易入门</a>。</p>\n<p>简单说，gork表达式可以方便的组合正则表达式，提取出日志的相关数据，最终转变成JSON格式输出。以下是我专门为以上Nginx日志结构写的Gork表达式，我们可以使用Gork Debuger工具来帮我们校验Gork表达式的正确性。</p>\n<p>Gork表达式需要一定的学习成本，但有了它，我们可以更方便快捷地分析日志。</p>\n<p>接下来，依次启动LagStash与FileBeat。 我们先认为的制造一点日志输出，可以看到在ElasicSearch中已经出现了响应的索引。</p>\n<h3 id=\"Configure-Kibana\"><a href=\"#Configure-Kibana\" class=\"headerlink\" title=\"Configure Kibana\"></a>Configure Kibana</h3><p>我们在Kibana中建立该索引，可以看到，日志的关键数据已经成功被提取并存入到ElasticSearch。接下来，我们将利用Kibana来统计报表。</p>\n<p><img src=\"http://res.xiezefan.me/images/blog/elk_in_action_kibana_chart\" alt=\"\"></p>\n<p>在Kibana绘制图标本身什么技术难度，关键一点是在将数据写入ElasticSearch中的时候，需要将一些关键指标转换成数值类型，我们可以在Grok转换的时候，指定生成Number类型，或者之间预定义相关业务的ElasticSearch Mapping Template。</p>\n<p>有一些绘图小技巧接下来准备独立整理一篇文章做单独分享。</p>"},{"layout":"post","title":"ELK实战 - Grok简易入门","date":"2017-04-08T16:00:00.000Z","_content":"\n\n\nGrok是ELK栈中，用来快速解析日志的一个脚本工具，运用得好的话，可以极大程度的降低日志解析的工作，最好的Grok表达式的学习方式是去阅读[官方文档](https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html)。\n\n<!--more-->\n\n### Example 示例\n\n一个简单的Grok表达式:\n\n```\n%{IP:source_ip}\n```\n\n它表示使用名为IP的正则表达式提取出内容，并命名为`source_ip`。\n\n我们以一个Nginx日志的例子来了解Grok表达式的工作模式:\n\n```\n// IP HTTP方法 请求资源 数据字节数 响应时间\n55.3.244.1 - GET /index.html 15824 0.043\n```\n解析该日志的Grok表达式为:\n\n```\n%{IP:client} - %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}\n```\n\n最终，Grok表达式将会从日志中提取出以下数据:\n\n```javascript\n{\n  \"client\": \"55.3.244.1\",\n  \"method\": \"GET\",\n  \"request\": \"/index.html\",\n  \"bytes\": \"15824\",\n  \"duration\": \"0.043\"\n}\n```\n\n细心可以注意到，bytes, duration这两个字段，虽然我们定义为NUMBER类型，但是提取出来的数据仍然是String。 我们以通过强制指定数据类型的方式，告知Gork解析器将指定字段保存为对应数据类型:\n\n```\n%{NUMBER:bytes:int}\n%{NUMBER:duration:float}\n```\n\n目前强制类型指定只支持float与int类型。\n\n#### Gork表达式\n\n官方默认提供了几组[Grok表达式](https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns)\n\n我介绍几个我用的比较顺手的Gork表达式\n\n* QS : 匹配双引号之间的字符串\n* NUMBER : 匹配数字，支持字符串与浮点型\n* HTTPDATE : 匹配Nginx默认保存的日期格式\n* IPORHOST : 同时匹配IP或者域名，试用与分析请求来源地址\n\n如果现有的Gork表达式不满足需求，我们以可以直接编写Gork表达式, 格式为\n\n```\n# 格式\n[名称] [正则表达式]\n\n# 示例(APPKEY:长度为24的随机字符串)\nAPPKEY [0-9a-zA-Z]{24}\n```\n\n文件名并无强制要求，我们可以将所有的Gork表达式保存在patterns文件夹中，这样可以方便让logstash引入所有的正则表达式， 上述提到官方提供的通用[Grok表达式](https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns)，也可以下载后，存放在patterns文件夹中。\n\n```\n...\nfilter {\n  grok {\n    patterns_dir => [\"/opt/push/logstash/patterns\"]\n    match => { \"message\" => \"<YOUT GROK PATTERN>\" }\n  }\n}\n...\n```\n\n\n最后，介绍一个方便的Grok测试工具 --- [Grok Debugger](http://grokdebug.herokuapp.com/) (PS: 需要注意的一点，该工具并不能支持Grok最新的指定数据类型的特性)\n\n\n### 总结\n\nGrok是节省解析日志时间与精力的利器，本身也不难，学习方法一是阅读[官方文档](https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html)，二是看官方提供的[Grok表达式](https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns)示例。稍微花点时间即可以基本掌握。\n\n\n\n","source":"_posts/elk_in_action_grok_start.md","raw":"---\nlayout: post\ntitle: \"ELK实战 - Grok简易入门\"\ndate: 2017-04-09\ncategories:\n- elk\ntags:\n- elk\n- gork\n\n---\n\n\n\nGrok是ELK栈中，用来快速解析日志的一个脚本工具，运用得好的话，可以极大程度的降低日志解析的工作，最好的Grok表达式的学习方式是去阅读[官方文档](https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html)。\n\n<!--more-->\n\n### Example 示例\n\n一个简单的Grok表达式:\n\n```\n%{IP:source_ip}\n```\n\n它表示使用名为IP的正则表达式提取出内容，并命名为`source_ip`。\n\n我们以一个Nginx日志的例子来了解Grok表达式的工作模式:\n\n```\n// IP HTTP方法 请求资源 数据字节数 响应时间\n55.3.244.1 - GET /index.html 15824 0.043\n```\n解析该日志的Grok表达式为:\n\n```\n%{IP:client} - %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}\n```\n\n最终，Grok表达式将会从日志中提取出以下数据:\n\n```javascript\n{\n  \"client\": \"55.3.244.1\",\n  \"method\": \"GET\",\n  \"request\": \"/index.html\",\n  \"bytes\": \"15824\",\n  \"duration\": \"0.043\"\n}\n```\n\n细心可以注意到，bytes, duration这两个字段，虽然我们定义为NUMBER类型，但是提取出来的数据仍然是String。 我们以通过强制指定数据类型的方式，告知Gork解析器将指定字段保存为对应数据类型:\n\n```\n%{NUMBER:bytes:int}\n%{NUMBER:duration:float}\n```\n\n目前强制类型指定只支持float与int类型。\n\n#### Gork表达式\n\n官方默认提供了几组[Grok表达式](https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns)\n\n我介绍几个我用的比较顺手的Gork表达式\n\n* QS : 匹配双引号之间的字符串\n* NUMBER : 匹配数字，支持字符串与浮点型\n* HTTPDATE : 匹配Nginx默认保存的日期格式\n* IPORHOST : 同时匹配IP或者域名，试用与分析请求来源地址\n\n如果现有的Gork表达式不满足需求，我们以可以直接编写Gork表达式, 格式为\n\n```\n# 格式\n[名称] [正则表达式]\n\n# 示例(APPKEY:长度为24的随机字符串)\nAPPKEY [0-9a-zA-Z]{24}\n```\n\n文件名并无强制要求，我们可以将所有的Gork表达式保存在patterns文件夹中，这样可以方便让logstash引入所有的正则表达式， 上述提到官方提供的通用[Grok表达式](https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns)，也可以下载后，存放在patterns文件夹中。\n\n```\n...\nfilter {\n  grok {\n    patterns_dir => [\"/opt/push/logstash/patterns\"]\n    match => { \"message\" => \"<YOUT GROK PATTERN>\" }\n  }\n}\n...\n```\n\n\n最后，介绍一个方便的Grok测试工具 --- [Grok Debugger](http://grokdebug.herokuapp.com/) (PS: 需要注意的一点，该工具并不能支持Grok最新的指定数据类型的特性)\n\n\n### 总结\n\nGrok是节省解析日志时间与精力的利器，本身也不难，学习方法一是阅读[官方文档](https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html)，二是看官方提供的[Grok表达式](https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns)示例。稍微花点时间即可以基本掌握。\n\n\n\n","slug":"elk_in_action_grok_start","published":1,"updated":"2018-10-11T17:47:50.624Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44f000al939agknp4gv","content":"<p>Grok是ELK栈中，用来快速解析日志的一个脚本工具，运用得好的话，可以极大程度的降低日志解析的工作，最好的Grok表达式的学习方式是去阅读<a href=\"https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html\" target=\"_blank\" rel=\"noopener\">官方文档</a>。</p>\n<a id=\"more\"></a>\n<h3 id=\"Example-示例\"><a href=\"#Example-示例\" class=\"headerlink\" title=\"Example 示例\"></a>Example 示例</h3><p>一个简单的Grok表达式:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">%&#123;IP:source_ip&#125;</span><br></pre></td></tr></table></figure>\n<p>它表示使用名为IP的正则表达式提取出内容，并命名为<code>source_ip</code>。</p>\n<p>我们以一个Nginx日志的例子来了解Grok表达式的工作模式:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// IP HTTP方法 请求资源 数据字节数 响应时间</span><br><span class=\"line\">55.3.244.1 - GET /index.html 15824 0.043</span><br></pre></td></tr></table></figure>\n<p>解析该日志的Grok表达式为:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">%&#123;IP:client&#125; - %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:bytes&#125; %&#123;NUMBER:duration&#125;</span><br></pre></td></tr></table></figure>\n<p>最终，Grok表达式将会从日志中提取出以下数据:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"client\"</span>: <span class=\"string\">\"55.3.244.1\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"method\"</span>: <span class=\"string\">\"GET\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"request\"</span>: <span class=\"string\">\"/index.html\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"bytes\"</span>: <span class=\"string\">\"15824\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"duration\"</span>: <span class=\"string\">\"0.043\"</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>细心可以注意到，bytes, duration这两个字段，虽然我们定义为NUMBER类型，但是提取出来的数据仍然是String。 我们以通过强制指定数据类型的方式，告知Gork解析器将指定字段保存为对应数据类型:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">%&#123;NUMBER:bytes:int&#125;</span><br><span class=\"line\">%&#123;NUMBER:duration:float&#125;</span><br></pre></td></tr></table></figure>\n<p>目前强制类型指定只支持float与int类型。</p>\n<h4 id=\"Gork表达式\"><a href=\"#Gork表达式\" class=\"headerlink\" title=\"Gork表达式\"></a>Gork表达式</h4><p>官方默认提供了几组<a href=\"https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns\" target=\"_blank\" rel=\"noopener\">Grok表达式</a></p>\n<p>我介绍几个我用的比较顺手的Gork表达式</p>\n<ul>\n<li>QS : 匹配双引号之间的字符串</li>\n<li>NUMBER : 匹配数字，支持字符串与浮点型</li>\n<li>HTTPDATE : 匹配Nginx默认保存的日期格式</li>\n<li>IPORHOST : 同时匹配IP或者域名，试用与分析请求来源地址</li>\n</ul>\n<p>如果现有的Gork表达式不满足需求，我们以可以直接编写Gork表达式, 格式为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 格式</span><br><span class=\"line\">[名称] [正则表达式]</span><br><span class=\"line\"></span><br><span class=\"line\"># 示例(APPKEY:长度为24的随机字符串)</span><br><span class=\"line\">APPKEY [0-9a-zA-Z]&#123;24&#125;</span><br></pre></td></tr></table></figure>\n<p>文件名并无强制要求，我们可以将所有的Gork表达式保存在patterns文件夹中，这样可以方便让logstash引入所有的正则表达式， 上述提到官方提供的通用<a href=\"https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns\" target=\"_blank\" rel=\"noopener\">Grok表达式</a>，也可以下载后，存放在patterns文件夹中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">filter &#123;</span><br><span class=\"line\">  grok &#123;</span><br><span class=\"line\">    patterns_dir =&gt; [&quot;/opt/push/logstash/patterns&quot;]</span><br><span class=\"line\">    match =&gt; &#123; &quot;message&quot; =&gt; &quot;&lt;YOUT GROK PATTERN&gt;&quot; &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>最后，介绍一个方便的Grok测试工具 — <a href=\"http://grokdebug.herokuapp.com/\" target=\"_blank\" rel=\"noopener\">Grok Debugger</a> (PS: 需要注意的一点，该工具并不能支持Grok最新的指定数据类型的特性)</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>Grok是节省解析日志时间与精力的利器，本身也不难，学习方法一是阅读<a href=\"https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html\" target=\"_blank\" rel=\"noopener\">官方文档</a>，二是看官方提供的<a href=\"https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns\" target=\"_blank\" rel=\"noopener\">Grok表达式</a>示例。稍微花点时间即可以基本掌握。</p>\n","site":{"data":{}},"excerpt":"<p>Grok是ELK栈中，用来快速解析日志的一个脚本工具，运用得好的话，可以极大程度的降低日志解析的工作，最好的Grok表达式的学习方式是去阅读<a href=\"https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html\" target=\"_blank\" rel=\"noopener\">官方文档</a>。</p>","more":"<h3 id=\"Example-示例\"><a href=\"#Example-示例\" class=\"headerlink\" title=\"Example 示例\"></a>Example 示例</h3><p>一个简单的Grok表达式:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">%&#123;IP:source_ip&#125;</span><br></pre></td></tr></table></figure>\n<p>它表示使用名为IP的正则表达式提取出内容，并命名为<code>source_ip</code>。</p>\n<p>我们以一个Nginx日志的例子来了解Grok表达式的工作模式:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// IP HTTP方法 请求资源 数据字节数 响应时间</span><br><span class=\"line\">55.3.244.1 - GET /index.html 15824 0.043</span><br></pre></td></tr></table></figure>\n<p>解析该日志的Grok表达式为:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">%&#123;IP:client&#125; - %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:bytes&#125; %&#123;NUMBER:duration&#125;</span><br></pre></td></tr></table></figure>\n<p>最终，Grok表达式将会从日志中提取出以下数据:</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"string\">\"client\"</span>: <span class=\"string\">\"55.3.244.1\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"method\"</span>: <span class=\"string\">\"GET\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"request\"</span>: <span class=\"string\">\"/index.html\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"bytes\"</span>: <span class=\"string\">\"15824\"</span>,</span><br><span class=\"line\">  <span class=\"string\">\"duration\"</span>: <span class=\"string\">\"0.043\"</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>细心可以注意到，bytes, duration这两个字段，虽然我们定义为NUMBER类型，但是提取出来的数据仍然是String。 我们以通过强制指定数据类型的方式，告知Gork解析器将指定字段保存为对应数据类型:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">%&#123;NUMBER:bytes:int&#125;</span><br><span class=\"line\">%&#123;NUMBER:duration:float&#125;</span><br></pre></td></tr></table></figure>\n<p>目前强制类型指定只支持float与int类型。</p>\n<h4 id=\"Gork表达式\"><a href=\"#Gork表达式\" class=\"headerlink\" title=\"Gork表达式\"></a>Gork表达式</h4><p>官方默认提供了几组<a href=\"https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns\" target=\"_blank\" rel=\"noopener\">Grok表达式</a></p>\n<p>我介绍几个我用的比较顺手的Gork表达式</p>\n<ul>\n<li>QS : 匹配双引号之间的字符串</li>\n<li>NUMBER : 匹配数字，支持字符串与浮点型</li>\n<li>HTTPDATE : 匹配Nginx默认保存的日期格式</li>\n<li>IPORHOST : 同时匹配IP或者域名，试用与分析请求来源地址</li>\n</ul>\n<p>如果现有的Gork表达式不满足需求，我们以可以直接编写Gork表达式, 格式为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 格式</span><br><span class=\"line\">[名称] [正则表达式]</span><br><span class=\"line\"></span><br><span class=\"line\"># 示例(APPKEY:长度为24的随机字符串)</span><br><span class=\"line\">APPKEY [0-9a-zA-Z]&#123;24&#125;</span><br></pre></td></tr></table></figure>\n<p>文件名并无强制要求，我们可以将所有的Gork表达式保存在patterns文件夹中，这样可以方便让logstash引入所有的正则表达式， 上述提到官方提供的通用<a href=\"https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns\" target=\"_blank\" rel=\"noopener\">Grok表达式</a>，也可以下载后，存放在patterns文件夹中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">...</span><br><span class=\"line\">filter &#123;</span><br><span class=\"line\">  grok &#123;</span><br><span class=\"line\">    patterns_dir =&gt; [&quot;/opt/push/logstash/patterns&quot;]</span><br><span class=\"line\">    match =&gt; &#123; &quot;message&quot; =&gt; &quot;&lt;YOUT GROK PATTERN&gt;&quot; &#125;</span><br><span class=\"line\">  &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>最后，介绍一个方便的Grok测试工具 — <a href=\"http://grokdebug.herokuapp.com/\" target=\"_blank\" rel=\"noopener\">Grok Debugger</a> (PS: 需要注意的一点，该工具并不能支持Grok最新的指定数据类型的特性)</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>Grok是节省解析日志时间与精力的利器，本身也不难，学习方法一是阅读<a href=\"https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html\" target=\"_blank\" rel=\"noopener\">官方文档</a>，二是看官方提供的<a href=\"https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns\" target=\"_blank\" rel=\"noopener\">Grok表达式</a>示例。稍微花点时间即可以基本掌握。</p>"},{"layout":"post","title":"finally引起的异常丢失问题","date":"2014-05-18T16:00:00.000Z","description":"finally引起的异常丢失问题","_content":"\nfinally 使用不当可能出现异常丢失问题，并且该缺陷尚未被修复， 开发中需要多加注意\n\n<!-- more -->\n\n### 场景一\n\n```Java\n\n\tpublic void loseException() throws Exception {\n\t\ttry {\n\t\t\tthrow new Exception(\"Exception A\");\n\t\t} finally {\n\t\t\tthrow new Exception(\"Exception B\");\n\t\t}\n\t}\n\n```\n\n调用 ``` loseException() ``` 你会发现，Exception A 被 Exception B覆盖掉了。这是非常严重的设计缺陷，并且很难察觉这些错误。\n目前Java还未修正这个错误。 其解决办法是将所有抛出异常的方法都打包同一个try-catch中。  \n\n### 场景二\n\n```Java\n\n\tpublic void loseException2() throws Exception {\n\t\ttry {\n\t\t\tthrow new Exception(\"Exception A\");\n\t\t} finally {\n\t\t\treturn;\n\t\t}\n\t}\n\n```\n\n这种方法让你更简单粗暴的丢失异常，并且不会产生任何输出。","source":"_posts/finally-lose.md","raw":"---\nlayout: post\ntitle: \"finally引起的异常丢失问题\"\ndate: 2014-05-19\ncategories:\n- java\ntags:\n- java\ndescription: finally引起的异常丢失问题\n\n---\n\nfinally 使用不当可能出现异常丢失问题，并且该缺陷尚未被修复， 开发中需要多加注意\n\n<!-- more -->\n\n### 场景一\n\n```Java\n\n\tpublic void loseException() throws Exception {\n\t\ttry {\n\t\t\tthrow new Exception(\"Exception A\");\n\t\t} finally {\n\t\t\tthrow new Exception(\"Exception B\");\n\t\t}\n\t}\n\n```\n\n调用 ``` loseException() ``` 你会发现，Exception A 被 Exception B覆盖掉了。这是非常严重的设计缺陷，并且很难察觉这些错误。\n目前Java还未修正这个错误。 其解决办法是将所有抛出异常的方法都打包同一个try-catch中。  \n\n### 场景二\n\n```Java\n\n\tpublic void loseException2() throws Exception {\n\t\ttry {\n\t\t\tthrow new Exception(\"Exception A\");\n\t\t} finally {\n\t\t\treturn;\n\t\t}\n\t}\n\n```\n\n这种方法让你更简单粗暴的丢失异常，并且不会产生任何输出。","slug":"finally-lose","published":1,"updated":"2018-10-11T17:47:50.624Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44g000bl939s9blb3oj","content":"<p>finally 使用不当可能出现异常丢失问题，并且该缺陷尚未被修复， 开发中需要多加注意</p>\n<a id=\"more\"></a>\n<h3 id=\"场景一\"><a href=\"#场景一\" class=\"headerlink\" title=\"场景一\"></a>场景一</h3><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">loseException</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> Exception(<span class=\"string\">\"Exception A\"</span>);</span><br><span class=\"line\">\t&#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> Exception(<span class=\"string\">\"Exception B\"</span>);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>调用 <figure class=\"highlight plain\"><figcaption><span>``` 你会发现，Exception A 被 Exception B覆盖掉了。这是非常严重的设计缺陷，并且很难察觉这些错误。</span></figcaption><table><tr><td class=\"code\"><pre><span class=\"line\">目前Java还未修正这个错误。 其解决办法是将所有抛出异常的方法都打包同一个try-catch中。  </span><br><span class=\"line\"></span><br><span class=\"line\">### 场景二</span><br><span class=\"line\"></span><br><span class=\"line\">```Java</span><br><span class=\"line\"></span><br><span class=\"line\">\tpublic void loseException2() throws Exception &#123;</span><br><span class=\"line\">\t\ttry &#123;</span><br><span class=\"line\">\t\t\tthrow new Exception(&quot;Exception A&quot;);</span><br><span class=\"line\">\t\t&#125; finally &#123;</span><br><span class=\"line\">\t\t\treturn;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br></pre></td></tr></table></figure></p>\n<p>这种方法让你更简单粗暴的丢失异常，并且不会产生任何输出。</p>\n","site":{"data":{}},"excerpt":"<p>finally 使用不当可能出现异常丢失问题，并且该缺陷尚未被修复， 开发中需要多加注意</p>","more":"<h3 id=\"场景一\"><a href=\"#场景一\" class=\"headerlink\" title=\"场景一\"></a>场景一</h3><figure class=\"highlight java\"><table><tr><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">loseException</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> Exception </span>&#123;</span><br><span class=\"line\">\t<span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> Exception(<span class=\"string\">\"Exception A\"</span>);</span><br><span class=\"line\">\t&#125; <span class=\"keyword\">finally</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">throw</span> <span class=\"keyword\">new</span> Exception(<span class=\"string\">\"Exception B\"</span>);</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>调用 <figure class=\"highlight plain\"><figcaption><span>``` 你会发现，Exception A 被 Exception B覆盖掉了。这是非常严重的设计缺陷，并且很难察觉这些错误。</span></figcaption><table><tr><td class=\"code\"><pre><span class=\"line\">目前Java还未修正这个错误。 其解决办法是将所有抛出异常的方法都打包同一个try-catch中。  </span><br><span class=\"line\"></span><br><span class=\"line\">### 场景二</span><br><span class=\"line\"></span><br><span class=\"line\">```Java</span><br><span class=\"line\"></span><br><span class=\"line\">\tpublic void loseException2() throws Exception &#123;</span><br><span class=\"line\">\t\ttry &#123;</span><br><span class=\"line\">\t\t\tthrow new Exception(&quot;Exception A&quot;);</span><br><span class=\"line\">\t\t&#125; finally &#123;</span><br><span class=\"line\">\t\t\treturn;</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t&#125;</span><br></pre></td></tr></table></figure></p>\n<p>这种方法让你更简单粗暴的丢失异常，并且不会产生任何输出。</p>"},{"layout":"post","title":"final, finally, finalize的区别","date":"2014-05-18T16:00:00.000Z","description":"final, finally, finalize的区别","_content":"\n\n## final, finally, finalize的区别\n### final\n* 如果一个类被声明为final，此类被能被重载。因此final和abstract不能同时修饰一个类\n* 如果一个方法被声明为final，此方法只能被使用，不能被重载\n* 如果一个变量被声明为final，此变量只能被使用，不能被修改，并且在声明的时候一定要初始化\n\n<!-- more -->\n\n### finally\n异常处理的程序块，使用finally来进行必要的清理工作（如关闭数据库联系，文件流之类的）。  \n值得一提的是  \n\n```\npublic int testFinally1() {\n    int i = 0;\n    try {\n        i++;\n        return i++;\n    } finally {\n        System.out.println(\"In finally\");\n        i++;\n    }\n}\npublic int testFinally2() {\n    int i = 0;\n    try {\n        i++;\n        return i++;\n    } finally {\n        System.out.println(\"In finally\");\n        i++;\n    }\n}\n```\ntestFinally1()返回的值是1，testFinally2()返回的值是2。 也就是说，finally会在return后执行。并且，return后，变量的改变并不会对返回值照成影响\n\n### finalize\n类似于C++的析构函数，但实际上有很大区别，垃圾回收器准备释放对象占用的存储空间的时候，就会调用finalize()方法，做一些清理工作。但是必须等到下一次垃圾回收回收动作才会回收内存。  \n所以，并不是finalize调用后内存就会被回收。因为垃圾回收是需要系统开销的。不到内存濒临用光或者程序退出的时候，垃圾回收动作很可能不会发送。  \n另外，，执行finalize的线程优先级一般比较低，所以即使垃圾回收器工作，finalize也不一定得到及时的执行  \nfinalize使用场景：\n  \n* 调用本地方法（如C，C++），其申请的内存是不会被垃圾回收器回收的。finalize可用来回收这部分内存。\n* 用于发现如文件是否被关闭，连接是否被关闭这种情景。","source":"_posts/final-finally-finalize-diff.md","raw":"---\nlayout: post\ntitle: \"final, finally, finalize的区别\"\ndate: 2014-05-19\ncategories:\n- java\ntags:\n- java\ndescription:  final, finally, finalize的区别\n\n---\n\n\n## final, finally, finalize的区别\n### final\n* 如果一个类被声明为final，此类被能被重载。因此final和abstract不能同时修饰一个类\n* 如果一个方法被声明为final，此方法只能被使用，不能被重载\n* 如果一个变量被声明为final，此变量只能被使用，不能被修改，并且在声明的时候一定要初始化\n\n<!-- more -->\n\n### finally\n异常处理的程序块，使用finally来进行必要的清理工作（如关闭数据库联系，文件流之类的）。  \n值得一提的是  \n\n```\npublic int testFinally1() {\n    int i = 0;\n    try {\n        i++;\n        return i++;\n    } finally {\n        System.out.println(\"In finally\");\n        i++;\n    }\n}\npublic int testFinally2() {\n    int i = 0;\n    try {\n        i++;\n        return i++;\n    } finally {\n        System.out.println(\"In finally\");\n        i++;\n    }\n}\n```\ntestFinally1()返回的值是1，testFinally2()返回的值是2。 也就是说，finally会在return后执行。并且，return后，变量的改变并不会对返回值照成影响\n\n### finalize\n类似于C++的析构函数，但实际上有很大区别，垃圾回收器准备释放对象占用的存储空间的时候，就会调用finalize()方法，做一些清理工作。但是必须等到下一次垃圾回收回收动作才会回收内存。  \n所以，并不是finalize调用后内存就会被回收。因为垃圾回收是需要系统开销的。不到内存濒临用光或者程序退出的时候，垃圾回收动作很可能不会发送。  \n另外，，执行finalize的线程优先级一般比较低，所以即使垃圾回收器工作，finalize也不一定得到及时的执行  \nfinalize使用场景：\n  \n* 调用本地方法（如C，C++），其申请的内存是不会被垃圾回收器回收的。finalize可用来回收这部分内存。\n* 用于发现如文件是否被关闭，连接是否被关闭这种情景。","slug":"final-finally-finalize-diff","published":1,"updated":"2018-10-11T17:47:50.624Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44i000gl93906kdubvl","content":"<h2 id=\"final-finally-finalize的区别\"><a href=\"#final-finally-finalize的区别\" class=\"headerlink\" title=\"final, finally, finalize的区别\"></a>final, finally, finalize的区别</h2><h3 id=\"final\"><a href=\"#final\" class=\"headerlink\" title=\"final\"></a>final</h3><ul>\n<li>如果一个类被声明为final，此类被能被重载。因此final和abstract不能同时修饰一个类</li>\n<li>如果一个方法被声明为final，此方法只能被使用，不能被重载</li>\n<li>如果一个变量被声明为final，此变量只能被使用，不能被修改，并且在声明的时候一定要初始化</li>\n</ul>\n<a id=\"more\"></a>\n<h3 id=\"finally\"><a href=\"#finally\" class=\"headerlink\" title=\"finally\"></a>finally</h3><p>异常处理的程序块，使用finally来进行必要的清理工作（如关闭数据库联系，文件流之类的）。<br>值得一提的是  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">public int testFinally1() &#123;</span><br><span class=\"line\">    int i = 0;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        i++;</span><br><span class=\"line\">        return i++;</span><br><span class=\"line\">    &#125; finally &#123;</span><br><span class=\"line\">        System.out.println(&quot;In finally&quot;);</span><br><span class=\"line\">        i++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">public int testFinally2() &#123;</span><br><span class=\"line\">    int i = 0;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        i++;</span><br><span class=\"line\">        return i++;</span><br><span class=\"line\">    &#125; finally &#123;</span><br><span class=\"line\">        System.out.println(&quot;In finally&quot;);</span><br><span class=\"line\">        i++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>testFinally1()返回的值是1，testFinally2()返回的值是2。 也就是说，finally会在return后执行。并且，return后，变量的改变并不会对返回值照成影响</p>\n<h3 id=\"finalize\"><a href=\"#finalize\" class=\"headerlink\" title=\"finalize\"></a>finalize</h3><p>类似于C++的析构函数，但实际上有很大区别，垃圾回收器准备释放对象占用的存储空间的时候，就会调用finalize()方法，做一些清理工作。但是必须等到下一次垃圾回收回收动作才会回收内存。<br>所以，并不是finalize调用后内存就会被回收。因为垃圾回收是需要系统开销的。不到内存濒临用光或者程序退出的时候，垃圾回收动作很可能不会发送。<br>另外，，执行finalize的线程优先级一般比较低，所以即使垃圾回收器工作，finalize也不一定得到及时的执行<br>finalize使用场景：</p>\n<ul>\n<li>调用本地方法（如C，C++），其申请的内存是不会被垃圾回收器回收的。finalize可用来回收这部分内存。</li>\n<li>用于发现如文件是否被关闭，连接是否被关闭这种情景。</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h2 id=\"final-finally-finalize的区别\"><a href=\"#final-finally-finalize的区别\" class=\"headerlink\" title=\"final, finally, finalize的区别\"></a>final, finally, finalize的区别</h2><h3 id=\"final\"><a href=\"#final\" class=\"headerlink\" title=\"final\"></a>final</h3><ul>\n<li>如果一个类被声明为final，此类被能被重载。因此final和abstract不能同时修饰一个类</li>\n<li>如果一个方法被声明为final，此方法只能被使用，不能被重载</li>\n<li>如果一个变量被声明为final，此变量只能被使用，不能被修改，并且在声明的时候一定要初始化</li>\n</ul>","more":"<h3 id=\"finally\"><a href=\"#finally\" class=\"headerlink\" title=\"finally\"></a>finally</h3><p>异常处理的程序块，使用finally来进行必要的清理工作（如关闭数据库联系，文件流之类的）。<br>值得一提的是  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">public int testFinally1() &#123;</span><br><span class=\"line\">    int i = 0;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        i++;</span><br><span class=\"line\">        return i++;</span><br><span class=\"line\">    &#125; finally &#123;</span><br><span class=\"line\">        System.out.println(&quot;In finally&quot;);</span><br><span class=\"line\">        i++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">public int testFinally2() &#123;</span><br><span class=\"line\">    int i = 0;</span><br><span class=\"line\">    try &#123;</span><br><span class=\"line\">        i++;</span><br><span class=\"line\">        return i++;</span><br><span class=\"line\">    &#125; finally &#123;</span><br><span class=\"line\">        System.out.println(&quot;In finally&quot;);</span><br><span class=\"line\">        i++;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>testFinally1()返回的值是1，testFinally2()返回的值是2。 也就是说，finally会在return后执行。并且，return后，变量的改变并不会对返回值照成影响</p>\n<h3 id=\"finalize\"><a href=\"#finalize\" class=\"headerlink\" title=\"finalize\"></a>finalize</h3><p>类似于C++的析构函数，但实际上有很大区别，垃圾回收器准备释放对象占用的存储空间的时候，就会调用finalize()方法，做一些清理工作。但是必须等到下一次垃圾回收回收动作才会回收内存。<br>所以，并不是finalize调用后内存就会被回收。因为垃圾回收是需要系统开销的。不到内存濒临用光或者程序退出的时候，垃圾回收动作很可能不会发送。<br>另外，，执行finalize的线程优先级一般比较低，所以即使垃圾回收器工作，finalize也不一定得到及时的执行<br>finalize使用场景：</p>\n<ul>\n<li>调用本地方法（如C，C++），其申请的内存是不会被垃圾回收器回收的。finalize可用来回收这部分内存。</li>\n<li>用于发现如文件是否被关闭，连接是否被关闭这种情景。</li>\n</ul>"},{"layout":"post","title":"基类构造函数，子类构造函数，成员类构造函数的调用顺序","date":"2014-05-18T16:00:00.000Z","_content":"\n这是Java 笔试经常遇到的一个问题，所有特定写代码研究下。\n\n<!-- more -->\n\n\n\n```\n\tclass Father {\n\t    public Father() {\n\t        System.out.println(\"In Father\");\n\t    }\n\t}\n\n\tclass Children extends Father {\n\t    private Friend friend = new Friend();\n\t    public Children() {\n\t        System.out.println(\"In Children\");\n\t    }\n\n\t}\n\n\tclass Friend {\n\t    public Friend() {\n\t        System.out.println(\"In Friend\");\n\t    }\n\t}\n```\n\n\n以上三个对象，运行 ``` new Children(); ``` ，执行的结果是\n\n\tIn Father\n\tIn Friend\n\tIn Children\n\n\n### 结论\n先执行基类构造函数，再执行成员类构造函数，最后执行子类构造函数。","source":"_posts/java-constructor-base.md","raw":"---\nlayout: post\ntitle: \"基类构造函数，子类构造函数，成员类构造函数的调用顺序\"\ndate: 2014-05-19\ncategories:\n- java\ntags:\n- java\n\n---\n\n这是Java 笔试经常遇到的一个问题，所有特定写代码研究下。\n\n<!-- more -->\n\n\n\n```\n\tclass Father {\n\t    public Father() {\n\t        System.out.println(\"In Father\");\n\t    }\n\t}\n\n\tclass Children extends Father {\n\t    private Friend friend = new Friend();\n\t    public Children() {\n\t        System.out.println(\"In Children\");\n\t    }\n\n\t}\n\n\tclass Friend {\n\t    public Friend() {\n\t        System.out.println(\"In Friend\");\n\t    }\n\t}\n```\n\n\n以上三个对象，运行 ``` new Children(); ``` ，执行的结果是\n\n\tIn Father\n\tIn Friend\n\tIn Children\n\n\n### 结论\n先执行基类构造函数，再执行成员类构造函数，最后执行子类构造函数。","slug":"java-constructor-base","published":1,"updated":"2018-10-11T17:47:50.625Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44j000il939hq2qp727","content":"<p>这是Java 笔试经常遇到的一个问题，所有特定写代码研究下。</p>\n<a id=\"more\"></a>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">class Father &#123;</span><br><span class=\"line\">    public Father() &#123;</span><br><span class=\"line\">        System.out.println(&quot;In Father&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">class Children extends Father &#123;</span><br><span class=\"line\">    private Friend friend = new Friend();</span><br><span class=\"line\">    public Children() &#123;</span><br><span class=\"line\">        System.out.println(&quot;In Children&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">class Friend &#123;</span><br><span class=\"line\">    public Friend() &#123;</span><br><span class=\"line\">        System.out.println(&quot;In Friend&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>以上三个对象，运行 <code>new Children();</code> ，执行的结果是</p>\n<pre><code>In Father\nIn Friend\nIn Children\n</code></pre><h3 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h3><p>先执行基类构造函数，再执行成员类构造函数，最后执行子类构造函数。</p>\n","site":{"data":{}},"excerpt":"<p>这是Java 笔试经常遇到的一个问题，所有特定写代码研究下。</p>","more":"<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">class Father &#123;</span><br><span class=\"line\">    public Father() &#123;</span><br><span class=\"line\">        System.out.println(&quot;In Father&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">class Children extends Father &#123;</span><br><span class=\"line\">    private Friend friend = new Friend();</span><br><span class=\"line\">    public Children() &#123;</span><br><span class=\"line\">        System.out.println(&quot;In Children&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">class Friend &#123;</span><br><span class=\"line\">    public Friend() &#123;</span><br><span class=\"line\">        System.out.println(&quot;In Friend&quot;);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>以上三个对象，运行 <code>new Children();</code> ，执行的结果是</p>\n<pre><code>In Father\nIn Friend\nIn Children\n</code></pre><h3 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h3><p>先执行基类构造函数，再执行成员类构造函数，最后执行子类构造函数。</p>"},{"layout":"post","title":"Linux系统安装配置JDK与Maven","date":"2015-01-02T16:00:00.000Z","description":"Linux 系统下快速按安装配置JDK与Maven的多种方法及利弊。","_content":"\nLinux 系统下快速按安装配置JDK与Maven的多种方法及利弊。\n\n<!-- more -->\n\n### 下载\n\n> Java  \n> http://www.oracle.com/technetwork/java/javase/downloads/index.html  \n> Maven  \n> http://maven.apache.org/download.cgi\n\n### 配置\n\n修改 `/etc/profile` 文件\n#### Java\n```\nJAVA_HOME=/usr/share/jdk1.5.0_05 \nPATH=$JAVA_HOME/bin:$PATH\nCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar \nexport JAVA_HOME \nexport PATH \nexport CLASSPATH\n```\n#### Maven\n\n```\nMAVEN_HOME=~/apache-maven-3.2.3\nexport MAVEN_HOME\n```\n\n#### 即刻生效修改\n```\nsource /etc/profile\n```\n\n\n### 其他配置方法\n\n上述方法是通过修改/etc/profile文件，但这个修改是全局的，所以，基于安全考虑，当只需要给某个用户权限使用这个环境变量的时候，只需修改该用户目录下的.bashrc文件并重启系统即可。\n当然也可以直接在sheel中设置，不过此方法设置后，在关闭了sheel后就会失效， 看需求使用\n\n```\n# 在sheel中导入JDK配置\nexport JAVA_HOME=/usr/share/jdk1.5.0_05\nexport PATH=$JAVA_HOME/bin:$PATH\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n```\n\n### 参考文章\n\n* [百度知道-linux下如何设置JDK环境变量][1]\n\n\n  [1]: http://zhidao.baidu.com/link?url=0XeoCXTgx-QLIMZVfWQlsak206gNr_7dkmdYHenFEB25gyt35Ctqzq5W0Kp9WmYaJT2LhSBsacETKP5Iizefm_\n","source":"_posts/linux-install-sdk-and-maven.md","raw":"---\nlayout: post\ntitle: \"Linux系统安装配置JDK与Maven\"\ndate: 2015-01-03\ncategories: \n- linux\ntags: \n- linux\n- maven\n- jdk\ndescription: Linux 系统下快速按安装配置JDK与Maven的多种方法及利弊。\n\n---\n\nLinux 系统下快速按安装配置JDK与Maven的多种方法及利弊。\n\n<!-- more -->\n\n### 下载\n\n> Java  \n> http://www.oracle.com/technetwork/java/javase/downloads/index.html  \n> Maven  \n> http://maven.apache.org/download.cgi\n\n### 配置\n\n修改 `/etc/profile` 文件\n#### Java\n```\nJAVA_HOME=/usr/share/jdk1.5.0_05 \nPATH=$JAVA_HOME/bin:$PATH\nCLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar \nexport JAVA_HOME \nexport PATH \nexport CLASSPATH\n```\n#### Maven\n\n```\nMAVEN_HOME=~/apache-maven-3.2.3\nexport MAVEN_HOME\n```\n\n#### 即刻生效修改\n```\nsource /etc/profile\n```\n\n\n### 其他配置方法\n\n上述方法是通过修改/etc/profile文件，但这个修改是全局的，所以，基于安全考虑，当只需要给某个用户权限使用这个环境变量的时候，只需修改该用户目录下的.bashrc文件并重启系统即可。\n当然也可以直接在sheel中设置，不过此方法设置后，在关闭了sheel后就会失效， 看需求使用\n\n```\n# 在sheel中导入JDK配置\nexport JAVA_HOME=/usr/share/jdk1.5.0_05\nexport PATH=$JAVA_HOME/bin:$PATH\nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n```\n\n### 参考文章\n\n* [百度知道-linux下如何设置JDK环境变量][1]\n\n\n  [1]: http://zhidao.baidu.com/link?url=0XeoCXTgx-QLIMZVfWQlsak206gNr_7dkmdYHenFEB25gyt35Ctqzq5W0Kp9WmYaJT2LhSBsacETKP5Iizefm_\n","slug":"linux-install-sdk-and-maven","published":1,"updated":"2018-10-11T17:47:50.625Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44l000nl93921r9eacx","content":"<p>Linux 系统下快速按安装配置JDK与Maven的多种方法及利弊。</p>\n<a id=\"more\"></a>\n<h3 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h3><blockquote>\n<p>Java<br><a href=\"http://www.oracle.com/technetwork/java/javase/downloads/index.html\" target=\"_blank\" rel=\"noopener\">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a><br>Maven<br><a href=\"http://maven.apache.org/download.cgi\" target=\"_blank\" rel=\"noopener\">http://maven.apache.org/download.cgi</a></p>\n</blockquote>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><p>修改 <code>/etc/profile</code> 文件</p>\n<h4 id=\"Java\"><a href=\"#Java\" class=\"headerlink\" title=\"Java\"></a>Java</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">JAVA_HOME=/usr/share/jdk1.5.0_05 </span><br><span class=\"line\">PATH=$JAVA_HOME/bin:$PATH</span><br><span class=\"line\">CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar </span><br><span class=\"line\">export JAVA_HOME </span><br><span class=\"line\">export PATH </span><br><span class=\"line\">export CLASSPATH</span><br></pre></td></tr></table></figure>\n<h4 id=\"Maven\"><a href=\"#Maven\" class=\"headerlink\" title=\"Maven\"></a>Maven</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">MAVEN_HOME=~/apache-maven-3.2.3</span><br><span class=\"line\">export MAVEN_HOME</span><br></pre></td></tr></table></figure>\n<h4 id=\"即刻生效修改\"><a href=\"#即刻生效修改\" class=\"headerlink\" title=\"即刻生效修改\"></a>即刻生效修改</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">source /etc/profile</span><br></pre></td></tr></table></figure>\n<h3 id=\"其他配置方法\"><a href=\"#其他配置方法\" class=\"headerlink\" title=\"其他配置方法\"></a>其他配置方法</h3><p>上述方法是通过修改/etc/profile文件，但这个修改是全局的，所以，基于安全考虑，当只需要给某个用户权限使用这个环境变量的时候，只需修改该用户目录下的.bashrc文件并重启系统即可。<br>当然也可以直接在sheel中设置，不过此方法设置后，在关闭了sheel后就会失效， 看需求使用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 在sheel中导入JDK配置</span><br><span class=\"line\">export JAVA_HOME=/usr/share/jdk1.5.0_05</span><br><span class=\"line\">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class=\"line\">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br></pre></td></tr></table></figure>\n<h3 id=\"参考文章\"><a href=\"#参考文章\" class=\"headerlink\" title=\"参考文章\"></a>参考文章</h3><ul>\n<li><a href=\"http://zhidao.baidu.com/link?url=0XeoCXTgx-QLIMZVfWQlsak206gNr_7dkmdYHenFEB25gyt35Ctqzq5W0Kp9WmYaJT2LhSBsacETKP5Iizefm_\" target=\"_blank\" rel=\"noopener\">百度知道-linux下如何设置JDK环境变量</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>Linux 系统下快速按安装配置JDK与Maven的多种方法及利弊。</p>","more":"<h3 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h3><blockquote>\n<p>Java<br><a href=\"http://www.oracle.com/technetwork/java/javase/downloads/index.html\" target=\"_blank\" rel=\"noopener\">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a><br>Maven<br><a href=\"http://maven.apache.org/download.cgi\" target=\"_blank\" rel=\"noopener\">http://maven.apache.org/download.cgi</a></p>\n</blockquote>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><p>修改 <code>/etc/profile</code> 文件</p>\n<h4 id=\"Java\"><a href=\"#Java\" class=\"headerlink\" title=\"Java\"></a>Java</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">JAVA_HOME=/usr/share/jdk1.5.0_05 </span><br><span class=\"line\">PATH=$JAVA_HOME/bin:$PATH</span><br><span class=\"line\">CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar </span><br><span class=\"line\">export JAVA_HOME </span><br><span class=\"line\">export PATH </span><br><span class=\"line\">export CLASSPATH</span><br></pre></td></tr></table></figure>\n<h4 id=\"Maven\"><a href=\"#Maven\" class=\"headerlink\" title=\"Maven\"></a>Maven</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">MAVEN_HOME=~/apache-maven-3.2.3</span><br><span class=\"line\">export MAVEN_HOME</span><br></pre></td></tr></table></figure>\n<h4 id=\"即刻生效修改\"><a href=\"#即刻生效修改\" class=\"headerlink\" title=\"即刻生效修改\"></a>即刻生效修改</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">source /etc/profile</span><br></pre></td></tr></table></figure>\n<h3 id=\"其他配置方法\"><a href=\"#其他配置方法\" class=\"headerlink\" title=\"其他配置方法\"></a>其他配置方法</h3><p>上述方法是通过修改/etc/profile文件，但这个修改是全局的，所以，基于安全考虑，当只需要给某个用户权限使用这个环境变量的时候，只需修改该用户目录下的.bashrc文件并重启系统即可。<br>当然也可以直接在sheel中设置，不过此方法设置后，在关闭了sheel后就会失效， 看需求使用</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\"># 在sheel中导入JDK配置</span><br><span class=\"line\">export JAVA_HOME=/usr/share/jdk1.5.0_05</span><br><span class=\"line\">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class=\"line\">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br></pre></td></tr></table></figure>\n<h3 id=\"参考文章\"><a href=\"#参考文章\" class=\"headerlink\" title=\"参考文章\"></a>参考文章</h3><ul>\n<li><a href=\"http://zhidao.baidu.com/link?url=0XeoCXTgx-QLIMZVfWQlsak206gNr_7dkmdYHenFEB25gyt35Ctqzq5W0Kp9WmYaJT2LhSBsacETKP5Iizefm_\" target=\"_blank\" rel=\"noopener\">百度知道-linux下如何设置JDK环境变量</a></li>\n</ul>"},{"layout":"post","title":"maven入门","date":"2014-05-12T16:00:00.000Z","_content":"\nMaven简单入门， 快速入手\n\n<!-- more -->\n\n## 下载\n    http://maven.apache.org/download.html\n\n## 配置\n    MAVEN_HOME : D:\\apache-maven-3.0.2  \n    MAVEN : %MAVEN_HOME%\\bin   \n    (可选） MAVEN_OPTS : -Xms256m -Xmx512m\n    PATH: 添加 %MAVEN%\n\n## 开始\n### 验证安装成功\n    mvn -version\n\n正常应该显示  \n\n    Apache Maven 3.2.1 (ea8b2b07643dbb1b84b6d16e1f08391b666bc1e9;2014-02-15T01:37:52+08:00)\n    Maven home: D:\\apache-maven-3.2.1\\bin\\..\n    Java version: 1.7.0_09, vendor: Oracle Corporation\n    Java home: C:\\Program Files\\Java\\jdk1.7.0_09\\jre\n    Default locale: zh_CN, platform encoding: GBK\n    OS name: \"windows 8\", version: \"6.2\", arch: \"amd64\", family: \"windows\"\n\n### 创建项目\n\n    #此命令创建一个默认项目\n    mvn archetype:create -DgroupId=com.xiezefan.app -DartifactId=my-app\n    #此命令创建一个web项目\n    mvn archetype:create -DgroupId=com.xiezefan.app -DartifactId=webappp -DarchetypeArtifactId=maven-archetype-webapp\n\n创建一个默认项目，项目名为my-app，项目包结构为com.xiezefan.app  \n\n* DgroupId 项目包结构\n* DartifactId 项目名\n* DarchetypeArtifactId 项目类型（maven-archetype-webapp是web项目，打包后生成war包）\n\n### 常用命令\n\n    mvn package  #打包项目，感觉pox.xml的packaging确定打包成jar or war","source":"_posts/maven-start.md","raw":"---\nlayout: post\ntitle: \"maven入门\"\ndate: 2014-05-13\ncategories:\n- java\ntags:\n- maven\n\n---\n\nMaven简单入门， 快速入手\n\n<!-- more -->\n\n## 下载\n    http://maven.apache.org/download.html\n\n## 配置\n    MAVEN_HOME : D:\\apache-maven-3.0.2  \n    MAVEN : %MAVEN_HOME%\\bin   \n    (可选） MAVEN_OPTS : -Xms256m -Xmx512m\n    PATH: 添加 %MAVEN%\n\n## 开始\n### 验证安装成功\n    mvn -version\n\n正常应该显示  \n\n    Apache Maven 3.2.1 (ea8b2b07643dbb1b84b6d16e1f08391b666bc1e9;2014-02-15T01:37:52+08:00)\n    Maven home: D:\\apache-maven-3.2.1\\bin\\..\n    Java version: 1.7.0_09, vendor: Oracle Corporation\n    Java home: C:\\Program Files\\Java\\jdk1.7.0_09\\jre\n    Default locale: zh_CN, platform encoding: GBK\n    OS name: \"windows 8\", version: \"6.2\", arch: \"amd64\", family: \"windows\"\n\n### 创建项目\n\n    #此命令创建一个默认项目\n    mvn archetype:create -DgroupId=com.xiezefan.app -DartifactId=my-app\n    #此命令创建一个web项目\n    mvn archetype:create -DgroupId=com.xiezefan.app -DartifactId=webappp -DarchetypeArtifactId=maven-archetype-webapp\n\n创建一个默认项目，项目名为my-app，项目包结构为com.xiezefan.app  \n\n* DgroupId 项目包结构\n* DartifactId 项目名\n* DarchetypeArtifactId 项目类型（maven-archetype-webapp是web项目，打包后生成war包）\n\n### 常用命令\n\n    mvn package  #打包项目，感觉pox.xml的packaging确定打包成jar or war","slug":"maven-start","published":1,"updated":"2018-10-11T17:47:50.625Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44m000ql9394z1uaniy","content":"<p>Maven简单入门， 快速入手</p>\n<a id=\"more\"></a>\n<h2 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h2><pre><code>http://maven.apache.org/download.html\n</code></pre><h2 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h2><pre><code>MAVEN_HOME : D:\\apache-maven-3.0.2  \nMAVEN : %MAVEN_HOME%\\bin   \n(可选） MAVEN_OPTS : -Xms256m -Xmx512m\nPATH: 添加 %MAVEN%\n</code></pre><h2 id=\"开始\"><a href=\"#开始\" class=\"headerlink\" title=\"开始\"></a>开始</h2><h3 id=\"验证安装成功\"><a href=\"#验证安装成功\" class=\"headerlink\" title=\"验证安装成功\"></a>验证安装成功</h3><pre><code>mvn -version\n</code></pre><p>正常应该显示  </p>\n<pre><code>Apache Maven 3.2.1 (ea8b2b07643dbb1b84b6d16e1f08391b666bc1e9;2014-02-15T01:37:52+08:00)\nMaven home: D:\\apache-maven-3.2.1\\bin\\..\nJava version: 1.7.0_09, vendor: Oracle Corporation\nJava home: C:\\Program Files\\Java\\jdk1.7.0_09\\jre\nDefault locale: zh_CN, platform encoding: GBK\nOS name: &quot;windows 8&quot;, version: &quot;6.2&quot;, arch: &quot;amd64&quot;, family: &quot;windows&quot;\n</code></pre><h3 id=\"创建项目\"><a href=\"#创建项目\" class=\"headerlink\" title=\"创建项目\"></a>创建项目</h3><pre><code>#此命令创建一个默认项目\nmvn archetype:create -DgroupId=com.xiezefan.app -DartifactId=my-app\n#此命令创建一个web项目\nmvn archetype:create -DgroupId=com.xiezefan.app -DartifactId=webappp -DarchetypeArtifactId=maven-archetype-webapp\n</code></pre><p>创建一个默认项目，项目名为my-app，项目包结构为com.xiezefan.app  </p>\n<ul>\n<li>DgroupId 项目包结构</li>\n<li>DartifactId 项目名</li>\n<li>DarchetypeArtifactId 项目类型（maven-archetype-webapp是web项目，打包后生成war包）</li>\n</ul>\n<h3 id=\"常用命令\"><a href=\"#常用命令\" class=\"headerlink\" title=\"常用命令\"></a>常用命令</h3><pre><code>mvn package  #打包项目，感觉pox.xml的packaging确定打包成jar or war\n</code></pre>","site":{"data":{}},"excerpt":"<p>Maven简单入门， 快速入手</p>","more":"<h2 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h2><pre><code>http://maven.apache.org/download.html\n</code></pre><h2 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h2><pre><code>MAVEN_HOME : D:\\apache-maven-3.0.2  \nMAVEN : %MAVEN_HOME%\\bin   \n(可选） MAVEN_OPTS : -Xms256m -Xmx512m\nPATH: 添加 %MAVEN%\n</code></pre><h2 id=\"开始\"><a href=\"#开始\" class=\"headerlink\" title=\"开始\"></a>开始</h2><h3 id=\"验证安装成功\"><a href=\"#验证安装成功\" class=\"headerlink\" title=\"验证安装成功\"></a>验证安装成功</h3><pre><code>mvn -version\n</code></pre><p>正常应该显示  </p>\n<pre><code>Apache Maven 3.2.1 (ea8b2b07643dbb1b84b6d16e1f08391b666bc1e9;2014-02-15T01:37:52+08:00)\nMaven home: D:\\apache-maven-3.2.1\\bin\\..\nJava version: 1.7.0_09, vendor: Oracle Corporation\nJava home: C:\\Program Files\\Java\\jdk1.7.0_09\\jre\nDefault locale: zh_CN, platform encoding: GBK\nOS name: &quot;windows 8&quot;, version: &quot;6.2&quot;, arch: &quot;amd64&quot;, family: &quot;windows&quot;\n</code></pre><h3 id=\"创建项目\"><a href=\"#创建项目\" class=\"headerlink\" title=\"创建项目\"></a>创建项目</h3><pre><code>#此命令创建一个默认项目\nmvn archetype:create -DgroupId=com.xiezefan.app -DartifactId=my-app\n#此命令创建一个web项目\nmvn archetype:create -DgroupId=com.xiezefan.app -DartifactId=webappp -DarchetypeArtifactId=maven-archetype-webapp\n</code></pre><p>创建一个默认项目，项目名为my-app，项目包结构为com.xiezefan.app  </p>\n<ul>\n<li>DgroupId 项目包结构</li>\n<li>DartifactId 项目名</li>\n<li>DarchetypeArtifactId 项目类型（maven-archetype-webapp是web项目，打包后生成war包）</li>\n</ul>\n<h3 id=\"常用命令\"><a href=\"#常用命令\" class=\"headerlink\" title=\"常用命令\"></a>常用命令</h3><pre><code>mvn package  #打包项目，感觉pox.xml的packaging确定打包成jar or war\n</code></pre>"},{"layout":"post","title":"使用Git SubModule对Maven Module进行优化","date":"2016-08-12T16:00:00.000Z","description":"这篇文章主要讲，如何将Maven Module功能与Git SubModule功能配合使用的问题。","_content":"\n\n这篇文章主要讲，如何将Maven Module功能与Git SubModule功能配合使用的问题。\n\n之所以有这篇文章，是因为在使用Maven管理Java项目的过程中，当项目逐渐发展到一点规模后，我们将项目进行模块划分，将不同业务功能拆分为不同的Maven Module，模块之间有依赖关系，但可以分开部署。\n\n但紧随而来的问题是：\n\n1. 当项目模块越来越多的时候，项目的编译时间越来越长\n2. 我们使用Gitlab CI做持续集成与持续交付。 Gitlab CI的持续集成与交付的是由每次Commit与每次Release Tag触发的。也就是说，每次触发CI的时候，各个模块都需要跑一边集成测试，而更麻烦的在于，无法使用Gitlab CI直接对项目进行自动部署，因为你不能每次发布的时候，都将所有的子模块都部署一遍。\n\n<!-- more -->\n\n为了应对这个问题，显然我们需要将项目进行拆分，按部署单元将拆分为不同的Git Repository。常规的做法是将项目中公共的模块抽取成独立的Maven Dependency。 打包发布到私有的Maven仓库。但这显然太繁琐了，因为项目迭代开发过程中，即使是公共的模块，也会频繁的变更，每次变更其余依赖模块都需要升级版本。\n\n自此终于引出文本的主题，如何使用Git SubModule与Maven Module来优雅的解决上述问题。\n\n\n### Maven Module 拆分示例\n\n我们以一个Blog后台的API项目作为示例\n\n```\n.\n├── dashboard-api       // Blog管理后台API模块\n│   └── pom.xml\n├── blog-api            // Blog前端的API模块\n│   └── pom.xml\n├── blog-common         // Blog系统的公共代码，如Entity，Util，Helper等逻辑\n│   └── pom.xml\n└── pom.xml\n```\n\ndashboard-api与blog-api都依赖blog-common，但两个模块最终都会打成独立的包分开部署。\n\n**PS: 显然一个Blog系统不需要做这么细致的模块划分，这里只是举例子方便大家理解。**\n\n我们的目标是将该项目拆分为3个Git Repositories:\n\n1. blog-common\n2. blog-api\n3. blog-dashboard-api\n\n首先我们将blog-common项目拆分出来\n\n```shell\ncd blog-common\ngit init\ngit remote add origin git@your-repository.com:xiezefan/blog-common.git\ngit add .\ngit commit\ngit push -u origin master\n```\n\n接下来我们将为blog-api独立成一个新的项目，并将blog-common设置为blog-api的子模块\n\n```shell\nmkdir blog-api\ncp -rf my-blog/blog-api blog-api/api\ncp my-blog/pom.xml blog-api/\n\ncd blog-api\ngit submodule add -b master git@your-repository.com:xiezefan/blog-common.git\n```\n\n这时候blog-api项目下将会生成`.gitmodule`文件，该文件对本项目的Git子模块进行声明\n\n```\n// .gitmodule\nsubmodule [\"blog-common\"]\n        path = blog-common\n        url = git@your-repository.com:xiezefan/blog-common.git\n        branch = master\n```\n\n接着我们编辑根目录下的pom.xml文件，声明`blog-common`, `api` 两个子模块\n\n```xml\n// pom.xml\n...\n\n<modules>\n  <module>blog-common</module>\n  <module>api</module>\n</modules>\n\n...\n```\n\n最后在`api`模块中，将`blog-common`进行引入即可。\n\n```xml\n// api/pom.xml\n\n...\n\n<dependency>\n  <groupId>me.xiezefan.blog</groupId>\n  <artifactId>blog-common</artifactId>\n  <version>0.0.1</version>\n</dependency>\n\n...\n```\n\n在此大功告成，此时项目的目录结构应为\n\n```\n.\n├── blog-api\n    ├── .gitmodule\n    ├── .gitignore\n    ├── api\n    │   └── pom.xml\n    ├── blog-common\n    │   └── pom.xml\n    └── pom.xml\n```\n\n我们可以执行`mvn clean package`进行打包看看拆分是否成功。 依据同样的方法，我们可以对blog-dashboard-api进行拆分。 \n\n\n### 如何使用Git SubModule\n\n因为blog-commmon本身是一个独立的项目，我们每次对其进行修改后，只需要在这模块中执行常规的git提交命令即可对模块进行更新。\n\n而对子模块的更新也有些许不同，当开发者第一次checkout带子模块的项目的时候，需要额外执行子模块检出命令。\n\n```shell\ngit clone \ngit@your-repository.com:xiezefan/blog-api.git\n\ncd blog-api\ngit submodule init\ngit submodule update --remote\n```\n\n此后，每次需要对子模块进行更新的时候，只需要执行\n\n```shell\ngit submodule update --remote\n```\n\n\n### 一些思考\n\n之所以研究Git Module来对Maven的项目结构进行优化，主要是因为在使用Gitlab CI进行持续集成过程中，面对一个项目中有多个模块的情况下，持续集成无法对子模块进行按需部署。\n\n为了解决这个问题，我一开始的思路是在CI脚本中编写逻辑判断，然后使用Gitlab Triggering API触发CI脚本并传入不同参数来选择部署不同的子模块。但这个解决方案还需要有一个定制的控制台来选择触发指定模块以及指定版本。\n\n对于创业公司永远不足的人力面前，最忌讳就是盲目造轮子。所以后来我选择的Git Module模块来解决这个问题，虽然会照成多出大量的Git Repositories的负作用，但这显然比造一个轮子来的经济实惠。\n\n\n\n\n\n\n### 参考资料\n\n* [Using Git Submodules for Maven Artifacts Not in Central](http://alex.nederlof.com/blog/2013/07/08/using-git-submodules-for-maven-artifacts-not-in-central/)\n* [Git 工具 - 子模块](https://git-scm.com/book/zh/v2/Git-工具-子模块)\n\n\n> 本文首发 : http://xiezefan.me/2016/08/13/maven_module_with_git_sub_module/\n\n\n\n","source":"_posts/maven_module_with_git_sub_module.md","raw":"---\nlayout: post\ntitle: \"使用Git SubModule对Maven Module进行优化\"\ndate: 2016-8-13\ncategories:\n- maven\ntags:\n- maven\n- git\ndescription: 这篇文章主要讲，如何将Maven Module功能与Git SubModule功能配合使用的问题。\n---\n\n\n这篇文章主要讲，如何将Maven Module功能与Git SubModule功能配合使用的问题。\n\n之所以有这篇文章，是因为在使用Maven管理Java项目的过程中，当项目逐渐发展到一点规模后，我们将项目进行模块划分，将不同业务功能拆分为不同的Maven Module，模块之间有依赖关系，但可以分开部署。\n\n但紧随而来的问题是：\n\n1. 当项目模块越来越多的时候，项目的编译时间越来越长\n2. 我们使用Gitlab CI做持续集成与持续交付。 Gitlab CI的持续集成与交付的是由每次Commit与每次Release Tag触发的。也就是说，每次触发CI的时候，各个模块都需要跑一边集成测试，而更麻烦的在于，无法使用Gitlab CI直接对项目进行自动部署，因为你不能每次发布的时候，都将所有的子模块都部署一遍。\n\n<!-- more -->\n\n为了应对这个问题，显然我们需要将项目进行拆分，按部署单元将拆分为不同的Git Repository。常规的做法是将项目中公共的模块抽取成独立的Maven Dependency。 打包发布到私有的Maven仓库。但这显然太繁琐了，因为项目迭代开发过程中，即使是公共的模块，也会频繁的变更，每次变更其余依赖模块都需要升级版本。\n\n自此终于引出文本的主题，如何使用Git SubModule与Maven Module来优雅的解决上述问题。\n\n\n### Maven Module 拆分示例\n\n我们以一个Blog后台的API项目作为示例\n\n```\n.\n├── dashboard-api       // Blog管理后台API模块\n│   └── pom.xml\n├── blog-api            // Blog前端的API模块\n│   └── pom.xml\n├── blog-common         // Blog系统的公共代码，如Entity，Util，Helper等逻辑\n│   └── pom.xml\n└── pom.xml\n```\n\ndashboard-api与blog-api都依赖blog-common，但两个模块最终都会打成独立的包分开部署。\n\n**PS: 显然一个Blog系统不需要做这么细致的模块划分，这里只是举例子方便大家理解。**\n\n我们的目标是将该项目拆分为3个Git Repositories:\n\n1. blog-common\n2. blog-api\n3. blog-dashboard-api\n\n首先我们将blog-common项目拆分出来\n\n```shell\ncd blog-common\ngit init\ngit remote add origin git@your-repository.com:xiezefan/blog-common.git\ngit add .\ngit commit\ngit push -u origin master\n```\n\n接下来我们将为blog-api独立成一个新的项目，并将blog-common设置为blog-api的子模块\n\n```shell\nmkdir blog-api\ncp -rf my-blog/blog-api blog-api/api\ncp my-blog/pom.xml blog-api/\n\ncd blog-api\ngit submodule add -b master git@your-repository.com:xiezefan/blog-common.git\n```\n\n这时候blog-api项目下将会生成`.gitmodule`文件，该文件对本项目的Git子模块进行声明\n\n```\n// .gitmodule\nsubmodule [\"blog-common\"]\n        path = blog-common\n        url = git@your-repository.com:xiezefan/blog-common.git\n        branch = master\n```\n\n接着我们编辑根目录下的pom.xml文件，声明`blog-common`, `api` 两个子模块\n\n```xml\n// pom.xml\n...\n\n<modules>\n  <module>blog-common</module>\n  <module>api</module>\n</modules>\n\n...\n```\n\n最后在`api`模块中，将`blog-common`进行引入即可。\n\n```xml\n// api/pom.xml\n\n...\n\n<dependency>\n  <groupId>me.xiezefan.blog</groupId>\n  <artifactId>blog-common</artifactId>\n  <version>0.0.1</version>\n</dependency>\n\n...\n```\n\n在此大功告成，此时项目的目录结构应为\n\n```\n.\n├── blog-api\n    ├── .gitmodule\n    ├── .gitignore\n    ├── api\n    │   └── pom.xml\n    ├── blog-common\n    │   └── pom.xml\n    └── pom.xml\n```\n\n我们可以执行`mvn clean package`进行打包看看拆分是否成功。 依据同样的方法，我们可以对blog-dashboard-api进行拆分。 \n\n\n### 如何使用Git SubModule\n\n因为blog-commmon本身是一个独立的项目，我们每次对其进行修改后，只需要在这模块中执行常规的git提交命令即可对模块进行更新。\n\n而对子模块的更新也有些许不同，当开发者第一次checkout带子模块的项目的时候，需要额外执行子模块检出命令。\n\n```shell\ngit clone \ngit@your-repository.com:xiezefan/blog-api.git\n\ncd blog-api\ngit submodule init\ngit submodule update --remote\n```\n\n此后，每次需要对子模块进行更新的时候，只需要执行\n\n```shell\ngit submodule update --remote\n```\n\n\n### 一些思考\n\n之所以研究Git Module来对Maven的项目结构进行优化，主要是因为在使用Gitlab CI进行持续集成过程中，面对一个项目中有多个模块的情况下，持续集成无法对子模块进行按需部署。\n\n为了解决这个问题，我一开始的思路是在CI脚本中编写逻辑判断，然后使用Gitlab Triggering API触发CI脚本并传入不同参数来选择部署不同的子模块。但这个解决方案还需要有一个定制的控制台来选择触发指定模块以及指定版本。\n\n对于创业公司永远不足的人力面前，最忌讳就是盲目造轮子。所以后来我选择的Git Module模块来解决这个问题，虽然会照成多出大量的Git Repositories的负作用，但这显然比造一个轮子来的经济实惠。\n\n\n\n\n\n\n### 参考资料\n\n* [Using Git Submodules for Maven Artifacts Not in Central](http://alex.nederlof.com/blog/2013/07/08/using-git-submodules-for-maven-artifacts-not-in-central/)\n* [Git 工具 - 子模块](https://git-scm.com/book/zh/v2/Git-工具-子模块)\n\n\n> 本文首发 : http://xiezefan.me/2016/08/13/maven_module_with_git_sub_module/\n\n\n\n","slug":"maven_module_with_git_sub_module","published":1,"updated":"2018-10-11T17:47:50.625Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44o000vl939zvmwtaem","content":"<p>这篇文章主要讲，如何将Maven Module功能与Git SubModule功能配合使用的问题。</p>\n<p>之所以有这篇文章，是因为在使用Maven管理Java项目的过程中，当项目逐渐发展到一点规模后，我们将项目进行模块划分，将不同业务功能拆分为不同的Maven Module，模块之间有依赖关系，但可以分开部署。</p>\n<p>但紧随而来的问题是：</p>\n<ol>\n<li>当项目模块越来越多的时候，项目的编译时间越来越长</li>\n<li>我们使用Gitlab CI做持续集成与持续交付。 Gitlab CI的持续集成与交付的是由每次Commit与每次Release Tag触发的。也就是说，每次触发CI的时候，各个模块都需要跑一边集成测试，而更麻烦的在于，无法使用Gitlab CI直接对项目进行自动部署，因为你不能每次发布的时候，都将所有的子模块都部署一遍。</li>\n</ol>\n<a id=\"more\"></a>\n<p>为了应对这个问题，显然我们需要将项目进行拆分，按部署单元将拆分为不同的Git Repository。常规的做法是将项目中公共的模块抽取成独立的Maven Dependency。 打包发布到私有的Maven仓库。但这显然太繁琐了，因为项目迭代开发过程中，即使是公共的模块，也会频繁的变更，每次变更其余依赖模块都需要升级版本。</p>\n<p>自此终于引出文本的主题，如何使用Git SubModule与Maven Module来优雅的解决上述问题。</p>\n<h3 id=\"Maven-Module-拆分示例\"><a href=\"#Maven-Module-拆分示例\" class=\"headerlink\" title=\"Maven Module 拆分示例\"></a>Maven Module 拆分示例</h3><p>我们以一个Blog后台的API项目作为示例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">.</span><br><span class=\"line\">├── dashboard-api       // Blog管理后台API模块</span><br><span class=\"line\">│   └── pom.xml</span><br><span class=\"line\">├── blog-api            // Blog前端的API模块</span><br><span class=\"line\">│   └── pom.xml</span><br><span class=\"line\">├── blog-common         // Blog系统的公共代码，如Entity，Util，Helper等逻辑</span><br><span class=\"line\">│   └── pom.xml</span><br><span class=\"line\">└── pom.xml</span><br></pre></td></tr></table></figure>\n<p>dashboard-api与blog-api都依赖blog-common，但两个模块最终都会打成独立的包分开部署。</p>\n<p><strong>PS: 显然一个Blog系统不需要做这么细致的模块划分，这里只是举例子方便大家理解。</strong></p>\n<p>我们的目标是将该项目拆分为3个Git Repositories:</p>\n<ol>\n<li>blog-common</li>\n<li>blog-api</li>\n<li>blog-dashboard-api</li>\n</ol>\n<p>首先我们将blog-common项目拆分出来</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">cd blog-common</span><br><span class=\"line\">git init</span><br><span class=\"line\">git remote add origin git@your-repository.com:xiezefan/blog-common.git</span><br><span class=\"line\">git add .</span><br><span class=\"line\">git commit</span><br><span class=\"line\">git push -u origin master</span><br></pre></td></tr></table></figure>\n<p>接下来我们将为blog-api独立成一个新的项目，并将blog-common设置为blog-api的子模块</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">mkdir blog-api</span><br><span class=\"line\">cp -rf my-blog/blog-api blog-api/api</span><br><span class=\"line\">cp my-blog/pom.xml blog-api/</span><br><span class=\"line\"></span><br><span class=\"line\">cd blog-api</span><br><span class=\"line\">git submodule add -b master git@your-repository.com:xiezefan/blog-common.git</span><br></pre></td></tr></table></figure>\n<p>这时候blog-api项目下将会生成<code>.gitmodule</code>文件，该文件对本项目的Git子模块进行声明</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// .gitmodule</span><br><span class=\"line\">submodule [&quot;blog-common&quot;]</span><br><span class=\"line\">        path = blog-common</span><br><span class=\"line\">        url = git@your-repository.com:xiezefan/blog-common.git</span><br><span class=\"line\">        branch = master</span><br></pre></td></tr></table></figure>\n<p>接着我们编辑根目录下的pom.xml文件，声明<code>blog-common</code>, <code>api</code> 两个子模块</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\">// pom.xml</span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">modules</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">module</span>&gt;</span>blog-common<span class=\"tag\">&lt;/<span class=\"name\">module</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">module</span>&gt;</span>api<span class=\"tag\">&lt;/<span class=\"name\">module</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">modules</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>最后在<code>api</code>模块中，将<code>blog-common</code>进行引入即可。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\">// api/pom.xml</span><br><span class=\"line\"></span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>me.xiezefan.blog<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>blog-common<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>0.0.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>在此大功告成，此时项目的目录结构应为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">.</span><br><span class=\"line\">├── blog-api</span><br><span class=\"line\">    ├── .gitmodule</span><br><span class=\"line\">    ├── .gitignore</span><br><span class=\"line\">    ├── api</span><br><span class=\"line\">    │   └── pom.xml</span><br><span class=\"line\">    ├── blog-common</span><br><span class=\"line\">    │   └── pom.xml</span><br><span class=\"line\">    └── pom.xml</span><br></pre></td></tr></table></figure>\n<p>我们可以执行<code>mvn clean package</code>进行打包看看拆分是否成功。 依据同样的方法，我们可以对blog-dashboard-api进行拆分。 </p>\n<h3 id=\"如何使用Git-SubModule\"><a href=\"#如何使用Git-SubModule\" class=\"headerlink\" title=\"如何使用Git SubModule\"></a>如何使用Git SubModule</h3><p>因为blog-commmon本身是一个独立的项目，我们每次对其进行修改后，只需要在这模块中执行常规的git提交命令即可对模块进行更新。</p>\n<p>而对子模块的更新也有些许不同，当开发者第一次checkout带子模块的项目的时候，需要额外执行子模块检出命令。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">git clone </span><br><span class=\"line\">git@your-repository.com:xiezefan/blog-api.git</span><br><span class=\"line\"></span><br><span class=\"line\">cd blog-api</span><br><span class=\"line\">git submodule init</span><br><span class=\"line\">git submodule update --remote</span><br></pre></td></tr></table></figure>\n<p>此后，每次需要对子模块进行更新的时候，只需要执行</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">git submodule update --remote</span><br></pre></td></tr></table></figure>\n<h3 id=\"一些思考\"><a href=\"#一些思考\" class=\"headerlink\" title=\"一些思考\"></a>一些思考</h3><p>之所以研究Git Module来对Maven的项目结构进行优化，主要是因为在使用Gitlab CI进行持续集成过程中，面对一个项目中有多个模块的情况下，持续集成无法对子模块进行按需部署。</p>\n<p>为了解决这个问题，我一开始的思路是在CI脚本中编写逻辑判断，然后使用Gitlab Triggering API触发CI脚本并传入不同参数来选择部署不同的子模块。但这个解决方案还需要有一个定制的控制台来选择触发指定模块以及指定版本。</p>\n<p>对于创业公司永远不足的人力面前，最忌讳就是盲目造轮子。所以后来我选择的Git Module模块来解决这个问题，虽然会照成多出大量的Git Repositories的负作用，但这显然比造一个轮子来的经济实惠。</p>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><ul>\n<li><a href=\"http://alex.nederlof.com/blog/2013/07/08/using-git-submodules-for-maven-artifacts-not-in-central/\" target=\"_blank\" rel=\"noopener\">Using Git Submodules for Maven Artifacts Not in Central</a></li>\n<li><a href=\"https://git-scm.com/book/zh/v2/Git-工具-子模块\" target=\"_blank\" rel=\"noopener\">Git 工具 - 子模块</a></li>\n</ul>\n<blockquote>\n<p>本文首发 : <a href=\"http://xiezefan.me/2016/08/13/maven_module_with_git_sub_module/\" target=\"_blank\" rel=\"noopener\">http://xiezefan.me/2016/08/13/maven_module_with_git_sub_module/</a></p>\n</blockquote>\n","site":{"data":{}},"excerpt":"<p>这篇文章主要讲，如何将Maven Module功能与Git SubModule功能配合使用的问题。</p>\n<p>之所以有这篇文章，是因为在使用Maven管理Java项目的过程中，当项目逐渐发展到一点规模后，我们将项目进行模块划分，将不同业务功能拆分为不同的Maven Module，模块之间有依赖关系，但可以分开部署。</p>\n<p>但紧随而来的问题是：</p>\n<ol>\n<li>当项目模块越来越多的时候，项目的编译时间越来越长</li>\n<li>我们使用Gitlab CI做持续集成与持续交付。 Gitlab CI的持续集成与交付的是由每次Commit与每次Release Tag触发的。也就是说，每次触发CI的时候，各个模块都需要跑一边集成测试，而更麻烦的在于，无法使用Gitlab CI直接对项目进行自动部署，因为你不能每次发布的时候，都将所有的子模块都部署一遍。</li>\n</ol>","more":"<p>为了应对这个问题，显然我们需要将项目进行拆分，按部署单元将拆分为不同的Git Repository。常规的做法是将项目中公共的模块抽取成独立的Maven Dependency。 打包发布到私有的Maven仓库。但这显然太繁琐了，因为项目迭代开发过程中，即使是公共的模块，也会频繁的变更，每次变更其余依赖模块都需要升级版本。</p>\n<p>自此终于引出文本的主题，如何使用Git SubModule与Maven Module来优雅的解决上述问题。</p>\n<h3 id=\"Maven-Module-拆分示例\"><a href=\"#Maven-Module-拆分示例\" class=\"headerlink\" title=\"Maven Module 拆分示例\"></a>Maven Module 拆分示例</h3><p>我们以一个Blog后台的API项目作为示例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">.</span><br><span class=\"line\">├── dashboard-api       // Blog管理后台API模块</span><br><span class=\"line\">│   └── pom.xml</span><br><span class=\"line\">├── blog-api            // Blog前端的API模块</span><br><span class=\"line\">│   └── pom.xml</span><br><span class=\"line\">├── blog-common         // Blog系统的公共代码，如Entity，Util，Helper等逻辑</span><br><span class=\"line\">│   └── pom.xml</span><br><span class=\"line\">└── pom.xml</span><br></pre></td></tr></table></figure>\n<p>dashboard-api与blog-api都依赖blog-common，但两个模块最终都会打成独立的包分开部署。</p>\n<p><strong>PS: 显然一个Blog系统不需要做这么细致的模块划分，这里只是举例子方便大家理解。</strong></p>\n<p>我们的目标是将该项目拆分为3个Git Repositories:</p>\n<ol>\n<li>blog-common</li>\n<li>blog-api</li>\n<li>blog-dashboard-api</li>\n</ol>\n<p>首先我们将blog-common项目拆分出来</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">cd blog-common</span><br><span class=\"line\">git init</span><br><span class=\"line\">git remote add origin git@your-repository.com:xiezefan/blog-common.git</span><br><span class=\"line\">git add .</span><br><span class=\"line\">git commit</span><br><span class=\"line\">git push -u origin master</span><br></pre></td></tr></table></figure>\n<p>接下来我们将为blog-api独立成一个新的项目，并将blog-common设置为blog-api的子模块</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">mkdir blog-api</span><br><span class=\"line\">cp -rf my-blog/blog-api blog-api/api</span><br><span class=\"line\">cp my-blog/pom.xml blog-api/</span><br><span class=\"line\"></span><br><span class=\"line\">cd blog-api</span><br><span class=\"line\">git submodule add -b master git@your-repository.com:xiezefan/blog-common.git</span><br></pre></td></tr></table></figure>\n<p>这时候blog-api项目下将会生成<code>.gitmodule</code>文件，该文件对本项目的Git子模块进行声明</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// .gitmodule</span><br><span class=\"line\">submodule [&quot;blog-common&quot;]</span><br><span class=\"line\">        path = blog-common</span><br><span class=\"line\">        url = git@your-repository.com:xiezefan/blog-common.git</span><br><span class=\"line\">        branch = master</span><br></pre></td></tr></table></figure>\n<p>接着我们编辑根目录下的pom.xml文件，声明<code>blog-common</code>, <code>api</code> 两个子模块</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\">// pom.xml</span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">modules</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">module</span>&gt;</span>blog-common<span class=\"tag\">&lt;/<span class=\"name\">module</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">module</span>&gt;</span>api<span class=\"tag\">&lt;/<span class=\"name\">module</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">modules</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>最后在<code>api</code>模块中，将<code>blog-common</code>进行引入即可。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"code\"><pre><span class=\"line\">// api/pom.xml</span><br><span class=\"line\"></span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>me.xiezefan.blog<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>blog-common<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>0.0.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>在此大功告成，此时项目的目录结构应为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">.</span><br><span class=\"line\">├── blog-api</span><br><span class=\"line\">    ├── .gitmodule</span><br><span class=\"line\">    ├── .gitignore</span><br><span class=\"line\">    ├── api</span><br><span class=\"line\">    │   └── pom.xml</span><br><span class=\"line\">    ├── blog-common</span><br><span class=\"line\">    │   └── pom.xml</span><br><span class=\"line\">    └── pom.xml</span><br></pre></td></tr></table></figure>\n<p>我们可以执行<code>mvn clean package</code>进行打包看看拆分是否成功。 依据同样的方法，我们可以对blog-dashboard-api进行拆分。 </p>\n<h3 id=\"如何使用Git-SubModule\"><a href=\"#如何使用Git-SubModule\" class=\"headerlink\" title=\"如何使用Git SubModule\"></a>如何使用Git SubModule</h3><p>因为blog-commmon本身是一个独立的项目，我们每次对其进行修改后，只需要在这模块中执行常规的git提交命令即可对模块进行更新。</p>\n<p>而对子模块的更新也有些许不同，当开发者第一次checkout带子模块的项目的时候，需要额外执行子模块检出命令。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">git clone </span><br><span class=\"line\">git@your-repository.com:xiezefan/blog-api.git</span><br><span class=\"line\"></span><br><span class=\"line\">cd blog-api</span><br><span class=\"line\">git submodule init</span><br><span class=\"line\">git submodule update --remote</span><br></pre></td></tr></table></figure>\n<p>此后，每次需要对子模块进行更新的时候，只需要执行</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">git submodule update --remote</span><br></pre></td></tr></table></figure>\n<h3 id=\"一些思考\"><a href=\"#一些思考\" class=\"headerlink\" title=\"一些思考\"></a>一些思考</h3><p>之所以研究Git Module来对Maven的项目结构进行优化，主要是因为在使用Gitlab CI进行持续集成过程中，面对一个项目中有多个模块的情况下，持续集成无法对子模块进行按需部署。</p>\n<p>为了解决这个问题，我一开始的思路是在CI脚本中编写逻辑判断，然后使用Gitlab Triggering API触发CI脚本并传入不同参数来选择部署不同的子模块。但这个解决方案还需要有一个定制的控制台来选择触发指定模块以及指定版本。</p>\n<p>对于创业公司永远不足的人力面前，最忌讳就是盲目造轮子。所以后来我选择的Git Module模块来解决这个问题，虽然会照成多出大量的Git Repositories的负作用，但这显然比造一个轮子来的经济实惠。</p>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><ul>\n<li><a href=\"http://alex.nederlof.com/blog/2013/07/08/using-git-submodules-for-maven-artifacts-not-in-central/\" target=\"_blank\" rel=\"noopener\">Using Git Submodules for Maven Artifacts Not in Central</a></li>\n<li><a href=\"https://git-scm.com/book/zh/v2/Git-工具-子模块\" target=\"_blank\" rel=\"noopener\">Git 工具 - 子模块</a></li>\n</ul>\n<blockquote>\n<p>本文首发 : <a href=\"http://xiezefan.me/2016/08/13/maven_module_with_git_sub_module/\" target=\"_blank\" rel=\"noopener\">http://xiezefan.me/2016/08/13/maven_module_with_git_sub_module/</a></p>\n</blockquote>"},{"layout":"post","title":"MQTT 基础知识","date":"2014-12-28T16:00:00.000Z","_content":"\nMQTT是IBM开发的一个即时通讯协议， 广泛运用在移动互联网实时推送以及相关扩展应用上，本文只要简述MQTT协议的部分知识点。\n\n<!-- more -->\n\n### 基础内容\n\nMQTT的固定头部包含以下信息\n\n#### MessageType\n消息类型，使用4位二进制标示，共16种消息类型，其中0和15位做保留待用，实际使用共14种消息事件类型\n\n#### DUP flag \n默认为0，标示该消息为第一次发送，当该值为一时，标示消息先前已经被传输过了，该位前置条件为Qos > 0，标示消息需要回复确认\n\n#### QoS level\n服务质量，由两个二进制位标示\n*　0：至多一次\n*　1：至少一次\n*　2：只有一次\n*　3：保留\n\n#### RETAIN\n是否对PUBLISH消息进行持久化\n* 1：标示需要持久化， 当新订阅者出现时，会收到最新一个持久化消息\n* 2：标示不需要持久化，推送仅对当前订阅者\n**当RETAIN=1，Payload=NULL时标示删除该Topic的持久化PUBLISH消息**\n\n### Topic通配符\n> /：用来表示层次，比如a/b，a/b/c。\n> \\#：表示匹配>=0个层次，比如a/#就匹配a/，a/b，a/b/c。\n> 单独的一个#表示匹配所有。\n> 不允许 a#和a/#/c。\n> +：表示匹配一个层次，例如a/+匹配a/b，a/c，不匹配a/b/c。\n> 单独的一个+是允许的，a+不允许，a/+/b不允许\n\n### 心跳 PINGREQ/PINGRES\nClient告知Server其心跳间隔KeepAliveTime，Client需要在该时长内发送PINGREQ，Server收到后返回PINGRES确认以保持Client与Server的长链接。\nServer在1.5个时长内未收到PINGREQ，就断开连接\nClient在1个时长内未收到Server的PINGRES，就断开连接\n时间最长为18hours，0标示不断开\n\n### Clean Session\n服务端是否保存Client的订阅信息\n* true:保存\n* false:不保持\n\n### 字段建议长度\n* clientId 客户端->服务端, 服务端->客户端的单向唯一标示,length<=23\n* username 用户名,用于身份验证, length<=12\n* password 用户密码,用户身份验证, length<=12\n\n\n### 遗嘱消息 WillMessage\n遗嘱消息标示客户端网络异常导致连接中断后, 服务器将发布该遗嘱消息\n遗嘱消息包含以下信息:\n* Will Flag:是否定义遗嘱消息，Will Flag=1是标示指定遗嘱消息，否则将直接忽略Will Qos，Will RETAIN的值\n* Will Qos:遗嘱消息的通讯质量\n* Will RETAIN:遗嘱消息是否持久化\n* Will Topic:遗嘱消息主题\n* Will Message:遗嘱消息Payload\n\n### 建立连接CONNECT的响应机制\n* 客户端绕过CONNECT消息直接发送其它类型消息，服务器应关闭此非法连接\n* 客户端发送CONNECT之后未收到CONNACT，需要关闭当前连接，然后重新连接\n* 相同Client ID客户端已连接到服务器，先前客户端必须断开连接后，服务器才能完成新的客户端CONNECT连接\n* 客户端发送无效非法CONNECT消息，服务器需要关闭\n\n\n\n### 参考资料\n\n* [MQTT协议简记][1]\n* [MQTT协议笔记之头部信息][2]\n* [MQTT协议笔记之连接和心跳][3]\n\n\n  [1]: http://www.cnblogs.com/caca/p/mqtt.html\n  [2]: http://www.blogjava.net/yongboy/archive/2014/02/07/409587.html\n  [3]: http://www.blogjava.net/yongboy/archive/2014/02/09/409630.html","source":"_posts/mqtt-start.md","raw":"---\nlayout: post\ntitle: \"MQTT 基础知识\"\ndate: 2014-12-29\ncategories:\n- mqtt\ntags:\n- mqtt \n- im\n\n---\n\nMQTT是IBM开发的一个即时通讯协议， 广泛运用在移动互联网实时推送以及相关扩展应用上，本文只要简述MQTT协议的部分知识点。\n\n<!-- more -->\n\n### 基础内容\n\nMQTT的固定头部包含以下信息\n\n#### MessageType\n消息类型，使用4位二进制标示，共16种消息类型，其中0和15位做保留待用，实际使用共14种消息事件类型\n\n#### DUP flag \n默认为0，标示该消息为第一次发送，当该值为一时，标示消息先前已经被传输过了，该位前置条件为Qos > 0，标示消息需要回复确认\n\n#### QoS level\n服务质量，由两个二进制位标示\n*　0：至多一次\n*　1：至少一次\n*　2：只有一次\n*　3：保留\n\n#### RETAIN\n是否对PUBLISH消息进行持久化\n* 1：标示需要持久化， 当新订阅者出现时，会收到最新一个持久化消息\n* 2：标示不需要持久化，推送仅对当前订阅者\n**当RETAIN=1，Payload=NULL时标示删除该Topic的持久化PUBLISH消息**\n\n### Topic通配符\n> /：用来表示层次，比如a/b，a/b/c。\n> \\#：表示匹配>=0个层次，比如a/#就匹配a/，a/b，a/b/c。\n> 单独的一个#表示匹配所有。\n> 不允许 a#和a/#/c。\n> +：表示匹配一个层次，例如a/+匹配a/b，a/c，不匹配a/b/c。\n> 单独的一个+是允许的，a+不允许，a/+/b不允许\n\n### 心跳 PINGREQ/PINGRES\nClient告知Server其心跳间隔KeepAliveTime，Client需要在该时长内发送PINGREQ，Server收到后返回PINGRES确认以保持Client与Server的长链接。\nServer在1.5个时长内未收到PINGREQ，就断开连接\nClient在1个时长内未收到Server的PINGRES，就断开连接\n时间最长为18hours，0标示不断开\n\n### Clean Session\n服务端是否保存Client的订阅信息\n* true:保存\n* false:不保持\n\n### 字段建议长度\n* clientId 客户端->服务端, 服务端->客户端的单向唯一标示,length<=23\n* username 用户名,用于身份验证, length<=12\n* password 用户密码,用户身份验证, length<=12\n\n\n### 遗嘱消息 WillMessage\n遗嘱消息标示客户端网络异常导致连接中断后, 服务器将发布该遗嘱消息\n遗嘱消息包含以下信息:\n* Will Flag:是否定义遗嘱消息，Will Flag=1是标示指定遗嘱消息，否则将直接忽略Will Qos，Will RETAIN的值\n* Will Qos:遗嘱消息的通讯质量\n* Will RETAIN:遗嘱消息是否持久化\n* Will Topic:遗嘱消息主题\n* Will Message:遗嘱消息Payload\n\n### 建立连接CONNECT的响应机制\n* 客户端绕过CONNECT消息直接发送其它类型消息，服务器应关闭此非法连接\n* 客户端发送CONNECT之后未收到CONNACT，需要关闭当前连接，然后重新连接\n* 相同Client ID客户端已连接到服务器，先前客户端必须断开连接后，服务器才能完成新的客户端CONNECT连接\n* 客户端发送无效非法CONNECT消息，服务器需要关闭\n\n\n\n### 参考资料\n\n* [MQTT协议简记][1]\n* [MQTT协议笔记之头部信息][2]\n* [MQTT协议笔记之连接和心跳][3]\n\n\n  [1]: http://www.cnblogs.com/caca/p/mqtt.html\n  [2]: http://www.blogjava.net/yongboy/archive/2014/02/07/409587.html\n  [3]: http://www.blogjava.net/yongboy/archive/2014/02/09/409630.html","slug":"mqtt-start","published":1,"updated":"2018-10-11T17:47:50.625Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44o000yl9399devyki9","content":"<p>MQTT是IBM开发的一个即时通讯协议， 广泛运用在移动互联网实时推送以及相关扩展应用上，本文只要简述MQTT协议的部分知识点。</p>\n<a id=\"more\"></a>\n<h3 id=\"基础内容\"><a href=\"#基础内容\" class=\"headerlink\" title=\"基础内容\"></a>基础内容</h3><p>MQTT的固定头部包含以下信息</p>\n<h4 id=\"MessageType\"><a href=\"#MessageType\" class=\"headerlink\" title=\"MessageType\"></a>MessageType</h4><p>消息类型，使用4位二进制标示，共16种消息类型，其中0和15位做保留待用，实际使用共14种消息事件类型</p>\n<h4 id=\"DUP-flag\"><a href=\"#DUP-flag\" class=\"headerlink\" title=\"DUP flag\"></a>DUP flag</h4><p>默认为0，标示该消息为第一次发送，当该值为一时，标示消息先前已经被传输过了，该位前置条件为Qos &gt; 0，标示消息需要回复确认</p>\n<h4 id=\"QoS-level\"><a href=\"#QoS-level\" class=\"headerlink\" title=\"QoS level\"></a>QoS level</h4><p>服务质量，由两个二进制位标示<br><em>　0：至多一次\n</em>　1：至少一次<br><em>　2：只有一次\n</em>　3：保留</p>\n<h4 id=\"RETAIN\"><a href=\"#RETAIN\" class=\"headerlink\" title=\"RETAIN\"></a>RETAIN</h4><p>是否对PUBLISH消息进行持久化</p>\n<ul>\n<li>1：标示需要持久化， 当新订阅者出现时，会收到最新一个持久化消息</li>\n<li>2：标示不需要持久化，推送仅对当前订阅者<br><strong>当RETAIN=1，Payload=NULL时标示删除该Topic的持久化PUBLISH消息</strong></li>\n</ul>\n<h3 id=\"Topic通配符\"><a href=\"#Topic通配符\" class=\"headerlink\" title=\"Topic通配符\"></a>Topic通配符</h3><blockquote>\n<p>/：用来表示层次，比如a/b，a/b/c。<br>#：表示匹配&gt;=0个层次，比如a/#就匹配a/，a/b，a/b/c。<br>单独的一个#表示匹配所有。<br>不允许 a#和a/#/c。<br>+：表示匹配一个层次，例如a/+匹配a/b，a/c，不匹配a/b/c。<br>单独的一个+是允许的，a+不允许，a/+/b不允许</p>\n</blockquote>\n<h3 id=\"心跳-PINGREQ-PINGRES\"><a href=\"#心跳-PINGREQ-PINGRES\" class=\"headerlink\" title=\"心跳 PINGREQ/PINGRES\"></a>心跳 PINGREQ/PINGRES</h3><p>Client告知Server其心跳间隔KeepAliveTime，Client需要在该时长内发送PINGREQ，Server收到后返回PINGRES确认以保持Client与Server的长链接。<br>Server在1.5个时长内未收到PINGREQ，就断开连接<br>Client在1个时长内未收到Server的PINGRES，就断开连接<br>时间最长为18hours，0标示不断开</p>\n<h3 id=\"Clean-Session\"><a href=\"#Clean-Session\" class=\"headerlink\" title=\"Clean Session\"></a>Clean Session</h3><p>服务端是否保存Client的订阅信息</p>\n<ul>\n<li>true:保存</li>\n<li>false:不保持</li>\n</ul>\n<h3 id=\"字段建议长度\"><a href=\"#字段建议长度\" class=\"headerlink\" title=\"字段建议长度\"></a>字段建议长度</h3><ul>\n<li>clientId 客户端-&gt;服务端, 服务端-&gt;客户端的单向唯一标示,length&lt;=23</li>\n<li>username 用户名,用于身份验证, length&lt;=12</li>\n<li>password 用户密码,用户身份验证, length&lt;=12</li>\n</ul>\n<h3 id=\"遗嘱消息-WillMessage\"><a href=\"#遗嘱消息-WillMessage\" class=\"headerlink\" title=\"遗嘱消息 WillMessage\"></a>遗嘱消息 WillMessage</h3><p>遗嘱消息标示客户端网络异常导致连接中断后, 服务器将发布该遗嘱消息<br>遗嘱消息包含以下信息:</p>\n<ul>\n<li>Will Flag:是否定义遗嘱消息，Will Flag=1是标示指定遗嘱消息，否则将直接忽略Will Qos，Will RETAIN的值</li>\n<li>Will Qos:遗嘱消息的通讯质量</li>\n<li>Will RETAIN:遗嘱消息是否持久化</li>\n<li>Will Topic:遗嘱消息主题</li>\n<li>Will Message:遗嘱消息Payload</li>\n</ul>\n<h3 id=\"建立连接CONNECT的响应机制\"><a href=\"#建立连接CONNECT的响应机制\" class=\"headerlink\" title=\"建立连接CONNECT的响应机制\"></a>建立连接CONNECT的响应机制</h3><ul>\n<li>客户端绕过CONNECT消息直接发送其它类型消息，服务器应关闭此非法连接</li>\n<li>客户端发送CONNECT之后未收到CONNACT，需要关闭当前连接，然后重新连接</li>\n<li>相同Client ID客户端已连接到服务器，先前客户端必须断开连接后，服务器才能完成新的客户端CONNECT连接</li>\n<li>客户端发送无效非法CONNECT消息，服务器需要关闭</li>\n</ul>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><ul>\n<li><a href=\"http://www.cnblogs.com/caca/p/mqtt.html\" target=\"_blank\" rel=\"noopener\">MQTT协议简记</a></li>\n<li><a href=\"http://www.blogjava.net/yongboy/archive/2014/02/07/409587.html\" target=\"_blank\" rel=\"noopener\">MQTT协议笔记之头部信息</a></li>\n<li><a href=\"http://www.blogjava.net/yongboy/archive/2014/02/09/409630.html\" target=\"_blank\" rel=\"noopener\">MQTT协议笔记之连接和心跳</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>MQTT是IBM开发的一个即时通讯协议， 广泛运用在移动互联网实时推送以及相关扩展应用上，本文只要简述MQTT协议的部分知识点。</p>","more":"<h3 id=\"基础内容\"><a href=\"#基础内容\" class=\"headerlink\" title=\"基础内容\"></a>基础内容</h3><p>MQTT的固定头部包含以下信息</p>\n<h4 id=\"MessageType\"><a href=\"#MessageType\" class=\"headerlink\" title=\"MessageType\"></a>MessageType</h4><p>消息类型，使用4位二进制标示，共16种消息类型，其中0和15位做保留待用，实际使用共14种消息事件类型</p>\n<h4 id=\"DUP-flag\"><a href=\"#DUP-flag\" class=\"headerlink\" title=\"DUP flag\"></a>DUP flag</h4><p>默认为0，标示该消息为第一次发送，当该值为一时，标示消息先前已经被传输过了，该位前置条件为Qos &gt; 0，标示消息需要回复确认</p>\n<h4 id=\"QoS-level\"><a href=\"#QoS-level\" class=\"headerlink\" title=\"QoS level\"></a>QoS level</h4><p>服务质量，由两个二进制位标示<br><em>　0：至多一次\n</em>　1：至少一次<br><em>　2：只有一次\n</em>　3：保留</p>\n<h4 id=\"RETAIN\"><a href=\"#RETAIN\" class=\"headerlink\" title=\"RETAIN\"></a>RETAIN</h4><p>是否对PUBLISH消息进行持久化</p>\n<ul>\n<li>1：标示需要持久化， 当新订阅者出现时，会收到最新一个持久化消息</li>\n<li>2：标示不需要持久化，推送仅对当前订阅者<br><strong>当RETAIN=1，Payload=NULL时标示删除该Topic的持久化PUBLISH消息</strong></li>\n</ul>\n<h3 id=\"Topic通配符\"><a href=\"#Topic通配符\" class=\"headerlink\" title=\"Topic通配符\"></a>Topic通配符</h3><blockquote>\n<p>/：用来表示层次，比如a/b，a/b/c。<br>#：表示匹配&gt;=0个层次，比如a/#就匹配a/，a/b，a/b/c。<br>单独的一个#表示匹配所有。<br>不允许 a#和a/#/c。<br>+：表示匹配一个层次，例如a/+匹配a/b，a/c，不匹配a/b/c。<br>单独的一个+是允许的，a+不允许，a/+/b不允许</p>\n</blockquote>\n<h3 id=\"心跳-PINGREQ-PINGRES\"><a href=\"#心跳-PINGREQ-PINGRES\" class=\"headerlink\" title=\"心跳 PINGREQ/PINGRES\"></a>心跳 PINGREQ/PINGRES</h3><p>Client告知Server其心跳间隔KeepAliveTime，Client需要在该时长内发送PINGREQ，Server收到后返回PINGRES确认以保持Client与Server的长链接。<br>Server在1.5个时长内未收到PINGREQ，就断开连接<br>Client在1个时长内未收到Server的PINGRES，就断开连接<br>时间最长为18hours，0标示不断开</p>\n<h3 id=\"Clean-Session\"><a href=\"#Clean-Session\" class=\"headerlink\" title=\"Clean Session\"></a>Clean Session</h3><p>服务端是否保存Client的订阅信息</p>\n<ul>\n<li>true:保存</li>\n<li>false:不保持</li>\n</ul>\n<h3 id=\"字段建议长度\"><a href=\"#字段建议长度\" class=\"headerlink\" title=\"字段建议长度\"></a>字段建议长度</h3><ul>\n<li>clientId 客户端-&gt;服务端, 服务端-&gt;客户端的单向唯一标示,length&lt;=23</li>\n<li>username 用户名,用于身份验证, length&lt;=12</li>\n<li>password 用户密码,用户身份验证, length&lt;=12</li>\n</ul>\n<h3 id=\"遗嘱消息-WillMessage\"><a href=\"#遗嘱消息-WillMessage\" class=\"headerlink\" title=\"遗嘱消息 WillMessage\"></a>遗嘱消息 WillMessage</h3><p>遗嘱消息标示客户端网络异常导致连接中断后, 服务器将发布该遗嘱消息<br>遗嘱消息包含以下信息:</p>\n<ul>\n<li>Will Flag:是否定义遗嘱消息，Will Flag=1是标示指定遗嘱消息，否则将直接忽略Will Qos，Will RETAIN的值</li>\n<li>Will Qos:遗嘱消息的通讯质量</li>\n<li>Will RETAIN:遗嘱消息是否持久化</li>\n<li>Will Topic:遗嘱消息主题</li>\n<li>Will Message:遗嘱消息Payload</li>\n</ul>\n<h3 id=\"建立连接CONNECT的响应机制\"><a href=\"#建立连接CONNECT的响应机制\" class=\"headerlink\" title=\"建立连接CONNECT的响应机制\"></a>建立连接CONNECT的响应机制</h3><ul>\n<li>客户端绕过CONNECT消息直接发送其它类型消息，服务器应关闭此非法连接</li>\n<li>客户端发送CONNECT之后未收到CONNACT，需要关闭当前连接，然后重新连接</li>\n<li>相同Client ID客户端已连接到服务器，先前客户端必须断开连接后，服务器才能完成新的客户端CONNECT连接</li>\n<li>客户端发送无效非法CONNECT消息，服务器需要关闭</li>\n</ul>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><ul>\n<li><a href=\"http://www.cnblogs.com/caca/p/mqtt.html\" target=\"_blank\" rel=\"noopener\">MQTT协议简记</a></li>\n<li><a href=\"http://www.blogjava.net/yongboy/archive/2014/02/07/409587.html\" target=\"_blank\" rel=\"noopener\">MQTT协议笔记之头部信息</a></li>\n<li><a href=\"http://www.blogjava.net/yongboy/archive/2014/02/09/409630.html\" target=\"_blank\" rel=\"noopener\">MQTT协议笔记之连接和心跳</a></li>\n</ul>"},{"layout":"post","title":"记一次生产环境Nginx间歇性502的事故分析过程","date":"2017-09-26T16:00:00.000Z","_content":"\n\n最近我们我们在将部分业务从自有机房迁移到国内某云服务器上，在小规模上量后，发现Nginx间接性出现大量502。异常出现的特点是，一瞬间后端多个独立部署的服务全部出现502。\n\n我们的服务架构如下:\n\n```text\n+--------+  HTTP   +-------+  HTTP   +-------+\n| Client | ------> |       | ------> | API A |\n+--------+         |       |         +-------+\n                   |       |  HTTP   +-------+\n                   | Nginx | ------> | API B |\n                   |       |         +-------+\n                   |       |  HTTP   +-------+\n                   |       | ------> | API C |\n                   +-------+         +-------+\n```\n\n一般讲，Nginx 502就是后端处理不过来，但查看监控后端几个API的负载均很低，当前请求的QPS远远低于服务的上限。而且同一瞬间，多套独立部署的API均处理不过来的概率也比较低。\n\n<!-- more -->\n\n我们简单做了个对比测试，分别对域名（请求走Nginx）与直接通过IP对内网一个API通过wrk进行小规模压测。\n![压测截图](http://res.xiezefan.me/images/压测截图.png)\n对比测试发现，直接通过域名走Nginx对API进行压测的话，QPS远远小于预期，并且存在大量失败请求。基本断定问题出在Nginx —> API 这条链路上。同时排除了后端服务响应不过来的可能性。网络问题可能性大一点。\n\n一开始我们怀疑云服务商对内网带宽做了限制，我们观察内网带宽达到在200MB/S后就上不去了，所以我们在Nginx机器上ping后端服务，观察一段时间发现有小量抖动，但基本延迟正常。那云服务商对网络做限制的可能性就变小了很多。\n\n我们观察Nginx错误日志:\n\n```text\n2017/09/26 14:23:00 [error] 4950#4950: *4162133210 no live upstreams while connecting to upstream, client: xxx.xxx.xxx.xxx, server: api.xx.xxxxxxx.cn, request: \"POST /xx/xxxxxx/bidder HTTP/1.1\", upstream: \"http://xxxxxxxxxx/bidder\", host: \"api.xx.xxxxxxx.cn\"\n```\n这里出现`no live upstreams while connecting to upstream`, 也就说一瞬间Nginx检测不到任何存活的后端服务，而网络又没有大波动，那就可能是TCP链接出问题。打开Zabbix监控发现TCP连接数的确发生剧烈的波动现象。\n![异常TCP连接数趋势](http://res.xiezefan.me/images/异常TCP连接数趋势.png)\n\n这时候问题很明显，Nginx->API这一链路存在大量的TCP链接被回收的情况，我们马上在API机器上查看链接状态\n\n```text\nshell > netstat -n | awk '/^tcp/ {++state[$NF]} END {for(key in state) print key,\"\\t\",state[key]}'\nSYN_RECV \t 1\nESTABLISHED \t 656\nFIN_WAIT1 \t 4\nTIME_WAIT \t 153429\n```\n\nTIME_WAIT特别的多，大量的连接被API侧主动关闭了。这说明Nginx->API这一步请求并没有Keep-Alive，我们检查Nginx，确定是配置了Keep-Alive\n\n```\nupstream xxxxxxx {\n    server 172.17.192.98:8087 max_fails=3 fail_timeout=5s weight=1;\n    server 172.17.192.99:8087 max_fails=3 fail_timeout=5s weight=1;\n    keepalive 256;\n}\n```\n\n因为业务的特殊性，我们很确定Client一定为携带Keep-Alive的。那么说明后端API没正确的支持Keep-Alive，我们开始对API代码逻辑进行Review，但我们检查配置，发现服务默认是开启Keep-Alive的，我们进行显式的配置，仍然不起作用。这里存在一个可能性就是我们时候的Web框架有BUG。所以我们接下来做了一个测试，来验证服务是否开启了Keep-Alive。\n![Keep-Alive测试](http://res.xiezefan.me/images/Keep-Alive测试.png)\n我们使用curl连发两次请求，在第二次请求的报文中，我们可以看到`Re-using existing connection`。这说明连接被复用，后端API服务对Keep-Alive的支持是正常的。\n\n这时候就陷入了困境了，求助Google大神后，发现Nginx支持Keep-Alive还需要在配置转发的时候的时候增加以下配置:\n\n```\nlocation ^~ /xxxxx/ {\n    ...\n    proxy_set_header Connection \"Keep-Alive\";\n    ...\n}\n```\n\n贴上配置后，惊奇的发现问题解决了，后端服务器TIME_WAIT的链接下降到2位数，并且也不再出现502现象。棒！\n\n\n### 后续发展\n\n在HTTP 1.0中，Keep-Alive默认是关闭的，需要在请求头显式加上`Connection: Keep-Alive`，才能启用Keep-Alive。但在HTTP 1.1中，该功能默认是开启的，需要使用`Connection: Close`才会禁用Keep-Alive。目前大部分浏览器都是使用HTTP 1.1协议。\n\n我们后来分析所有的Client请求，发现全部都是1.1协议，这就很诡异了。接下来我们在Nginx->API这条链路上捉包，惊奇的发现，竟然出现部分流量是1.0协议的，部分是1.1协议的。这里就解释了为什么会出现连接无法复用的问题。所以我们统一将所有的转发配置都增加了以下规制强制指定使用1.1协议。\n\n```\nlocation ^~ /xxxxxx/ {\n    ...\n    proxy_http_version 1.1;\n    proxy_set_header Connection \"\";\n    ...\n}\n```\n\n但整个事故中，仍然存在几个疑点:\n\n1. 为什么Nginx转发的流量中，会混入1.0协议的请求呢？\n2. 是什么原因导致Nginx或Nginx所在服务器的操作系统在对TCP链接大量回收，并且把正常连接也回收掉导致后端Server \"no live upstreams\"了呢？\n\n目前暂无头绪，后续分析有结果再补上。\n\n\n\n\n\n\n\n","source":"_posts/nginx-502-bug-trace.md","raw":"---\nlayout: post\ntitle: \"记一次生产环境Nginx间歇性502的事故分析过程\"\ndate: 2017-09-27\ncategories:\n- issue-trace\ntags:\n- nginx\n- keepalive\n---\n\n\n最近我们我们在将部分业务从自有机房迁移到国内某云服务器上，在小规模上量后，发现Nginx间接性出现大量502。异常出现的特点是，一瞬间后端多个独立部署的服务全部出现502。\n\n我们的服务架构如下:\n\n```text\n+--------+  HTTP   +-------+  HTTP   +-------+\n| Client | ------> |       | ------> | API A |\n+--------+         |       |         +-------+\n                   |       |  HTTP   +-------+\n                   | Nginx | ------> | API B |\n                   |       |         +-------+\n                   |       |  HTTP   +-------+\n                   |       | ------> | API C |\n                   +-------+         +-------+\n```\n\n一般讲，Nginx 502就是后端处理不过来，但查看监控后端几个API的负载均很低，当前请求的QPS远远低于服务的上限。而且同一瞬间，多套独立部署的API均处理不过来的概率也比较低。\n\n<!-- more -->\n\n我们简单做了个对比测试，分别对域名（请求走Nginx）与直接通过IP对内网一个API通过wrk进行小规模压测。\n![压测截图](http://res.xiezefan.me/images/压测截图.png)\n对比测试发现，直接通过域名走Nginx对API进行压测的话，QPS远远小于预期，并且存在大量失败请求。基本断定问题出在Nginx —> API 这条链路上。同时排除了后端服务响应不过来的可能性。网络问题可能性大一点。\n\n一开始我们怀疑云服务商对内网带宽做了限制，我们观察内网带宽达到在200MB/S后就上不去了，所以我们在Nginx机器上ping后端服务，观察一段时间发现有小量抖动，但基本延迟正常。那云服务商对网络做限制的可能性就变小了很多。\n\n我们观察Nginx错误日志:\n\n```text\n2017/09/26 14:23:00 [error] 4950#4950: *4162133210 no live upstreams while connecting to upstream, client: xxx.xxx.xxx.xxx, server: api.xx.xxxxxxx.cn, request: \"POST /xx/xxxxxx/bidder HTTP/1.1\", upstream: \"http://xxxxxxxxxx/bidder\", host: \"api.xx.xxxxxxx.cn\"\n```\n这里出现`no live upstreams while connecting to upstream`, 也就说一瞬间Nginx检测不到任何存活的后端服务，而网络又没有大波动，那就可能是TCP链接出问题。打开Zabbix监控发现TCP连接数的确发生剧烈的波动现象。\n![异常TCP连接数趋势](http://res.xiezefan.me/images/异常TCP连接数趋势.png)\n\n这时候问题很明显，Nginx->API这一链路存在大量的TCP链接被回收的情况，我们马上在API机器上查看链接状态\n\n```text\nshell > netstat -n | awk '/^tcp/ {++state[$NF]} END {for(key in state) print key,\"\\t\",state[key]}'\nSYN_RECV \t 1\nESTABLISHED \t 656\nFIN_WAIT1 \t 4\nTIME_WAIT \t 153429\n```\n\nTIME_WAIT特别的多，大量的连接被API侧主动关闭了。这说明Nginx->API这一步请求并没有Keep-Alive，我们检查Nginx，确定是配置了Keep-Alive\n\n```\nupstream xxxxxxx {\n    server 172.17.192.98:8087 max_fails=3 fail_timeout=5s weight=1;\n    server 172.17.192.99:8087 max_fails=3 fail_timeout=5s weight=1;\n    keepalive 256;\n}\n```\n\n因为业务的特殊性，我们很确定Client一定为携带Keep-Alive的。那么说明后端API没正确的支持Keep-Alive，我们开始对API代码逻辑进行Review，但我们检查配置，发现服务默认是开启Keep-Alive的，我们进行显式的配置，仍然不起作用。这里存在一个可能性就是我们时候的Web框架有BUG。所以我们接下来做了一个测试，来验证服务是否开启了Keep-Alive。\n![Keep-Alive测试](http://res.xiezefan.me/images/Keep-Alive测试.png)\n我们使用curl连发两次请求，在第二次请求的报文中，我们可以看到`Re-using existing connection`。这说明连接被复用，后端API服务对Keep-Alive的支持是正常的。\n\n这时候就陷入了困境了，求助Google大神后，发现Nginx支持Keep-Alive还需要在配置转发的时候的时候增加以下配置:\n\n```\nlocation ^~ /xxxxx/ {\n    ...\n    proxy_set_header Connection \"Keep-Alive\";\n    ...\n}\n```\n\n贴上配置后，惊奇的发现问题解决了，后端服务器TIME_WAIT的链接下降到2位数，并且也不再出现502现象。棒！\n\n\n### 后续发展\n\n在HTTP 1.0中，Keep-Alive默认是关闭的，需要在请求头显式加上`Connection: Keep-Alive`，才能启用Keep-Alive。但在HTTP 1.1中，该功能默认是开启的，需要使用`Connection: Close`才会禁用Keep-Alive。目前大部分浏览器都是使用HTTP 1.1协议。\n\n我们后来分析所有的Client请求，发现全部都是1.1协议，这就很诡异了。接下来我们在Nginx->API这条链路上捉包，惊奇的发现，竟然出现部分流量是1.0协议的，部分是1.1协议的。这里就解释了为什么会出现连接无法复用的问题。所以我们统一将所有的转发配置都增加了以下规制强制指定使用1.1协议。\n\n```\nlocation ^~ /xxxxxx/ {\n    ...\n    proxy_http_version 1.1;\n    proxy_set_header Connection \"\";\n    ...\n}\n```\n\n但整个事故中，仍然存在几个疑点:\n\n1. 为什么Nginx转发的流量中，会混入1.0协议的请求呢？\n2. 是什么原因导致Nginx或Nginx所在服务器的操作系统在对TCP链接大量回收，并且把正常连接也回收掉导致后端Server \"no live upstreams\"了呢？\n\n目前暂无头绪，后续分析有结果再补上。\n\n\n\n\n\n\n\n","slug":"nginx-502-bug-trace","published":1,"updated":"2018-10-12T02:09:53.869Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44q0012l939ec2yolbz","content":"<p>最近我们我们在将部分业务从自有机房迁移到国内某云服务器上，在小规模上量后，发现Nginx间接性出现大量502。异常出现的特点是，一瞬间后端多个独立部署的服务全部出现502。</p>\n<p>我们的服务架构如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">+--------+  HTTP   +-------+  HTTP   +-------+</span><br><span class=\"line\">| Client | ------&gt; |       | ------&gt; | API A |</span><br><span class=\"line\">+--------+         |       |         +-------+</span><br><span class=\"line\">                   |       |  HTTP   +-------+</span><br><span class=\"line\">                   | Nginx | ------&gt; | API B |</span><br><span class=\"line\">                   |       |         +-------+</span><br><span class=\"line\">                   |       |  HTTP   +-------+</span><br><span class=\"line\">                   |       | ------&gt; | API C |</span><br><span class=\"line\">                   +-------+         +-------+</span><br></pre></td></tr></table></figure>\n<p>一般讲，Nginx 502就是后端处理不过来，但查看监控后端几个API的负载均很低，当前请求的QPS远远低于服务的上限。而且同一瞬间，多套独立部署的API均处理不过来的概率也比较低。</p>\n<a id=\"more\"></a>\n<p>我们简单做了个对比测试，分别对域名（请求走Nginx）与直接通过IP对内网一个API通过wrk进行小规模压测。<br><img src=\"http://res.xiezefan.me/images/压测截图.png\" alt=\"压测截图\"><br>对比测试发现，直接通过域名走Nginx对API进行压测的话，QPS远远小于预期，并且存在大量失败请求。基本断定问题出在Nginx —&gt; API 这条链路上。同时排除了后端服务响应不过来的可能性。网络问题可能性大一点。</p>\n<p>一开始我们怀疑云服务商对内网带宽做了限制，我们观察内网带宽达到在200MB/S后就上不去了，所以我们在Nginx机器上ping后端服务，观察一段时间发现有小量抖动，但基本延迟正常。那云服务商对网络做限制的可能性就变小了很多。</p>\n<p>我们观察Nginx错误日志:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">2017/09/26 14:23:00 [error] 4950#4950: *4162133210 no live upstreams while connecting to upstream, client: xxx.xxx.xxx.xxx, server: api.xx.xxxxxxx.cn, request: &quot;POST /xx/xxxxxx/bidder HTTP/1.1&quot;, upstream: &quot;http://xxxxxxxxxx/bidder&quot;, host: &quot;api.xx.xxxxxxx.cn&quot;</span><br></pre></td></tr></table></figure>\n<p>这里出现<code>no live upstreams while connecting to upstream</code>, 也就说一瞬间Nginx检测不到任何存活的后端服务，而网络又没有大波动，那就可能是TCP链接出问题。打开Zabbix监控发现TCP连接数的确发生剧烈的波动现象。<br><img src=\"http://res.xiezefan.me/images/异常TCP连接数趋势.png\" alt=\"异常TCP连接数趋势\"></p>\n<p>这时候问题很明显，Nginx-&gt;API这一链路存在大量的TCP链接被回收的情况，我们马上在API机器上查看链接状态</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">shell &gt; netstat -n | awk &apos;/^tcp/ &#123;++state[$NF]&#125; END &#123;for(key in state) print key,&quot;\\t&quot;,state[key]&#125;&apos;</span><br><span class=\"line\">SYN_RECV \t 1</span><br><span class=\"line\">ESTABLISHED \t 656</span><br><span class=\"line\">FIN_WAIT1 \t 4</span><br><span class=\"line\">TIME_WAIT \t 153429</span><br></pre></td></tr></table></figure>\n<p>TIME_WAIT特别的多，大量的连接被API侧主动关闭了。这说明Nginx-&gt;API这一步请求并没有Keep-Alive，我们检查Nginx，确定是配置了Keep-Alive</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream xxxxxxx &#123;</span><br><span class=\"line\">    server 172.17.192.98:8087 max_fails=3 fail_timeout=5s weight=1;</span><br><span class=\"line\">    server 172.17.192.99:8087 max_fails=3 fail_timeout=5s weight=1;</span><br><span class=\"line\">    keepalive 256;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>因为业务的特殊性，我们很确定Client一定为携带Keep-Alive的。那么说明后端API没正确的支持Keep-Alive，我们开始对API代码逻辑进行Review，但我们检查配置，发现服务默认是开启Keep-Alive的，我们进行显式的配置，仍然不起作用。这里存在一个可能性就是我们时候的Web框架有BUG。所以我们接下来做了一个测试，来验证服务是否开启了Keep-Alive。<br><img src=\"http://res.xiezefan.me/images/Keep-Alive测试.png\" alt=\"Keep-Alive测试\"><br>我们使用curl连发两次请求，在第二次请求的报文中，我们可以看到<code>Re-using existing connection</code>。这说明连接被复用，后端API服务对Keep-Alive的支持是正常的。</p>\n<p>这时候就陷入了困境了，求助Google大神后，发现Nginx支持Keep-Alive还需要在配置转发的时候的时候增加以下配置:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">location ^~ /xxxxx/ &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    proxy_set_header Connection &quot;Keep-Alive&quot;;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>贴上配置后，惊奇的发现问题解决了，后端服务器TIME_WAIT的链接下降到2位数，并且也不再出现502现象。棒！</p>\n<h3 id=\"后续发展\"><a href=\"#后续发展\" class=\"headerlink\" title=\"后续发展\"></a>后续发展</h3><p>在HTTP 1.0中，Keep-Alive默认是关闭的，需要在请求头显式加上<code>Connection: Keep-Alive</code>，才能启用Keep-Alive。但在HTTP 1.1中，该功能默认是开启的，需要使用<code>Connection: Close</code>才会禁用Keep-Alive。目前大部分浏览器都是使用HTTP 1.1协议。</p>\n<p>我们后来分析所有的Client请求，发现全部都是1.1协议，这就很诡异了。接下来我们在Nginx-&gt;API这条链路上捉包，惊奇的发现，竟然出现部分流量是1.0协议的，部分是1.1协议的。这里就解释了为什么会出现连接无法复用的问题。所以我们统一将所有的转发配置都增加了以下规制强制指定使用1.1协议。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">location ^~ /xxxxxx/ &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    proxy_http_version 1.1;</span><br><span class=\"line\">    proxy_set_header Connection &quot;&quot;;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>但整个事故中，仍然存在几个疑点:</p>\n<ol>\n<li>为什么Nginx转发的流量中，会混入1.0协议的请求呢？</li>\n<li>是什么原因导致Nginx或Nginx所在服务器的操作系统在对TCP链接大量回收，并且把正常连接也回收掉导致后端Server “no live upstreams”了呢？</li>\n</ol>\n<p>目前暂无头绪，后续分析有结果再补上。</p>\n","site":{"data":{}},"excerpt":"<p>最近我们我们在将部分业务从自有机房迁移到国内某云服务器上，在小规模上量后，发现Nginx间接性出现大量502。异常出现的特点是，一瞬间后端多个独立部署的服务全部出现502。</p>\n<p>我们的服务架构如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">+--------+  HTTP   +-------+  HTTP   +-------+</span><br><span class=\"line\">| Client | ------&gt; |       | ------&gt; | API A |</span><br><span class=\"line\">+--------+         |       |         +-------+</span><br><span class=\"line\">                   |       |  HTTP   +-------+</span><br><span class=\"line\">                   | Nginx | ------&gt; | API B |</span><br><span class=\"line\">                   |       |         +-------+</span><br><span class=\"line\">                   |       |  HTTP   +-------+</span><br><span class=\"line\">                   |       | ------&gt; | API C |</span><br><span class=\"line\">                   +-------+         +-------+</span><br></pre></td></tr></table></figure>\n<p>一般讲，Nginx 502就是后端处理不过来，但查看监控后端几个API的负载均很低，当前请求的QPS远远低于服务的上限。而且同一瞬间，多套独立部署的API均处理不过来的概率也比较低。</p>","more":"<p>我们简单做了个对比测试，分别对域名（请求走Nginx）与直接通过IP对内网一个API通过wrk进行小规模压测。<br><img src=\"http://res.xiezefan.me/images/压测截图.png\" alt=\"压测截图\"><br>对比测试发现，直接通过域名走Nginx对API进行压测的话，QPS远远小于预期，并且存在大量失败请求。基本断定问题出在Nginx —&gt; API 这条链路上。同时排除了后端服务响应不过来的可能性。网络问题可能性大一点。</p>\n<p>一开始我们怀疑云服务商对内网带宽做了限制，我们观察内网带宽达到在200MB/S后就上不去了，所以我们在Nginx机器上ping后端服务，观察一段时间发现有小量抖动，但基本延迟正常。那云服务商对网络做限制的可能性就变小了很多。</p>\n<p>我们观察Nginx错误日志:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">2017/09/26 14:23:00 [error] 4950#4950: *4162133210 no live upstreams while connecting to upstream, client: xxx.xxx.xxx.xxx, server: api.xx.xxxxxxx.cn, request: &quot;POST /xx/xxxxxx/bidder HTTP/1.1&quot;, upstream: &quot;http://xxxxxxxxxx/bidder&quot;, host: &quot;api.xx.xxxxxxx.cn&quot;</span><br></pre></td></tr></table></figure>\n<p>这里出现<code>no live upstreams while connecting to upstream</code>, 也就说一瞬间Nginx检测不到任何存活的后端服务，而网络又没有大波动，那就可能是TCP链接出问题。打开Zabbix监控发现TCP连接数的确发生剧烈的波动现象。<br><img src=\"http://res.xiezefan.me/images/异常TCP连接数趋势.png\" alt=\"异常TCP连接数趋势\"></p>\n<p>这时候问题很明显，Nginx-&gt;API这一链路存在大量的TCP链接被回收的情况，我们马上在API机器上查看链接状态</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">shell &gt; netstat -n | awk &apos;/^tcp/ &#123;++state[$NF]&#125; END &#123;for(key in state) print key,&quot;\\t&quot;,state[key]&#125;&apos;</span><br><span class=\"line\">SYN_RECV \t 1</span><br><span class=\"line\">ESTABLISHED \t 656</span><br><span class=\"line\">FIN_WAIT1 \t 4</span><br><span class=\"line\">TIME_WAIT \t 153429</span><br></pre></td></tr></table></figure>\n<p>TIME_WAIT特别的多，大量的连接被API侧主动关闭了。这说明Nginx-&gt;API这一步请求并没有Keep-Alive，我们检查Nginx，确定是配置了Keep-Alive</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">upstream xxxxxxx &#123;</span><br><span class=\"line\">    server 172.17.192.98:8087 max_fails=3 fail_timeout=5s weight=1;</span><br><span class=\"line\">    server 172.17.192.99:8087 max_fails=3 fail_timeout=5s weight=1;</span><br><span class=\"line\">    keepalive 256;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>因为业务的特殊性，我们很确定Client一定为携带Keep-Alive的。那么说明后端API没正确的支持Keep-Alive，我们开始对API代码逻辑进行Review，但我们检查配置，发现服务默认是开启Keep-Alive的，我们进行显式的配置，仍然不起作用。这里存在一个可能性就是我们时候的Web框架有BUG。所以我们接下来做了一个测试，来验证服务是否开启了Keep-Alive。<br><img src=\"http://res.xiezefan.me/images/Keep-Alive测试.png\" alt=\"Keep-Alive测试\"><br>我们使用curl连发两次请求，在第二次请求的报文中，我们可以看到<code>Re-using existing connection</code>。这说明连接被复用，后端API服务对Keep-Alive的支持是正常的。</p>\n<p>这时候就陷入了困境了，求助Google大神后，发现Nginx支持Keep-Alive还需要在配置转发的时候的时候增加以下配置:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">location ^~ /xxxxx/ &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    proxy_set_header Connection &quot;Keep-Alive&quot;;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>贴上配置后，惊奇的发现问题解决了，后端服务器TIME_WAIT的链接下降到2位数，并且也不再出现502现象。棒！</p>\n<h3 id=\"后续发展\"><a href=\"#后续发展\" class=\"headerlink\" title=\"后续发展\"></a>后续发展</h3><p>在HTTP 1.0中，Keep-Alive默认是关闭的，需要在请求头显式加上<code>Connection: Keep-Alive</code>，才能启用Keep-Alive。但在HTTP 1.1中，该功能默认是开启的，需要使用<code>Connection: Close</code>才会禁用Keep-Alive。目前大部分浏览器都是使用HTTP 1.1协议。</p>\n<p>我们后来分析所有的Client请求，发现全部都是1.1协议，这就很诡异了。接下来我们在Nginx-&gt;API这条链路上捉包，惊奇的发现，竟然出现部分流量是1.0协议的，部分是1.1协议的。这里就解释了为什么会出现连接无法复用的问题。所以我们统一将所有的转发配置都增加了以下规制强制指定使用1.1协议。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">location ^~ /xxxxxx/ &#123;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">    proxy_http_version 1.1;</span><br><span class=\"line\">    proxy_set_header Connection &quot;&quot;;</span><br><span class=\"line\">    ...</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>但整个事故中，仍然存在几个疑点:</p>\n<ol>\n<li>为什么Nginx转发的流量中，会混入1.0协议的请求呢？</li>\n<li>是什么原因导致Nginx或Nginx所在服务器的操作系统在对TCP链接大量回收，并且把正常连接也回收掉导致后端Server “no live upstreams”了呢？</li>\n</ol>\n<p>目前暂无头绪，后续分析有结果再补上。</p>"},{"layout":"post","title":"生成力工具【瀑布IM】正确使用手册","date":"2015-10-23T16:00:00.000Z","_content":"\n\n去年的这个时候，国外的企业协作工具[Slack](https://slack.com/)的报告铺天盖地，如今一年过去，Slack已经估值30亿美金，成了新的明星独角兽公司。  \n    \n不过Slack毕竟作为一款境外的软件，网络访问以及语言障碍在团队内推广还是挺成问题的。而近一年来，国内也涌现出一批类Slack的国产应用。如[瀑布IM](https://beta.pubu.im/)，[纷云](https://lesschat.com/)，[Bearychat](https://bearychat.com)等。\n\n\n<!-- more -->\n\n\n先简单介绍下我们团队的现状，目前我们使用Gitlab + Tower.im + 瀑布IM，团队成员提交Pull Request后，需要其他成员Review才能合并进Master分支。而项目正处于前期开发阶段，对BUG的收集整理并不需要像生产环境的项目一样走一个复杂的流程，所以我们使用Tower.im来进行项目任务管理与BUG追踪。 \n\n![Tower.im](http://res.xiezefan.me/images/blog/tower_screen.png)  \n\n无意中在Tower.im的主页上看到瀑布IM的介绍，试用了下效果非常不错，推广到整个开发小组，组内成员普遍好评，简单地设置了WebHooks就接入了Gitlab与Tower.im， 小组成员提交了代码，创建Pull Request，在Tower上创建/讨论/完成任务，第一时间在瀑布IM上就可以收到消息，这在团队密切协作的时候特别有用，你能快速地了解到，你的队友在做什么。所有地碎片化消息都统一地在一个平台内展示。\n\n![Pubu.im Screen](http://res.xiezefan.me/images/blog/pubu_im_screen.png?t=1)\n\n在以往，我们用QQ群，QQ讨论组做团队沟通，有时候很无奈，QQ上掺杂着很多私人的关系在上面，工作时候的确会有一些干扰，瀑布IM的组内讨论，体验上虽然有些许比不上QQ，但作为工作讨论可以屏蔽掉很多干扰。并且我很喜欢其中的一个功能，瀑布IM会收集团队聊天中的图片，文件，代码片段，特别是链接片段，这无疑是一个需求痛点，工作中，我经常翻好几页聊天记录去找同事N天前发给我的测试页面的链接。\n\n![Pubu.im Files Collection](http://res.xiezefan.me/images/blog/pubu_im_files_collection.jpg)\n\n\n### 自定义扩展\n\n瀑布IM也提供了自定义扩展，方便有开发能力的用户接入内部的管理系统，其主要有\n\n输出类：\n\n* Command命令\n* Outgoing\n\n\n接入类：\n\n* 代收邮件\n* Incomming\n\n\n输出类定义一个聊天事件，当聊天事件触发的时候，会往你指定的URL POST一些数据，接入类则通过设置Webhooks，当事件触发时，开发者主动调用Webhoods发送数据向指定渠道推送消息。 \n\n我试验了一下[Incoming服务](https://blog.pubu.im/how-to-add-incoming/)，背景是这样，当一个用户支付了订单时候，服务端会进行一些Webhookds回调，正常情况下，我需要编写一个程序以查看回调通知的内容，在此之前，我使用纷云的开源Webhooks调试框架 - [Request](http://request.lesschat.com/)，为了试验瀑布IM的Incoming服务，我用Nodejs编写了一个简单的转发Webhooks的程序，当收到回调后，程序格式化文本并调用瀑布IM的回调接口。\n\n```javascript\nrequest({\n    uri: 'https://hooks.pubu.im/services/xxxxxxx',\n    method: 'POST',\n    json: {text:text, attachments:attachments, displayUser:displayUser},\n    headers : {'Content-Type' : 'application/json'}\n}, function(err, rep) {\n    if (err) {\n        return console.log(err);\n    }\n    console.log(JSON.stringify(rep.body));\n});\n```\n\n![Pubu.im Custom Service](http://res.xiezefan.me/images/blog/pubu_im_custom_service.png)  \n\n\n有一点需要吐槽的是，瀑布IM提供的API有一个BUG，当未指定`Content-Type=application/json`的时候，API会抛500异常，回复邮件反馈也不是很迅速，最后还是我自己找到原因的。不过考虑到目前该产品仍然处于Beta版本，还是可以理解的。另外，在JSON中使用驼峰式命名是很不专业的行为呀。\n\n\n### 额外的话\n\n昨天和一位跳槽某大型互联网公司的前同事聊天，他同我吐槽说公司对第三方生成力工具很克制，禁止员工使用其他第三方平台提供管理工具，理由不外乎信息安全，而一般大型互联网公司的内部工具难免跟不上时代，效率上总有些瑕疵。像Tower.im，Teambition，瀑布IM这些工具想在内部推广阻力重重，而反倒乎创业团队，无须考虑太多这些事情，执行力也高，能第一时间体验这些提供工作效率的生产力工具。只不过在国内的大环境下，如何探索出一套可行的商业模式当下还是路漫漫。\n\n\n\n\n\n","source":"_posts/pubu_im_start.md","raw":"---\nlayout: post\ntitle: \"生成力工具【瀑布IM】正确使用手册\"\ndate: 2015-10-24\ncategories:\n- tools\ntags:\n- tools\n\n---\n\n\n去年的这个时候，国外的企业协作工具[Slack](https://slack.com/)的报告铺天盖地，如今一年过去，Slack已经估值30亿美金，成了新的明星独角兽公司。  \n    \n不过Slack毕竟作为一款境外的软件，网络访问以及语言障碍在团队内推广还是挺成问题的。而近一年来，国内也涌现出一批类Slack的国产应用。如[瀑布IM](https://beta.pubu.im/)，[纷云](https://lesschat.com/)，[Bearychat](https://bearychat.com)等。\n\n\n<!-- more -->\n\n\n先简单介绍下我们团队的现状，目前我们使用Gitlab + Tower.im + 瀑布IM，团队成员提交Pull Request后，需要其他成员Review才能合并进Master分支。而项目正处于前期开发阶段，对BUG的收集整理并不需要像生产环境的项目一样走一个复杂的流程，所以我们使用Tower.im来进行项目任务管理与BUG追踪。 \n\n![Tower.im](http://res.xiezefan.me/images/blog/tower_screen.png)  \n\n无意中在Tower.im的主页上看到瀑布IM的介绍，试用了下效果非常不错，推广到整个开发小组，组内成员普遍好评，简单地设置了WebHooks就接入了Gitlab与Tower.im， 小组成员提交了代码，创建Pull Request，在Tower上创建/讨论/完成任务，第一时间在瀑布IM上就可以收到消息，这在团队密切协作的时候特别有用，你能快速地了解到，你的队友在做什么。所有地碎片化消息都统一地在一个平台内展示。\n\n![Pubu.im Screen](http://res.xiezefan.me/images/blog/pubu_im_screen.png?t=1)\n\n在以往，我们用QQ群，QQ讨论组做团队沟通，有时候很无奈，QQ上掺杂着很多私人的关系在上面，工作时候的确会有一些干扰，瀑布IM的组内讨论，体验上虽然有些许比不上QQ，但作为工作讨论可以屏蔽掉很多干扰。并且我很喜欢其中的一个功能，瀑布IM会收集团队聊天中的图片，文件，代码片段，特别是链接片段，这无疑是一个需求痛点，工作中，我经常翻好几页聊天记录去找同事N天前发给我的测试页面的链接。\n\n![Pubu.im Files Collection](http://res.xiezefan.me/images/blog/pubu_im_files_collection.jpg)\n\n\n### 自定义扩展\n\n瀑布IM也提供了自定义扩展，方便有开发能力的用户接入内部的管理系统，其主要有\n\n输出类：\n\n* Command命令\n* Outgoing\n\n\n接入类：\n\n* 代收邮件\n* Incomming\n\n\n输出类定义一个聊天事件，当聊天事件触发的时候，会往你指定的URL POST一些数据，接入类则通过设置Webhooks，当事件触发时，开发者主动调用Webhoods发送数据向指定渠道推送消息。 \n\n我试验了一下[Incoming服务](https://blog.pubu.im/how-to-add-incoming/)，背景是这样，当一个用户支付了订单时候，服务端会进行一些Webhookds回调，正常情况下，我需要编写一个程序以查看回调通知的内容，在此之前，我使用纷云的开源Webhooks调试框架 - [Request](http://request.lesschat.com/)，为了试验瀑布IM的Incoming服务，我用Nodejs编写了一个简单的转发Webhooks的程序，当收到回调后，程序格式化文本并调用瀑布IM的回调接口。\n\n```javascript\nrequest({\n    uri: 'https://hooks.pubu.im/services/xxxxxxx',\n    method: 'POST',\n    json: {text:text, attachments:attachments, displayUser:displayUser},\n    headers : {'Content-Type' : 'application/json'}\n}, function(err, rep) {\n    if (err) {\n        return console.log(err);\n    }\n    console.log(JSON.stringify(rep.body));\n});\n```\n\n![Pubu.im Custom Service](http://res.xiezefan.me/images/blog/pubu_im_custom_service.png)  \n\n\n有一点需要吐槽的是，瀑布IM提供的API有一个BUG，当未指定`Content-Type=application/json`的时候，API会抛500异常，回复邮件反馈也不是很迅速，最后还是我自己找到原因的。不过考虑到目前该产品仍然处于Beta版本，还是可以理解的。另外，在JSON中使用驼峰式命名是很不专业的行为呀。\n\n\n### 额外的话\n\n昨天和一位跳槽某大型互联网公司的前同事聊天，他同我吐槽说公司对第三方生成力工具很克制，禁止员工使用其他第三方平台提供管理工具，理由不外乎信息安全，而一般大型互联网公司的内部工具难免跟不上时代，效率上总有些瑕疵。像Tower.im，Teambition，瀑布IM这些工具想在内部推广阻力重重，而反倒乎创业团队，无须考虑太多这些事情，执行力也高，能第一时间体验这些提供工作效率的生产力工具。只不过在国内的大环境下，如何探索出一套可行的商业模式当下还是路漫漫。\n\n\n\n\n\n","slug":"pubu_im_start","published":1,"updated":"2018-10-12T02:09:54.508Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44r0014l939bldcc3b9","content":"<p>去年的这个时候，国外的企业协作工具<a href=\"https://slack.com/\" target=\"_blank\" rel=\"noopener\">Slack</a>的报告铺天盖地，如今一年过去，Slack已经估值30亿美金，成了新的明星独角兽公司。  </p>\n<p>不过Slack毕竟作为一款境外的软件，网络访问以及语言障碍在团队内推广还是挺成问题的。而近一年来，国内也涌现出一批类Slack的国产应用。如<a href=\"https://beta.pubu.im/\" target=\"_blank\" rel=\"noopener\">瀑布IM</a>，<a href=\"https://lesschat.com/\" target=\"_blank\" rel=\"noopener\">纷云</a>，<a href=\"https://bearychat.com\" target=\"_blank\" rel=\"noopener\">Bearychat</a>等。</p>\n<a id=\"more\"></a>\n<p>先简单介绍下我们团队的现状，目前我们使用Gitlab + Tower.im + 瀑布IM，团队成员提交Pull Request后，需要其他成员Review才能合并进Master分支。而项目正处于前期开发阶段，对BUG的收集整理并不需要像生产环境的项目一样走一个复杂的流程，所以我们使用Tower.im来进行项目任务管理与BUG追踪。 </p>\n<p><img src=\"http://res.xiezefan.me/images/blog/tower_screen.png\" alt=\"Tower.im\">  </p>\n<p>无意中在Tower.im的主页上看到瀑布IM的介绍，试用了下效果非常不错，推广到整个开发小组，组内成员普遍好评，简单地设置了WebHooks就接入了Gitlab与Tower.im， 小组成员提交了代码，创建Pull Request，在Tower上创建/讨论/完成任务，第一时间在瀑布IM上就可以收到消息，这在团队密切协作的时候特别有用，你能快速地了解到，你的队友在做什么。所有地碎片化消息都统一地在一个平台内展示。</p>\n<p><img src=\"http://res.xiezefan.me/images/blog/pubu_im_screen.png?t=1\" alt=\"Pubu.im Screen\"></p>\n<p>在以往，我们用QQ群，QQ讨论组做团队沟通，有时候很无奈，QQ上掺杂着很多私人的关系在上面，工作时候的确会有一些干扰，瀑布IM的组内讨论，体验上虽然有些许比不上QQ，但作为工作讨论可以屏蔽掉很多干扰。并且我很喜欢其中的一个功能，瀑布IM会收集团队聊天中的图片，文件，代码片段，特别是链接片段，这无疑是一个需求痛点，工作中，我经常翻好几页聊天记录去找同事N天前发给我的测试页面的链接。</p>\n<p><img src=\"http://res.xiezefan.me/images/blog/pubu_im_files_collection.jpg\" alt=\"Pubu.im Files Collection\"></p>\n<h3 id=\"自定义扩展\"><a href=\"#自定义扩展\" class=\"headerlink\" title=\"自定义扩展\"></a>自定义扩展</h3><p>瀑布IM也提供了自定义扩展，方便有开发能力的用户接入内部的管理系统，其主要有</p>\n<p>输出类：</p>\n<ul>\n<li>Command命令</li>\n<li>Outgoing</li>\n</ul>\n<p>接入类：</p>\n<ul>\n<li>代收邮件</li>\n<li>Incomming</li>\n</ul>\n<p>输出类定义一个聊天事件，当聊天事件触发的时候，会往你指定的URL POST一些数据，接入类则通过设置Webhooks，当事件触发时，开发者主动调用Webhoods发送数据向指定渠道推送消息。 </p>\n<p>我试验了一下<a href=\"https://blog.pubu.im/how-to-add-incoming/\" target=\"_blank\" rel=\"noopener\">Incoming服务</a>，背景是这样，当一个用户支付了订单时候，服务端会进行一些Webhookds回调，正常情况下，我需要编写一个程序以查看回调通知的内容，在此之前，我使用纷云的开源Webhooks调试框架 - <a href=\"http://request.lesschat.com/\" target=\"_blank\" rel=\"noopener\">Request</a>，为了试验瀑布IM的Incoming服务，我用Nodejs编写了一个简单的转发Webhooks的程序，当收到回调后，程序格式化文本并调用瀑布IM的回调接口。</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"code\"><pre><span class=\"line\">request(&#123;</span><br><span class=\"line\">    uri: <span class=\"string\">'https://hooks.pubu.im/services/xxxxxxx'</span>,</span><br><span class=\"line\">    method: <span class=\"string\">'POST'</span>,</span><br><span class=\"line\">    json: &#123;<span class=\"attr\">text</span>:text, <span class=\"attr\">attachments</span>:attachments, <span class=\"attr\">displayUser</span>:displayUser&#125;,</span><br><span class=\"line\">    headers : &#123;<span class=\"string\">'Content-Type'</span> : <span class=\"string\">'application/json'</span>&#125;</span><br><span class=\"line\">&#125;, <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">err, rep</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (err) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">console</span>.log(err);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(<span class=\"built_in\">JSON</span>.stringify(rep.body));</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://res.xiezefan.me/images/blog/pubu_im_custom_service.png\" alt=\"Pubu.im Custom Service\">  </p>\n<p>有一点需要吐槽的是，瀑布IM提供的API有一个BUG，当未指定<code>Content-Type=application/json</code>的时候，API会抛500异常，回复邮件反馈也不是很迅速，最后还是我自己找到原因的。不过考虑到目前该产品仍然处于Beta版本，还是可以理解的。另外，在JSON中使用驼峰式命名是很不专业的行为呀。</p>\n<h3 id=\"额外的话\"><a href=\"#额外的话\" class=\"headerlink\" title=\"额外的话\"></a>额外的话</h3><p>昨天和一位跳槽某大型互联网公司的前同事聊天，他同我吐槽说公司对第三方生成力工具很克制，禁止员工使用其他第三方平台提供管理工具，理由不外乎信息安全，而一般大型互联网公司的内部工具难免跟不上时代，效率上总有些瑕疵。像Tower.im，Teambition，瀑布IM这些工具想在内部推广阻力重重，而反倒乎创业团队，无须考虑太多这些事情，执行力也高，能第一时间体验这些提供工作效率的生产力工具。只不过在国内的大环境下，如何探索出一套可行的商业模式当下还是路漫漫。</p>\n","site":{"data":{}},"excerpt":"<p>去年的这个时候，国外的企业协作工具<a href=\"https://slack.com/\" target=\"_blank\" rel=\"noopener\">Slack</a>的报告铺天盖地，如今一年过去，Slack已经估值30亿美金，成了新的明星独角兽公司。  </p>\n<p>不过Slack毕竟作为一款境外的软件，网络访问以及语言障碍在团队内推广还是挺成问题的。而近一年来，国内也涌现出一批类Slack的国产应用。如<a href=\"https://beta.pubu.im/\" target=\"_blank\" rel=\"noopener\">瀑布IM</a>，<a href=\"https://lesschat.com/\" target=\"_blank\" rel=\"noopener\">纷云</a>，<a href=\"https://bearychat.com\" target=\"_blank\" rel=\"noopener\">Bearychat</a>等。</p>","more":"<p>先简单介绍下我们团队的现状，目前我们使用Gitlab + Tower.im + 瀑布IM，团队成员提交Pull Request后，需要其他成员Review才能合并进Master分支。而项目正处于前期开发阶段，对BUG的收集整理并不需要像生产环境的项目一样走一个复杂的流程，所以我们使用Tower.im来进行项目任务管理与BUG追踪。 </p>\n<p><img src=\"http://res.xiezefan.me/images/blog/tower_screen.png\" alt=\"Tower.im\">  </p>\n<p>无意中在Tower.im的主页上看到瀑布IM的介绍，试用了下效果非常不错，推广到整个开发小组，组内成员普遍好评，简单地设置了WebHooks就接入了Gitlab与Tower.im， 小组成员提交了代码，创建Pull Request，在Tower上创建/讨论/完成任务，第一时间在瀑布IM上就可以收到消息，这在团队密切协作的时候特别有用，你能快速地了解到，你的队友在做什么。所有地碎片化消息都统一地在一个平台内展示。</p>\n<p><img src=\"http://res.xiezefan.me/images/blog/pubu_im_screen.png?t=1\" alt=\"Pubu.im Screen\"></p>\n<p>在以往，我们用QQ群，QQ讨论组做团队沟通，有时候很无奈，QQ上掺杂着很多私人的关系在上面，工作时候的确会有一些干扰，瀑布IM的组内讨论，体验上虽然有些许比不上QQ，但作为工作讨论可以屏蔽掉很多干扰。并且我很喜欢其中的一个功能，瀑布IM会收集团队聊天中的图片，文件，代码片段，特别是链接片段，这无疑是一个需求痛点，工作中，我经常翻好几页聊天记录去找同事N天前发给我的测试页面的链接。</p>\n<p><img src=\"http://res.xiezefan.me/images/blog/pubu_im_files_collection.jpg\" alt=\"Pubu.im Files Collection\"></p>\n<h3 id=\"自定义扩展\"><a href=\"#自定义扩展\" class=\"headerlink\" title=\"自定义扩展\"></a>自定义扩展</h3><p>瀑布IM也提供了自定义扩展，方便有开发能力的用户接入内部的管理系统，其主要有</p>\n<p>输出类：</p>\n<ul>\n<li>Command命令</li>\n<li>Outgoing</li>\n</ul>\n<p>接入类：</p>\n<ul>\n<li>代收邮件</li>\n<li>Incomming</li>\n</ul>\n<p>输出类定义一个聊天事件，当聊天事件触发的时候，会往你指定的URL POST一些数据，接入类则通过设置Webhooks，当事件触发时，开发者主动调用Webhoods发送数据向指定渠道推送消息。 </p>\n<p>我试验了一下<a href=\"https://blog.pubu.im/how-to-add-incoming/\" target=\"_blank\" rel=\"noopener\">Incoming服务</a>，背景是这样，当一个用户支付了订单时候，服务端会进行一些Webhookds回调，正常情况下，我需要编写一个程序以查看回调通知的内容，在此之前，我使用纷云的开源Webhooks调试框架 - <a href=\"http://request.lesschat.com/\" target=\"_blank\" rel=\"noopener\">Request</a>，为了试验瀑布IM的Incoming服务，我用Nodejs编写了一个简单的转发Webhooks的程序，当收到回调后，程序格式化文本并调用瀑布IM的回调接口。</p>\n<figure class=\"highlight javascript\"><table><tr><td class=\"code\"><pre><span class=\"line\">request(&#123;</span><br><span class=\"line\">    uri: <span class=\"string\">'https://hooks.pubu.im/services/xxxxxxx'</span>,</span><br><span class=\"line\">    method: <span class=\"string\">'POST'</span>,</span><br><span class=\"line\">    json: &#123;<span class=\"attr\">text</span>:text, <span class=\"attr\">attachments</span>:attachments, <span class=\"attr\">displayUser</span>:displayUser&#125;,</span><br><span class=\"line\">    headers : &#123;<span class=\"string\">'Content-Type'</span> : <span class=\"string\">'application/json'</span>&#125;</span><br><span class=\"line\">&#125;, <span class=\"function\"><span class=\"keyword\">function</span>(<span class=\"params\">err, rep</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (err) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"built_in\">console</span>.log(err);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"built_in\">console</span>.log(<span class=\"built_in\">JSON</span>.stringify(rep.body));</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<p><img src=\"http://res.xiezefan.me/images/blog/pubu_im_custom_service.png\" alt=\"Pubu.im Custom Service\">  </p>\n<p>有一点需要吐槽的是，瀑布IM提供的API有一个BUG，当未指定<code>Content-Type=application/json</code>的时候，API会抛500异常，回复邮件反馈也不是很迅速，最后还是我自己找到原因的。不过考虑到目前该产品仍然处于Beta版本，还是可以理解的。另外，在JSON中使用驼峰式命名是很不专业的行为呀。</p>\n<h3 id=\"额外的话\"><a href=\"#额外的话\" class=\"headerlink\" title=\"额外的话\"></a>额外的话</h3><p>昨天和一位跳槽某大型互联网公司的前同事聊天，他同我吐槽说公司对第三方生成力工具很克制，禁止员工使用其他第三方平台提供管理工具，理由不外乎信息安全，而一般大型互联网公司的内部工具难免跟不上时代，效率上总有些瑕疵。像Tower.im，Teambition，瀑布IM这些工具想在内部推广阻力重重，而反倒乎创业团队，无须考虑太多这些事情，执行力也高，能第一时间体验这些提供工作效率的生产力工具。只不过在国内的大环境下，如何探索出一套可行的商业模式当下还是路漫漫。</p>"},{"layout":"post","title":"MySQL解决插入emoji表情失败的问题","date":"2015-02-02T16:00:00.000Z","_content":"\n\n\n\n一直以为UTF-8是万能的字符集问题解决方案. 直到遇到这个问题.\n最近在做新浪微博的爬虫, 在存库的时候, 发现只要保持emoji表情, 就回抛出以下异常\n```\nIncorrect string value: '\\xF0\\x90\\x8D\\x83\\xF0\\x90...' \n```\n众所周知UTF-8是3个字节,  其中已经包括我们日常能见过的绝大多数字体. 但3个字节远远不够容纳所有的文字, 所以便有了utf8mb4, utf8mb4是utf8的超集, 占4个字节, 向下兼容utf8. 我们日常用的emoji表情就是4个字节了.\n所以在此我们像utf8的数据表插入数据就会报出`Incorrect string value`这个错误.\n\n\n<!-- more -->\n\nGoogle一下很容易就找到了解决方案, 具体解决办法是:\n\n- 1.修改数据表的字符集为utf8mb4\n> 这点很简单, 修改语句网上找一大堆, 不过建议重新建表, 使用 `mysqldump -uusername -ppassword database_name table_name > table.sql` 备份相应数据表, 并修改其中的建表语句的字符集为 utf8mb4 即可, 然后 `mysql -uusername -ppassword database_name < table.sql` 重新导入sql即可完成修改字符集操作.\n\n- 2.MySQL数据库版本要5.5.3及以上\n\n    > 网络上所有的文章都说明要MySQL 5.5.3以上的版本才支持utf8mb4, 不过我使用的数据库版本为5.5.18, 最终仍能解决问题, 所以同学们不要急着找运维哥哥升级数据库先, 先试试能不能自己解决问题.\n\n- 3.修改数据库配置文件`/etc/my.cnf`并重启mysql服务\n    > 主要是修改数据库的默认字符集, 以及连接, 查询的字符集, [Mysql支持emoji 表情符号 升级编码为UTF8MB4][1]  这篇文章有详细的设置方法,  [深入Mysql字符集设置][2] 这篇文章有其中设置的各个字符集的作用, 大家可以科普下.\n\n- 4.升级MySQL Connector到5.1.21及以上\n\n以上所有的操作, 最关键的是步骤3, 修改数据库的配置文件, 其中大概修改了\n```\n[client]\n# 客户端来源数据的默认字符集\ndefault-character-set = utf8mb4\n\n[mysqld]\n# 服务端默认字符集\ncharacter-set-server=utf8mb4\n# 连接层默认字符集\ncollation-server=utf8mb4_unicode_ci\n\n[mysql]\n# 数据库默认字符集\ndefault-character-set = utf8mb4\n```\n这些配置指定了数据从客户端到服务端所经过的一条条管道使用的字符集, 其中每一个管道出现问题都可能会导致插入失败或者乱码.\n\n但很多时候, 线上的数据库是不能随便修改数据库文件的, 所以我们的运维同学很果断的回绝了我修改数据库配置文件的请求(T_T)  \n\n所以就只能用代码解决了, 一开始是准备从JDBC连接时候就指定使用的字符集处下手.\n```\njdbc:mysql://localhost:3306/ding?characterEncoding=UTF-8\n```\n主要把UTF-8修改为utf8mb4对于的Java Style Charset字符串应该就能解决问题吧? \n不过很遗憾的是, Java JDBC并不存在utf8mb4对于的字符集. 使用UTF-8的时候可以兼容urf8mb4并自动转换字符集.\n\n> For example, to use 4-byte UTF-8 character sets with Connector/J, configure the MySQL server with character_set_server=utf8mb4, and leave characterEncoding out of the Connector/J connection string. Connector/J will then autodetect the UTF-8 setting.  -- [MySQL:Using Character Sets and Unicode][3]\n\n后来科普了一下, 在每一次查询请求的时候, 可以显式的指定使用的字符集, 使用 `set names utf8mb4` 可以指定本次链接的字符集为utf8mb4, 但这个设置在每次连接被释放后都会失效. \n目前的解决办法是, 在需要插入utf8mb4的时候, 显示地调用执行`set names utf8mb4`, 如:\n```\njdbcTemplate.execute(\"set names utf8mb4\");\njdbcTempalte.execute(\"...\");\n```\n需要注意的是, 我们在使用一下ORM框架的时候, 因为性能优化原因, 框架会延迟提交, 除非事务结束或者用户主动调用强制提交, 负责执行的`set names utf8mb4`仍然不会生效. \n\n在这里我使用的是myBatis, 以MessageDao为例\n\n```\n// MessageDao\npublic interface MessageDao {\n    @Update(\"set names utf8mb4\")\n    public void setCharsetToUtf8mb4();\n    @Insert(\"insert into tb_message ......\")\n    public void insert(Message msg);\n}\n\n// test code\n\nSqlSession sqlSession = sqlSessioFactory.openSession();\nmessageDao = sqlSession.getMapper(MessageDao.class);\nmessageDao.setCharsetToUtf8mb4();\n// 强制提交\nsqlSession.commit();\nmessageDao.insert(message);\n\n```\n至此, 问题便解决了..\n哎, 如果世事能那么顺利就好了, 在项目中, mybatis是实例是交由Spring去管理的, 也就是说我拿不到sqlSession, 也就是强制提交不了. 并且因为Spring事务框架的限制, 他并不允许用户显式调用强制提交.  目前还在纠结这个问题.\n有两个解决思路:\n1. 使用AOP, 在可能插入4字节UTF8字符的时候, 前置方法执行`set names utf8mb4`, 但该方案还不能确定AOP的方法会被Spring进行事务管理么, 并且在前置方法中,拿到的链接是否和接下来拿到的连接对象是同一个session.\n2. 研究Spring JDBC的创建方法, 写一个hook在每次创建新的数据库连接的时候, 都执行一次`set names utf8mb4`, 这样就保证每一次拿到的链接都是设置过字符集的.\n\n待有时间再实验一下以上两种方案.\n","source":"_posts/mysql-utf8mb4.md","raw":"---\nlayout: post\ntitle: \"MySQL解决插入emoji表情失败的问题\"\ndate: 2015-02-03\ncategories:\n- mysql\ntags:\n- mysql\n\n---\n\n\n\n\n一直以为UTF-8是万能的字符集问题解决方案. 直到遇到这个问题.\n最近在做新浪微博的爬虫, 在存库的时候, 发现只要保持emoji表情, 就回抛出以下异常\n```\nIncorrect string value: '\\xF0\\x90\\x8D\\x83\\xF0\\x90...' \n```\n众所周知UTF-8是3个字节,  其中已经包括我们日常能见过的绝大多数字体. 但3个字节远远不够容纳所有的文字, 所以便有了utf8mb4, utf8mb4是utf8的超集, 占4个字节, 向下兼容utf8. 我们日常用的emoji表情就是4个字节了.\n所以在此我们像utf8的数据表插入数据就会报出`Incorrect string value`这个错误.\n\n\n<!-- more -->\n\nGoogle一下很容易就找到了解决方案, 具体解决办法是:\n\n- 1.修改数据表的字符集为utf8mb4\n> 这点很简单, 修改语句网上找一大堆, 不过建议重新建表, 使用 `mysqldump -uusername -ppassword database_name table_name > table.sql` 备份相应数据表, 并修改其中的建表语句的字符集为 utf8mb4 即可, 然后 `mysql -uusername -ppassword database_name < table.sql` 重新导入sql即可完成修改字符集操作.\n\n- 2.MySQL数据库版本要5.5.3及以上\n\n    > 网络上所有的文章都说明要MySQL 5.5.3以上的版本才支持utf8mb4, 不过我使用的数据库版本为5.5.18, 最终仍能解决问题, 所以同学们不要急着找运维哥哥升级数据库先, 先试试能不能自己解决问题.\n\n- 3.修改数据库配置文件`/etc/my.cnf`并重启mysql服务\n    > 主要是修改数据库的默认字符集, 以及连接, 查询的字符集, [Mysql支持emoji 表情符号 升级编码为UTF8MB4][1]  这篇文章有详细的设置方法,  [深入Mysql字符集设置][2] 这篇文章有其中设置的各个字符集的作用, 大家可以科普下.\n\n- 4.升级MySQL Connector到5.1.21及以上\n\n以上所有的操作, 最关键的是步骤3, 修改数据库的配置文件, 其中大概修改了\n```\n[client]\n# 客户端来源数据的默认字符集\ndefault-character-set = utf8mb4\n\n[mysqld]\n# 服务端默认字符集\ncharacter-set-server=utf8mb4\n# 连接层默认字符集\ncollation-server=utf8mb4_unicode_ci\n\n[mysql]\n# 数据库默认字符集\ndefault-character-set = utf8mb4\n```\n这些配置指定了数据从客户端到服务端所经过的一条条管道使用的字符集, 其中每一个管道出现问题都可能会导致插入失败或者乱码.\n\n但很多时候, 线上的数据库是不能随便修改数据库文件的, 所以我们的运维同学很果断的回绝了我修改数据库配置文件的请求(T_T)  \n\n所以就只能用代码解决了, 一开始是准备从JDBC连接时候就指定使用的字符集处下手.\n```\njdbc:mysql://localhost:3306/ding?characterEncoding=UTF-8\n```\n主要把UTF-8修改为utf8mb4对于的Java Style Charset字符串应该就能解决问题吧? \n不过很遗憾的是, Java JDBC并不存在utf8mb4对于的字符集. 使用UTF-8的时候可以兼容urf8mb4并自动转换字符集.\n\n> For example, to use 4-byte UTF-8 character sets with Connector/J, configure the MySQL server with character_set_server=utf8mb4, and leave characterEncoding out of the Connector/J connection string. Connector/J will then autodetect the UTF-8 setting.  -- [MySQL:Using Character Sets and Unicode][3]\n\n后来科普了一下, 在每一次查询请求的时候, 可以显式的指定使用的字符集, 使用 `set names utf8mb4` 可以指定本次链接的字符集为utf8mb4, 但这个设置在每次连接被释放后都会失效. \n目前的解决办法是, 在需要插入utf8mb4的时候, 显示地调用执行`set names utf8mb4`, 如:\n```\njdbcTemplate.execute(\"set names utf8mb4\");\njdbcTempalte.execute(\"...\");\n```\n需要注意的是, 我们在使用一下ORM框架的时候, 因为性能优化原因, 框架会延迟提交, 除非事务结束或者用户主动调用强制提交, 负责执行的`set names utf8mb4`仍然不会生效. \n\n在这里我使用的是myBatis, 以MessageDao为例\n\n```\n// MessageDao\npublic interface MessageDao {\n    @Update(\"set names utf8mb4\")\n    public void setCharsetToUtf8mb4();\n    @Insert(\"insert into tb_message ......\")\n    public void insert(Message msg);\n}\n\n// test code\n\nSqlSession sqlSession = sqlSessioFactory.openSession();\nmessageDao = sqlSession.getMapper(MessageDao.class);\nmessageDao.setCharsetToUtf8mb4();\n// 强制提交\nsqlSession.commit();\nmessageDao.insert(message);\n\n```\n至此, 问题便解决了..\n哎, 如果世事能那么顺利就好了, 在项目中, mybatis是实例是交由Spring去管理的, 也就是说我拿不到sqlSession, 也就是强制提交不了. 并且因为Spring事务框架的限制, 他并不允许用户显式调用强制提交.  目前还在纠结这个问题.\n有两个解决思路:\n1. 使用AOP, 在可能插入4字节UTF8字符的时候, 前置方法执行`set names utf8mb4`, 但该方案还不能确定AOP的方法会被Spring进行事务管理么, 并且在前置方法中,拿到的链接是否和接下来拿到的连接对象是同一个session.\n2. 研究Spring JDBC的创建方法, 写一个hook在每次创建新的数据库连接的时候, 都执行一次`set names utf8mb4`, 这样就保证每一次拿到的链接都是设置过字符集的.\n\n待有时间再实验一下以上两种方案.\n","slug":"mysql-utf8mb4","published":1,"updated":"2018-10-11T17:47:50.625Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44r0017l9394gnhfk4d","content":"<p>一直以为UTF-8是万能的字符集问题解决方案. 直到遇到这个问题.<br>最近在做新浪微博的爬虫, 在存库的时候, 发现只要保持emoji表情, 就回抛出以下异常<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Incorrect string value: &apos;\\xF0\\x90\\x8D\\x83\\xF0\\x90...&apos;</span><br></pre></td></tr></table></figure></p>\n<p>众所周知UTF-8是3个字节,  其中已经包括我们日常能见过的绝大多数字体. 但3个字节远远不够容纳所有的文字, 所以便有了utf8mb4, utf8mb4是utf8的超集, 占4个字节, 向下兼容utf8. 我们日常用的emoji表情就是4个字节了.<br>所以在此我们像utf8的数据表插入数据就会报出<code>Incorrect string value</code>这个错误.</p>\n<a id=\"more\"></a>\n<p>Google一下很容易就找到了解决方案, 具体解决办法是:</p>\n<ul>\n<li><p>1.修改数据表的字符集为utf8mb4</p>\n<blockquote>\n<p>这点很简单, 修改语句网上找一大堆, 不过建议重新建表, 使用 <code>mysqldump -uusername -ppassword database_name table_name &gt; table.sql</code> 备份相应数据表, 并修改其中的建表语句的字符集为 utf8mb4 即可, 然后 <code>mysql -uusername -ppassword database_name &lt; table.sql</code> 重新导入sql即可完成修改字符集操作.</p>\n</blockquote>\n</li>\n<li><p>2.MySQL数据库版本要5.5.3及以上</p>\n<blockquote>\n<p>网络上所有的文章都说明要MySQL 5.5.3以上的版本才支持utf8mb4, 不过我使用的数据库版本为5.5.18, 最终仍能解决问题, 所以同学们不要急着找运维哥哥升级数据库先, 先试试能不能自己解决问题.</p>\n</blockquote>\n</li>\n<li><p>3.修改数据库配置文件<code>/etc/my.cnf</code>并重启mysql服务</p>\n<blockquote>\n<p>主要是修改数据库的默认字符集, 以及连接, 查询的字符集, [Mysql支持emoji 表情符号 升级编码为UTF8MB4][1]  这篇文章有详细的设置方法,  [深入Mysql字符集设置][2] 这篇文章有其中设置的各个字符集的作用, 大家可以科普下.</p>\n</blockquote>\n</li>\n<li><p>4.升级MySQL Connector到5.1.21及以上</p>\n</li>\n</ul>\n<p>以上所有的操作, 最关键的是步骤3, 修改数据库的配置文件, 其中大概修改了<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[client]</span><br><span class=\"line\"># 客户端来源数据的默认字符集</span><br><span class=\"line\">default-character-set = utf8mb4</span><br><span class=\"line\"></span><br><span class=\"line\">[mysqld]</span><br><span class=\"line\"># 服务端默认字符集</span><br><span class=\"line\">character-set-server=utf8mb4</span><br><span class=\"line\"># 连接层默认字符集</span><br><span class=\"line\">collation-server=utf8mb4_unicode_ci</span><br><span class=\"line\"></span><br><span class=\"line\">[mysql]</span><br><span class=\"line\"># 数据库默认字符集</span><br><span class=\"line\">default-character-set = utf8mb4</span><br></pre></td></tr></table></figure></p>\n<p>这些配置指定了数据从客户端到服务端所经过的一条条管道使用的字符集, 其中每一个管道出现问题都可能会导致插入失败或者乱码.</p>\n<p>但很多时候, 线上的数据库是不能随便修改数据库文件的, 所以我们的运维同学很果断的回绝了我修改数据库配置文件的请求(T_T)  </p>\n<p>所以就只能用代码解决了, 一开始是准备从JDBC连接时候就指定使用的字符集处下手.<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">jdbc:mysql://localhost:3306/ding?characterEncoding=UTF-8</span><br></pre></td></tr></table></figure></p>\n<p>主要把UTF-8修改为utf8mb4对于的Java Style Charset字符串应该就能解决问题吧?<br>不过很遗憾的是, Java JDBC并不存在utf8mb4对于的字符集. 使用UTF-8的时候可以兼容urf8mb4并自动转换字符集.</p>\n<blockquote>\n<p>For example, to use 4-byte UTF-8 character sets with Connector/J, configure the MySQL server with character_set_server=utf8mb4, and leave characterEncoding out of the Connector/J connection string. Connector/J will then autodetect the UTF-8 setting.  – [MySQL:Using Character Sets and Unicode][3]</p>\n</blockquote>\n<p>后来科普了一下, 在每一次查询请求的时候, 可以显式的指定使用的字符集, 使用 <code>set names utf8mb4</code> 可以指定本次链接的字符集为utf8mb4, 但这个设置在每次连接被释放后都会失效.<br>目前的解决办法是, 在需要插入utf8mb4的时候, 显示地调用执行<code>set names utf8mb4</code>, 如:<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">jdbcTemplate.execute(&quot;set names utf8mb4&quot;);</span><br><span class=\"line\">jdbcTempalte.execute(&quot;...&quot;);</span><br></pre></td></tr></table></figure></p>\n<p>需要注意的是, 我们在使用一下ORM框架的时候, 因为性能优化原因, 框架会延迟提交, 除非事务结束或者用户主动调用强制提交, 负责执行的<code>set names utf8mb4</code>仍然不会生效. </p>\n<p>在这里我使用的是myBatis, 以MessageDao为例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// MessageDao</span><br><span class=\"line\">public interface MessageDao &#123;</span><br><span class=\"line\">    @Update(&quot;set names utf8mb4&quot;)</span><br><span class=\"line\">    public void setCharsetToUtf8mb4();</span><br><span class=\"line\">    @Insert(&quot;insert into tb_message ......&quot;)</span><br><span class=\"line\">    public void insert(Message msg);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// test code</span><br><span class=\"line\"></span><br><span class=\"line\">SqlSession sqlSession = sqlSessioFactory.openSession();</span><br><span class=\"line\">messageDao = sqlSession.getMapper(MessageDao.class);</span><br><span class=\"line\">messageDao.setCharsetToUtf8mb4();</span><br><span class=\"line\">// 强制提交</span><br><span class=\"line\">sqlSession.commit();</span><br><span class=\"line\">messageDao.insert(message);</span><br></pre></td></tr></table></figure>\n<p>至此, 问题便解决了..<br>哎, 如果世事能那么顺利就好了, 在项目中, mybatis是实例是交由Spring去管理的, 也就是说我拿不到sqlSession, 也就是强制提交不了. 并且因为Spring事务框架的限制, 他并不允许用户显式调用强制提交.  目前还在纠结这个问题.<br>有两个解决思路:</p>\n<ol>\n<li>使用AOP, 在可能插入4字节UTF8字符的时候, 前置方法执行<code>set names utf8mb4</code>, 但该方案还不能确定AOP的方法会被Spring进行事务管理么, 并且在前置方法中,拿到的链接是否和接下来拿到的连接对象是同一个session.</li>\n<li>研究Spring JDBC的创建方法, 写一个hook在每次创建新的数据库连接的时候, 都执行一次<code>set names utf8mb4</code>, 这样就保证每一次拿到的链接都是设置过字符集的.</li>\n</ol>\n<p>待有时间再实验一下以上两种方案.</p>\n","site":{"data":{}},"excerpt":"<p>一直以为UTF-8是万能的字符集问题解决方案. 直到遇到这个问题.<br>最近在做新浪微博的爬虫, 在存库的时候, 发现只要保持emoji表情, 就回抛出以下异常<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">Incorrect string value: &apos;\\xF0\\x90\\x8D\\x83\\xF0\\x90...&apos;</span><br></pre></td></tr></table></figure></p>\n<p>众所周知UTF-8是3个字节,  其中已经包括我们日常能见过的绝大多数字体. 但3个字节远远不够容纳所有的文字, 所以便有了utf8mb4, utf8mb4是utf8的超集, 占4个字节, 向下兼容utf8. 我们日常用的emoji表情就是4个字节了.<br>所以在此我们像utf8的数据表插入数据就会报出<code>Incorrect string value</code>这个错误.</p>","more":"<p>Google一下很容易就找到了解决方案, 具体解决办法是:</p>\n<ul>\n<li><p>1.修改数据表的字符集为utf8mb4</p>\n<blockquote>\n<p>这点很简单, 修改语句网上找一大堆, 不过建议重新建表, 使用 <code>mysqldump -uusername -ppassword database_name table_name &gt; table.sql</code> 备份相应数据表, 并修改其中的建表语句的字符集为 utf8mb4 即可, 然后 <code>mysql -uusername -ppassword database_name &lt; table.sql</code> 重新导入sql即可完成修改字符集操作.</p>\n</blockquote>\n</li>\n<li><p>2.MySQL数据库版本要5.5.3及以上</p>\n<blockquote>\n<p>网络上所有的文章都说明要MySQL 5.5.3以上的版本才支持utf8mb4, 不过我使用的数据库版本为5.5.18, 最终仍能解决问题, 所以同学们不要急着找运维哥哥升级数据库先, 先试试能不能自己解决问题.</p>\n</blockquote>\n</li>\n<li><p>3.修改数据库配置文件<code>/etc/my.cnf</code>并重启mysql服务</p>\n<blockquote>\n<p>主要是修改数据库的默认字符集, 以及连接, 查询的字符集, [Mysql支持emoji 表情符号 升级编码为UTF8MB4][1]  这篇文章有详细的设置方法,  [深入Mysql字符集设置][2] 这篇文章有其中设置的各个字符集的作用, 大家可以科普下.</p>\n</blockquote>\n</li>\n<li><p>4.升级MySQL Connector到5.1.21及以上</p>\n</li>\n</ul>\n<p>以上所有的操作, 最关键的是步骤3, 修改数据库的配置文件, 其中大概修改了<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">[client]</span><br><span class=\"line\"># 客户端来源数据的默认字符集</span><br><span class=\"line\">default-character-set = utf8mb4</span><br><span class=\"line\"></span><br><span class=\"line\">[mysqld]</span><br><span class=\"line\"># 服务端默认字符集</span><br><span class=\"line\">character-set-server=utf8mb4</span><br><span class=\"line\"># 连接层默认字符集</span><br><span class=\"line\">collation-server=utf8mb4_unicode_ci</span><br><span class=\"line\"></span><br><span class=\"line\">[mysql]</span><br><span class=\"line\"># 数据库默认字符集</span><br><span class=\"line\">default-character-set = utf8mb4</span><br></pre></td></tr></table></figure></p>\n<p>这些配置指定了数据从客户端到服务端所经过的一条条管道使用的字符集, 其中每一个管道出现问题都可能会导致插入失败或者乱码.</p>\n<p>但很多时候, 线上的数据库是不能随便修改数据库文件的, 所以我们的运维同学很果断的回绝了我修改数据库配置文件的请求(T_T)  </p>\n<p>所以就只能用代码解决了, 一开始是准备从JDBC连接时候就指定使用的字符集处下手.<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">jdbc:mysql://localhost:3306/ding?characterEncoding=UTF-8</span><br></pre></td></tr></table></figure></p>\n<p>主要把UTF-8修改为utf8mb4对于的Java Style Charset字符串应该就能解决问题吧?<br>不过很遗憾的是, Java JDBC并不存在utf8mb4对于的字符集. 使用UTF-8的时候可以兼容urf8mb4并自动转换字符集.</p>\n<blockquote>\n<p>For example, to use 4-byte UTF-8 character sets with Connector/J, configure the MySQL server with character_set_server=utf8mb4, and leave characterEncoding out of the Connector/J connection string. Connector/J will then autodetect the UTF-8 setting.  – [MySQL:Using Character Sets and Unicode][3]</p>\n</blockquote>\n<p>后来科普了一下, 在每一次查询请求的时候, 可以显式的指定使用的字符集, 使用 <code>set names utf8mb4</code> 可以指定本次链接的字符集为utf8mb4, 但这个设置在每次连接被释放后都会失效.<br>目前的解决办法是, 在需要插入utf8mb4的时候, 显示地调用执行<code>set names utf8mb4</code>, 如:<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">jdbcTemplate.execute(&quot;set names utf8mb4&quot;);</span><br><span class=\"line\">jdbcTempalte.execute(&quot;...&quot;);</span><br></pre></td></tr></table></figure></p>\n<p>需要注意的是, 我们在使用一下ORM框架的时候, 因为性能优化原因, 框架会延迟提交, 除非事务结束或者用户主动调用强制提交, 负责执行的<code>set names utf8mb4</code>仍然不会生效. </p>\n<p>在这里我使用的是myBatis, 以MessageDao为例</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">// MessageDao</span><br><span class=\"line\">public interface MessageDao &#123;</span><br><span class=\"line\">    @Update(&quot;set names utf8mb4&quot;)</span><br><span class=\"line\">    public void setCharsetToUtf8mb4();</span><br><span class=\"line\">    @Insert(&quot;insert into tb_message ......&quot;)</span><br><span class=\"line\">    public void insert(Message msg);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">// test code</span><br><span class=\"line\"></span><br><span class=\"line\">SqlSession sqlSession = sqlSessioFactory.openSession();</span><br><span class=\"line\">messageDao = sqlSession.getMapper(MessageDao.class);</span><br><span class=\"line\">messageDao.setCharsetToUtf8mb4();</span><br><span class=\"line\">// 强制提交</span><br><span class=\"line\">sqlSession.commit();</span><br><span class=\"line\">messageDao.insert(message);</span><br></pre></td></tr></table></figure>\n<p>至此, 问题便解决了..<br>哎, 如果世事能那么顺利就好了, 在项目中, mybatis是实例是交由Spring去管理的, 也就是说我拿不到sqlSession, 也就是强制提交不了. 并且因为Spring事务框架的限制, 他并不允许用户显式调用强制提交.  目前还在纠结这个问题.<br>有两个解决思路:</p>\n<ol>\n<li>使用AOP, 在可能插入4字节UTF8字符的时候, 前置方法执行<code>set names utf8mb4</code>, 但该方案还不能确定AOP的方法会被Spring进行事务管理么, 并且在前置方法中,拿到的链接是否和接下来拿到的连接对象是同一个session.</li>\n<li>研究Spring JDBC的创建方法, 写一个hook在每次创建新的数据库连接的时候, 都执行一次<code>set names utf8mb4</code>, 这样就保证每一次拿到的链接都是设置过字符集的.</li>\n</ol>\n<p>待有时间再实验一下以上两种方案.</p>"},{"layout":"post","title":"Redis Cluster 初探(2) - 运行规制","date":"2015-12-12T16:00:00.000Z","_content":"\n上一篇文章我们说过，Redis Cluster 采用Smart Client的方式，避免与节点的通讯还需要通过一层Proxy，以达到性能地提升。 Smart Client的优点与缺点网上也有很多人在讨论，我们现在来了解下Redis Client的运行规制。\n\n<!-- more -->\n\nRedis Cluster是无中心节点的设计，Client可以连接集群中的任一一个节点，当操作的Key不在该节点的Slot中的时候，如访问在Slot-6433的Key，客户端会返回一个 `(error) MOVED 6433 10.211.55.4:7001` 这样的错误信息。Client捕获到此异常后，再自动重定向到 `10.211.55.4:7001` 这个节点上并获取数据。\n![redis_cluster_slot_mode](http://res.xiezefan.me/images/blog/redis_cluster_slot_model.png)\n\n\n虽然每次请求客户端都会重新定向，但这样额外耗费多一次连接是很没有必要的，官方建议在初次建立连接后，Redis Client会获取连接集群的节点信息以及Slot分布信息，并在本地缓存一份hash slot与node关系的的路由表，当收到操作请求时，先本地用CRC16算法计算出该Key对应哪一个Slot，再在表中查询该Slot的节点信息，最后选择对应的节点去连接，这样，每次请求就不需要通过一个统一的代理层去转发请求。当服务器进行扩容，迁移数据的时候，客户端的路由表并不会立即更新，而是当在被迁移是Slot上操作的时候，因为Slot已经不在原先的节点上了，Redis Cluster返回Moved指令，告诉客户端该Slot现在所在的节点。此时，客户端应该更新自己的路由表信息，以达到最优，即每次操作直接与节点通讯并不进行跳转。\n![redis_cluster_slot_mode](http://res.xiezefan.me/images/blog/redis_cluster_slot_model2.png)\n\n在前面我说道过，Redis Cluster预先将Key分到16384个Slot，通过CRC16算法算出Key该被分配到哪一个Slot中。\n\n```\nHASH_SLOT = CRC16(key) mod 16384 \n```\n\n但是这么做有一个缺陷就是，如果你需要进行涉及多个key的操作的话，因为Key可能被分散到不同的节点中，所以查询请求将会在各个节点间跳转，效率会非常差，为此，Redis Cluster干脆不支持所有的多Key操作命令。\n假如你想使用多Key操作命令，可以通过Keys Hash Tag去将相关数据强制存储在同一个slot。当一个key包含`{`和`}`的时候，Redis-Cluster会取`{`和`}`之间的字符进行`CRC16`哈希算出存放在哪个slot，比如：\n* `{user1000}.following`这个key会使用`user1000`的hash值\n* `foo{}{bar}`这个key会使用`foo{}{bar}`的hash值，因为第一个`{`和`}`之间的值为空\n* `foo{{bar}}zap`这个key会使用`{bar`的hash值\n* `foo{bar}{zap}`这个key会使用`{bar}`的hash值\n\n但是使用Hash Tag仍然仍然会面临新的问题，因为不可避免会有些Key的Value额外的大，虽然根据概率学，当基数足够大的时候，每一个Slot的大小都会趋于平均，但实际应用中，我使用我们生产环境的一些数据进行测试，Cluster节点数目为16，测试数据集大概16G，存储数据结构为Set，每一个Key对应一个或多个Value，正常来说最终测试结果每一个节点的内存占用应该为1G，但实际上，内存使用最高与最低相差足足有200M。\n\n\n在集群运行的过程中，不可避免有些节点会因为各种原因挂掉（被踢掉网线，打雷，停电，软件故障>_>）。所以，在成本允许范围内，我们会尽量避免所有节点在同一台物理机上，避免Master，Slave在同一台物理机上，利用Redis Cluster的自动故障转移的功能，让集群在及时部分节点挂掉的情况下，仍然能继续工作。\n\n为了数据的安全性，我们一般会保持一份及以上的数据冗余。即一个Master节点对应多个Slave节点模式，当Master节点挂掉后，集群自动选择一个Slave升级为Master节点，重启原Master节点并作为Slave节点加入现有集群。\n\n而Redis Cluster是如何发现节点挂掉呢？在集群中，每一个节点之间都会保持一个长连接，即有N个节点的集群，每个节点将会保持N-1条长连接，节点定时给其他节点发送Ping指定，如果在指定的timeout内没有返回Pong，即认为该节点故障，并启动故障转移。节点timeout的时间是可以配置，但是需要明白的是，当一个节点故障的时候，他通常不能写入数据并且不能读取数据，所以节点故障到其他节点发现其故障并且进行故障转移这段时间内，写入该节点的数据可能会丢失。所以timeout时间过长意味着你将在节点故障的时候丢书过多的数据，而timeout时间过短则可能引发误判。\n\n当一个Master节点以及他的所有Slave节点都挂掉的时候，集群将处于不可用的状态，当然这是可以配置的。我们可以根据业务来决定是否打开此开关。\n\n## 坑\n\nRedis在实际应用中的一些需要避免的一些坑，在Redis Cluster之中同样存在，在调研Redis Cluster与我实际测试中，总结一些别人遇到以及我自己掉入的坑。\n\n* 为什么Redis需要预留额外一半的内存？因为Redis的AOF实际上是通过fork一个Redis进程来实现，所以为了防止AOF集中发生，出现SWAP和OOM，所以需要预留额外的一半内存。但实际有更优的解决办法：\n    1. 关闭Redis所有自动落地，通过一个Remote控制中心来管理Redis实例，远程调用`BGSAVE`命令主动触发落地。避免同一时间落地导致内存不足。\n    2. 设置最大内存使用，当内存超过此阀值的时候，写入将失败，但读取仍然是正常的，可以配置告警脚本。这能最大限度保证Redis进程不会因为内存过高而挂掉。\n\n* 在云风的 [谈谈陌陌争霸在数据库方面踩过的坑( Redis 篇)](http://blog.codingnow.com/2014/03/mmzb_redis.html) 中提到一个Redis的主从方案，即一个Master节点对应N个Slave节点，如果所有的节点都选择数据落地，每一台机器都需要预留很多内存来防止落地的时候的内存占用过高问题，但实际上这是很没有必要的，我们可以选择其中几个Slave节点进行数据落地即可。但这招在Redis Cluster是行不通的，因为Redis Cluster的故障迁移功能，默认是Master节点如果挂掉的话，Slave会自动升级为Master节点，原先的Master节点自动重启并作为Slave节点加入集群。这样如果我们在集群中指定其中几个Slave节点进行数据落地的话，当发生故障转移的时候，落地策略就会出现混乱。\n\n\n","source":"_posts/redis_cluster_research_2.md","raw":"---\nlayout: post\ntitle: \"Redis Cluster 初探(2) - 运行规制\"\ndate: 2015-12-13\ncategories:\n- Database\ntags:\n- redis\n---\n\n上一篇文章我们说过，Redis Cluster 采用Smart Client的方式，避免与节点的通讯还需要通过一层Proxy，以达到性能地提升。 Smart Client的优点与缺点网上也有很多人在讨论，我们现在来了解下Redis Client的运行规制。\n\n<!-- more -->\n\nRedis Cluster是无中心节点的设计，Client可以连接集群中的任一一个节点，当操作的Key不在该节点的Slot中的时候，如访问在Slot-6433的Key，客户端会返回一个 `(error) MOVED 6433 10.211.55.4:7001` 这样的错误信息。Client捕获到此异常后，再自动重定向到 `10.211.55.4:7001` 这个节点上并获取数据。\n![redis_cluster_slot_mode](http://res.xiezefan.me/images/blog/redis_cluster_slot_model.png)\n\n\n虽然每次请求客户端都会重新定向，但这样额外耗费多一次连接是很没有必要的，官方建议在初次建立连接后，Redis Client会获取连接集群的节点信息以及Slot分布信息，并在本地缓存一份hash slot与node关系的的路由表，当收到操作请求时，先本地用CRC16算法计算出该Key对应哪一个Slot，再在表中查询该Slot的节点信息，最后选择对应的节点去连接，这样，每次请求就不需要通过一个统一的代理层去转发请求。当服务器进行扩容，迁移数据的时候，客户端的路由表并不会立即更新，而是当在被迁移是Slot上操作的时候，因为Slot已经不在原先的节点上了，Redis Cluster返回Moved指令，告诉客户端该Slot现在所在的节点。此时，客户端应该更新自己的路由表信息，以达到最优，即每次操作直接与节点通讯并不进行跳转。\n![redis_cluster_slot_mode](http://res.xiezefan.me/images/blog/redis_cluster_slot_model2.png)\n\n在前面我说道过，Redis Cluster预先将Key分到16384个Slot，通过CRC16算法算出Key该被分配到哪一个Slot中。\n\n```\nHASH_SLOT = CRC16(key) mod 16384 \n```\n\n但是这么做有一个缺陷就是，如果你需要进行涉及多个key的操作的话，因为Key可能被分散到不同的节点中，所以查询请求将会在各个节点间跳转，效率会非常差，为此，Redis Cluster干脆不支持所有的多Key操作命令。\n假如你想使用多Key操作命令，可以通过Keys Hash Tag去将相关数据强制存储在同一个slot。当一个key包含`{`和`}`的时候，Redis-Cluster会取`{`和`}`之间的字符进行`CRC16`哈希算出存放在哪个slot，比如：\n* `{user1000}.following`这个key会使用`user1000`的hash值\n* `foo{}{bar}`这个key会使用`foo{}{bar}`的hash值，因为第一个`{`和`}`之间的值为空\n* `foo{{bar}}zap`这个key会使用`{bar`的hash值\n* `foo{bar}{zap}`这个key会使用`{bar}`的hash值\n\n但是使用Hash Tag仍然仍然会面临新的问题，因为不可避免会有些Key的Value额外的大，虽然根据概率学，当基数足够大的时候，每一个Slot的大小都会趋于平均，但实际应用中，我使用我们生产环境的一些数据进行测试，Cluster节点数目为16，测试数据集大概16G，存储数据结构为Set，每一个Key对应一个或多个Value，正常来说最终测试结果每一个节点的内存占用应该为1G，但实际上，内存使用最高与最低相差足足有200M。\n\n\n在集群运行的过程中，不可避免有些节点会因为各种原因挂掉（被踢掉网线，打雷，停电，软件故障>_>）。所以，在成本允许范围内，我们会尽量避免所有节点在同一台物理机上，避免Master，Slave在同一台物理机上，利用Redis Cluster的自动故障转移的功能，让集群在及时部分节点挂掉的情况下，仍然能继续工作。\n\n为了数据的安全性，我们一般会保持一份及以上的数据冗余。即一个Master节点对应多个Slave节点模式，当Master节点挂掉后，集群自动选择一个Slave升级为Master节点，重启原Master节点并作为Slave节点加入现有集群。\n\n而Redis Cluster是如何发现节点挂掉呢？在集群中，每一个节点之间都会保持一个长连接，即有N个节点的集群，每个节点将会保持N-1条长连接，节点定时给其他节点发送Ping指定，如果在指定的timeout内没有返回Pong，即认为该节点故障，并启动故障转移。节点timeout的时间是可以配置，但是需要明白的是，当一个节点故障的时候，他通常不能写入数据并且不能读取数据，所以节点故障到其他节点发现其故障并且进行故障转移这段时间内，写入该节点的数据可能会丢失。所以timeout时间过长意味着你将在节点故障的时候丢书过多的数据，而timeout时间过短则可能引发误判。\n\n当一个Master节点以及他的所有Slave节点都挂掉的时候，集群将处于不可用的状态，当然这是可以配置的。我们可以根据业务来决定是否打开此开关。\n\n## 坑\n\nRedis在实际应用中的一些需要避免的一些坑，在Redis Cluster之中同样存在，在调研Redis Cluster与我实际测试中，总结一些别人遇到以及我自己掉入的坑。\n\n* 为什么Redis需要预留额外一半的内存？因为Redis的AOF实际上是通过fork一个Redis进程来实现，所以为了防止AOF集中发生，出现SWAP和OOM，所以需要预留额外的一半内存。但实际有更优的解决办法：\n    1. 关闭Redis所有自动落地，通过一个Remote控制中心来管理Redis实例，远程调用`BGSAVE`命令主动触发落地。避免同一时间落地导致内存不足。\n    2. 设置最大内存使用，当内存超过此阀值的时候，写入将失败，但读取仍然是正常的，可以配置告警脚本。这能最大限度保证Redis进程不会因为内存过高而挂掉。\n\n* 在云风的 [谈谈陌陌争霸在数据库方面踩过的坑( Redis 篇)](http://blog.codingnow.com/2014/03/mmzb_redis.html) 中提到一个Redis的主从方案，即一个Master节点对应N个Slave节点，如果所有的节点都选择数据落地，每一台机器都需要预留很多内存来防止落地的时候的内存占用过高问题，但实际上这是很没有必要的，我们可以选择其中几个Slave节点进行数据落地即可。但这招在Redis Cluster是行不通的，因为Redis Cluster的故障迁移功能，默认是Master节点如果挂掉的话，Slave会自动升级为Master节点，原先的Master节点自动重启并作为Slave节点加入集群。这样如果我们在集群中指定其中几个Slave节点进行数据落地的话，当发生故障转移的时候，落地策略就会出现混乱。\n\n\n","slug":"redis_cluster_research_2","published":1,"updated":"2018-10-12T02:09:55.310Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44t001bl939ki1gmbqc","content":"<p>上一篇文章我们说过，Redis Cluster 采用Smart Client的方式，避免与节点的通讯还需要通过一层Proxy，以达到性能地提升。 Smart Client的优点与缺点网上也有很多人在讨论，我们现在来了解下Redis Client的运行规制。</p>\n<a id=\"more\"></a>\n<p>Redis Cluster是无中心节点的设计，Client可以连接集群中的任一一个节点，当操作的Key不在该节点的Slot中的时候，如访问在Slot-6433的Key，客户端会返回一个 <code>(error) MOVED 6433 10.211.55.4:7001</code> 这样的错误信息。Client捕获到此异常后，再自动重定向到 <code>10.211.55.4:7001</code> 这个节点上并获取数据。<br><img src=\"http://res.xiezefan.me/images/blog/redis_cluster_slot_model.png\" alt=\"redis_cluster_slot_mode\"></p>\n<p>虽然每次请求客户端都会重新定向，但这样额外耗费多一次连接是很没有必要的，官方建议在初次建立连接后，Redis Client会获取连接集群的节点信息以及Slot分布信息，并在本地缓存一份hash slot与node关系的的路由表，当收到操作请求时，先本地用CRC16算法计算出该Key对应哪一个Slot，再在表中查询该Slot的节点信息，最后选择对应的节点去连接，这样，每次请求就不需要通过一个统一的代理层去转发请求。当服务器进行扩容，迁移数据的时候，客户端的路由表并不会立即更新，而是当在被迁移是Slot上操作的时候，因为Slot已经不在原先的节点上了，Redis Cluster返回Moved指令，告诉客户端该Slot现在所在的节点。此时，客户端应该更新自己的路由表信息，以达到最优，即每次操作直接与节点通讯并不进行跳转。<br><img src=\"http://res.xiezefan.me/images/blog/redis_cluster_slot_model2.png\" alt=\"redis_cluster_slot_mode\"></p>\n<p>在前面我说道过，Redis Cluster预先将Key分到16384个Slot，通过CRC16算法算出Key该被分配到哪一个Slot中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">HASH_SLOT = CRC16(key) mod 16384</span><br></pre></td></tr></table></figure>\n<p>但是这么做有一个缺陷就是，如果你需要进行涉及多个key的操作的话，因为Key可能被分散到不同的节点中，所以查询请求将会在各个节点间跳转，效率会非常差，为此，Redis Cluster干脆不支持所有的多Key操作命令。<br>假如你想使用多Key操作命令，可以通过Keys Hash Tag去将相关数据强制存储在同一个slot。当一个key包含<code>{</code>和<code>}</code>的时候，Redis-Cluster会取<code>{</code>和<code>}</code>之间的字符进行<code>CRC16</code>哈希算出存放在哪个slot，比如：</p>\n<ul>\n<li><code>{user1000}.following</code>这个key会使用<code>user1000</code>的hash值</li>\n<li><code>foo{}{bar}</code>这个key会使用<code>foo{}{bar}</code>的hash值，因为第一个<code>{</code>和<code>}</code>之间的值为空</li>\n<li><code>foozap</code>这个key会使用<code>{bar</code>的hash值</li>\n<li><code>foo{bar}{zap}</code>这个key会使用<code>{bar}</code>的hash值</li>\n</ul>\n<p>但是使用Hash Tag仍然仍然会面临新的问题，因为不可避免会有些Key的Value额外的大，虽然根据概率学，当基数足够大的时候，每一个Slot的大小都会趋于平均，但实际应用中，我使用我们生产环境的一些数据进行测试，Cluster节点数目为16，测试数据集大概16G，存储数据结构为Set，每一个Key对应一个或多个Value，正常来说最终测试结果每一个节点的内存占用应该为1G，但实际上，内存使用最高与最低相差足足有200M。</p>\n<p>在集群运行的过程中，不可避免有些节点会因为各种原因挂掉（被踢掉网线，打雷，停电，软件故障&gt;_&gt;）。所以，在成本允许范围内，我们会尽量避免所有节点在同一台物理机上，避免Master，Slave在同一台物理机上，利用Redis Cluster的自动故障转移的功能，让集群在及时部分节点挂掉的情况下，仍然能继续工作。</p>\n<p>为了数据的安全性，我们一般会保持一份及以上的数据冗余。即一个Master节点对应多个Slave节点模式，当Master节点挂掉后，集群自动选择一个Slave升级为Master节点，重启原Master节点并作为Slave节点加入现有集群。</p>\n<p>而Redis Cluster是如何发现节点挂掉呢？在集群中，每一个节点之间都会保持一个长连接，即有N个节点的集群，每个节点将会保持N-1条长连接，节点定时给其他节点发送Ping指定，如果在指定的timeout内没有返回Pong，即认为该节点故障，并启动故障转移。节点timeout的时间是可以配置，但是需要明白的是，当一个节点故障的时候，他通常不能写入数据并且不能读取数据，所以节点故障到其他节点发现其故障并且进行故障转移这段时间内，写入该节点的数据可能会丢失。所以timeout时间过长意味着你将在节点故障的时候丢书过多的数据，而timeout时间过短则可能引发误判。</p>\n<p>当一个Master节点以及他的所有Slave节点都挂掉的时候，集群将处于不可用的状态，当然这是可以配置的。我们可以根据业务来决定是否打开此开关。</p>\n<h2 id=\"坑\"><a href=\"#坑\" class=\"headerlink\" title=\"坑\"></a>坑</h2><p>Redis在实际应用中的一些需要避免的一些坑，在Redis Cluster之中同样存在，在调研Redis Cluster与我实际测试中，总结一些别人遇到以及我自己掉入的坑。</p>\n<ul>\n<li><p>为什么Redis需要预留额外一半的内存？因为Redis的AOF实际上是通过fork一个Redis进程来实现，所以为了防止AOF集中发生，出现SWAP和OOM，所以需要预留额外的一半内存。但实际有更优的解决办法：</p>\n<ol>\n<li>关闭Redis所有自动落地，通过一个Remote控制中心来管理Redis实例，远程调用<code>BGSAVE</code>命令主动触发落地。避免同一时间落地导致内存不足。</li>\n<li>设置最大内存使用，当内存超过此阀值的时候，写入将失败，但读取仍然是正常的，可以配置告警脚本。这能最大限度保证Redis进程不会因为内存过高而挂掉。</li>\n</ol>\n</li>\n<li><p>在云风的 <a href=\"http://blog.codingnow.com/2014/03/mmzb_redis.html\" target=\"_blank\" rel=\"noopener\">谈谈陌陌争霸在数据库方面踩过的坑( Redis 篇)</a> 中提到一个Redis的主从方案，即一个Master节点对应N个Slave节点，如果所有的节点都选择数据落地，每一台机器都需要预留很多内存来防止落地的时候的内存占用过高问题，但实际上这是很没有必要的，我们可以选择其中几个Slave节点进行数据落地即可。但这招在Redis Cluster是行不通的，因为Redis Cluster的故障迁移功能，默认是Master节点如果挂掉的话，Slave会自动升级为Master节点，原先的Master节点自动重启并作为Slave节点加入集群。这样如果我们在集群中指定其中几个Slave节点进行数据落地的话，当发生故障转移的时候，落地策略就会出现混乱。</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>上一篇文章我们说过，Redis Cluster 采用Smart Client的方式，避免与节点的通讯还需要通过一层Proxy，以达到性能地提升。 Smart Client的优点与缺点网上也有很多人在讨论，我们现在来了解下Redis Client的运行规制。</p>","more":"<p>Redis Cluster是无中心节点的设计，Client可以连接集群中的任一一个节点，当操作的Key不在该节点的Slot中的时候，如访问在Slot-6433的Key，客户端会返回一个 <code>(error) MOVED 6433 10.211.55.4:7001</code> 这样的错误信息。Client捕获到此异常后，再自动重定向到 <code>10.211.55.4:7001</code> 这个节点上并获取数据。<br><img src=\"http://res.xiezefan.me/images/blog/redis_cluster_slot_model.png\" alt=\"redis_cluster_slot_mode\"></p>\n<p>虽然每次请求客户端都会重新定向，但这样额外耗费多一次连接是很没有必要的，官方建议在初次建立连接后，Redis Client会获取连接集群的节点信息以及Slot分布信息，并在本地缓存一份hash slot与node关系的的路由表，当收到操作请求时，先本地用CRC16算法计算出该Key对应哪一个Slot，再在表中查询该Slot的节点信息，最后选择对应的节点去连接，这样，每次请求就不需要通过一个统一的代理层去转发请求。当服务器进行扩容，迁移数据的时候，客户端的路由表并不会立即更新，而是当在被迁移是Slot上操作的时候，因为Slot已经不在原先的节点上了，Redis Cluster返回Moved指令，告诉客户端该Slot现在所在的节点。此时，客户端应该更新自己的路由表信息，以达到最优，即每次操作直接与节点通讯并不进行跳转。<br><img src=\"http://res.xiezefan.me/images/blog/redis_cluster_slot_model2.png\" alt=\"redis_cluster_slot_mode\"></p>\n<p>在前面我说道过，Redis Cluster预先将Key分到16384个Slot，通过CRC16算法算出Key该被分配到哪一个Slot中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">HASH_SLOT = CRC16(key) mod 16384</span><br></pre></td></tr></table></figure>\n<p>但是这么做有一个缺陷就是，如果你需要进行涉及多个key的操作的话，因为Key可能被分散到不同的节点中，所以查询请求将会在各个节点间跳转，效率会非常差，为此，Redis Cluster干脆不支持所有的多Key操作命令。<br>假如你想使用多Key操作命令，可以通过Keys Hash Tag去将相关数据强制存储在同一个slot。当一个key包含<code>{</code>和<code>}</code>的时候，Redis-Cluster会取<code>{</code>和<code>}</code>之间的字符进行<code>CRC16</code>哈希算出存放在哪个slot，比如：</p>\n<ul>\n<li><code>{user1000}.following</code>这个key会使用<code>user1000</code>的hash值</li>\n<li><code>foo{}{bar}</code>这个key会使用<code>foo{}{bar}</code>的hash值，因为第一个<code>{</code>和<code>}</code>之间的值为空</li>\n<li><code>foozap</code>这个key会使用<code>{bar</code>的hash值</li>\n<li><code>foo{bar}{zap}</code>这个key会使用<code>{bar}</code>的hash值</li>\n</ul>\n<p>但是使用Hash Tag仍然仍然会面临新的问题，因为不可避免会有些Key的Value额外的大，虽然根据概率学，当基数足够大的时候，每一个Slot的大小都会趋于平均，但实际应用中，我使用我们生产环境的一些数据进行测试，Cluster节点数目为16，测试数据集大概16G，存储数据结构为Set，每一个Key对应一个或多个Value，正常来说最终测试结果每一个节点的内存占用应该为1G，但实际上，内存使用最高与最低相差足足有200M。</p>\n<p>在集群运行的过程中，不可避免有些节点会因为各种原因挂掉（被踢掉网线，打雷，停电，软件故障&gt;_&gt;）。所以，在成本允许范围内，我们会尽量避免所有节点在同一台物理机上，避免Master，Slave在同一台物理机上，利用Redis Cluster的自动故障转移的功能，让集群在及时部分节点挂掉的情况下，仍然能继续工作。</p>\n<p>为了数据的安全性，我们一般会保持一份及以上的数据冗余。即一个Master节点对应多个Slave节点模式，当Master节点挂掉后，集群自动选择一个Slave升级为Master节点，重启原Master节点并作为Slave节点加入现有集群。</p>\n<p>而Redis Cluster是如何发现节点挂掉呢？在集群中，每一个节点之间都会保持一个长连接，即有N个节点的集群，每个节点将会保持N-1条长连接，节点定时给其他节点发送Ping指定，如果在指定的timeout内没有返回Pong，即认为该节点故障，并启动故障转移。节点timeout的时间是可以配置，但是需要明白的是，当一个节点故障的时候，他通常不能写入数据并且不能读取数据，所以节点故障到其他节点发现其故障并且进行故障转移这段时间内，写入该节点的数据可能会丢失。所以timeout时间过长意味着你将在节点故障的时候丢书过多的数据，而timeout时间过短则可能引发误判。</p>\n<p>当一个Master节点以及他的所有Slave节点都挂掉的时候，集群将处于不可用的状态，当然这是可以配置的。我们可以根据业务来决定是否打开此开关。</p>\n<h2 id=\"坑\"><a href=\"#坑\" class=\"headerlink\" title=\"坑\"></a>坑</h2><p>Redis在实际应用中的一些需要避免的一些坑，在Redis Cluster之中同样存在，在调研Redis Cluster与我实际测试中，总结一些别人遇到以及我自己掉入的坑。</p>\n<ul>\n<li><p>为什么Redis需要预留额外一半的内存？因为Redis的AOF实际上是通过fork一个Redis进程来实现，所以为了防止AOF集中发生，出现SWAP和OOM，所以需要预留额外的一半内存。但实际有更优的解决办法：</p>\n<ol>\n<li>关闭Redis所有自动落地，通过一个Remote控制中心来管理Redis实例，远程调用<code>BGSAVE</code>命令主动触发落地。避免同一时间落地导致内存不足。</li>\n<li>设置最大内存使用，当内存超过此阀值的时候，写入将失败，但读取仍然是正常的，可以配置告警脚本。这能最大限度保证Redis进程不会因为内存过高而挂掉。</li>\n</ol>\n</li>\n<li><p>在云风的 <a href=\"http://blog.codingnow.com/2014/03/mmzb_redis.html\" target=\"_blank\" rel=\"noopener\">谈谈陌陌争霸在数据库方面踩过的坑( Redis 篇)</a> 中提到一个Redis的主从方案，即一个Master节点对应N个Slave节点，如果所有的节点都选择数据落地，每一台机器都需要预留很多内存来防止落地的时候的内存占用过高问题，但实际上这是很没有必要的，我们可以选择其中几个Slave节点进行数据落地即可。但这招在Redis Cluster是行不通的，因为Redis Cluster的故障迁移功能，默认是Master节点如果挂掉的话，Slave会自动升级为Master节点，原先的Master节点自动重启并作为Slave节点加入集群。这样如果我们在集群中指定其中几个Slave节点进行数据落地的话，当发生故障转移的时候，落地策略就会出现混乱。</p>\n</li>\n</ul>"},{"layout":"post","title":"使用Spring Test编写单元测试","date":"2015-01-05T16:00:00.000Z","description":"用Spring Test的话, 可以指定在测试用例执行完毕后,对数据库进行回滚操作","_content":"\n在编写单元测试的时候,特别是涉及数据存储的单元测试环境中,我们需要保证测试环境的整洁,避免测试数据污染正常使用的数据库.  \n通常的做法是, 创建一个测试数据库, 使用配置文件控制在测试环境下, 数据持久化到测试环境. 这种方法比较笨拙.  \n如果使用Spring Test的话, 就可以指定在测试用例执行完毕后,对数据库进行回滚操作.\n\n<!-- more -->\n\n### 依赖管理\n#### JUnit\n```\n<!-- junit -->\n<dependency>\n    <groupId>junit</groupId>\n    <artifactId>junit</artifactId>\n    <version>4.11</version>\n    <scope>test</scope>\n</dependency>\n```\n#### Spring Test\n```\n<!-- spring test -->\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-test</artifactId>\n    <version>4.1.2.RELEASE</version>\n    <scope>test</scope>\n</dependency>\n```\n\n### 测试用例编写\n在未使用Spring Test之前, 我们可以用`ApplicationContext`获取实例, 但该方法不够便捷, 每个单元测试类都需要编写一套初始化代码.\n```\nApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"applicationContext.xml\");\nMessageDao messageDao = applicationContext.getBean(\"messageDao\");\n```\n\n在此可以使用Spring Test, 以期使用注解注入需要使用到的实例. 如下:\n```\n@RunWith(SpringJUnit4ClassRunner.class)\n@ContextConfiguration(locations=\"classpath:applicationContext.xml\")\npublic class MessageDaoTest {\n    @Resource\n    private MessageDao messageDao;\n}\n```\n\n在此, 单元测试类可以选择继承自`AbstractJUnit4SpringContextTests`或`AbstractTransactionalJUnit4SpringContextTests`. 关于上述两者的区别:\n> 如果再你的测试类中，需要用到事务管理（比如要在测试结果出来之后回滚测试内容），就可以使用AbstractTransactionalJUnit4SpringTests类。事务管理的使用方法和正常使用Spring事务管理是一样的。再此需要注意的是，如果想要使用声明式事务管理，即使用AbstractTransactionalJUnitSpringContextTests类，请在applicationContext.xml文件中加入transactionManager bean\n摘至: [Spring Test 整合 JUnit 4 使用总结][1]\n\n在继承 `AbstractTransactionalJUnit4SpringContextTests` 后, 测试用例执行完成后, 所有涉及的数据库操作都会被回滚,十分方便. 不用再测试完成后再做清理现场的操作.\n\n在编写测试用例的时候, 一些注解的说明\n```\n@BeforeClass\npublic void static beforeClass() {// 做一些测试前置数据的创建工作, 只执行一次}\n@Before\npublic void before() {// 做一些测试前置数据的创建工作, 他对于每一个测试方法都回执行一次}\n@AfterClass\npublic void static afterClass() {//做一些清理现场,释放资源的操作, 只执行一次 }\n@After\npublic void after() { //做一些清理现场,释放资源的操作, 他对于每一个测试方法都回执行一次}\n```\n\n### 后记\n对于使用Spring Test做单元测试并不是十全十美, 因为有一些存储操作, 我们并不希望交由Spring管理,  例如项目中使用redis做一些缓存操作, 在使用单元测试后, 必须删除对应的缓存数据, 这时候只能手动清理现场.\n(虽然使用Spring-data-redis能交由spring管理事物, 但考虑到其他需求, 没有引入)\n\n### 参考资料\n[Spring Test 整合 JUnit 4 使用总结][1]\n\n  [1]: http://blog.csdn.net/feihong247/article/details/7828143","source":"_posts/spring-test-start.md","raw":"---\nlayout: post\ntitle: \"使用Spring Test编写单元测试\"\ndate: 2015-01-06\ncategories: \n- java\ntags: \n- spring-test\ndescription: \"用Spring Test的话, 可以指定在测试用例执行完毕后,对数据库进行回滚操作\"\n\n---\n\n在编写单元测试的时候,特别是涉及数据存储的单元测试环境中,我们需要保证测试环境的整洁,避免测试数据污染正常使用的数据库.  \n通常的做法是, 创建一个测试数据库, 使用配置文件控制在测试环境下, 数据持久化到测试环境. 这种方法比较笨拙.  \n如果使用Spring Test的话, 就可以指定在测试用例执行完毕后,对数据库进行回滚操作.\n\n<!-- more -->\n\n### 依赖管理\n#### JUnit\n```\n<!-- junit -->\n<dependency>\n    <groupId>junit</groupId>\n    <artifactId>junit</artifactId>\n    <version>4.11</version>\n    <scope>test</scope>\n</dependency>\n```\n#### Spring Test\n```\n<!-- spring test -->\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-test</artifactId>\n    <version>4.1.2.RELEASE</version>\n    <scope>test</scope>\n</dependency>\n```\n\n### 测试用例编写\n在未使用Spring Test之前, 我们可以用`ApplicationContext`获取实例, 但该方法不够便捷, 每个单元测试类都需要编写一套初始化代码.\n```\nApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"applicationContext.xml\");\nMessageDao messageDao = applicationContext.getBean(\"messageDao\");\n```\n\n在此可以使用Spring Test, 以期使用注解注入需要使用到的实例. 如下:\n```\n@RunWith(SpringJUnit4ClassRunner.class)\n@ContextConfiguration(locations=\"classpath:applicationContext.xml\")\npublic class MessageDaoTest {\n    @Resource\n    private MessageDao messageDao;\n}\n```\n\n在此, 单元测试类可以选择继承自`AbstractJUnit4SpringContextTests`或`AbstractTransactionalJUnit4SpringContextTests`. 关于上述两者的区别:\n> 如果再你的测试类中，需要用到事务管理（比如要在测试结果出来之后回滚测试内容），就可以使用AbstractTransactionalJUnit4SpringTests类。事务管理的使用方法和正常使用Spring事务管理是一样的。再此需要注意的是，如果想要使用声明式事务管理，即使用AbstractTransactionalJUnitSpringContextTests类，请在applicationContext.xml文件中加入transactionManager bean\n摘至: [Spring Test 整合 JUnit 4 使用总结][1]\n\n在继承 `AbstractTransactionalJUnit4SpringContextTests` 后, 测试用例执行完成后, 所有涉及的数据库操作都会被回滚,十分方便. 不用再测试完成后再做清理现场的操作.\n\n在编写测试用例的时候, 一些注解的说明\n```\n@BeforeClass\npublic void static beforeClass() {// 做一些测试前置数据的创建工作, 只执行一次}\n@Before\npublic void before() {// 做一些测试前置数据的创建工作, 他对于每一个测试方法都回执行一次}\n@AfterClass\npublic void static afterClass() {//做一些清理现场,释放资源的操作, 只执行一次 }\n@After\npublic void after() { //做一些清理现场,释放资源的操作, 他对于每一个测试方法都回执行一次}\n```\n\n### 后记\n对于使用Spring Test做单元测试并不是十全十美, 因为有一些存储操作, 我们并不希望交由Spring管理,  例如项目中使用redis做一些缓存操作, 在使用单元测试后, 必须删除对应的缓存数据, 这时候只能手动清理现场.\n(虽然使用Spring-data-redis能交由spring管理事物, 但考虑到其他需求, 没有引入)\n\n### 参考资料\n[Spring Test 整合 JUnit 4 使用总结][1]\n\n  [1]: http://blog.csdn.net/feihong247/article/details/7828143","slug":"spring-test-start","published":1,"updated":"2018-10-11T17:47:50.627Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44t001el9394osacpph","content":"<p>在编写单元测试的时候,特别是涉及数据存储的单元测试环境中,我们需要保证测试环境的整洁,避免测试数据污染正常使用的数据库.<br>通常的做法是, 创建一个测试数据库, 使用配置文件控制在测试环境下, 数据持久化到测试环境. 这种方法比较笨拙.<br>如果使用Spring Test的话, 就可以指定在测试用例执行完毕后,对数据库进行回滚操作.</p>\n<a id=\"more\"></a>\n<h3 id=\"依赖管理\"><a href=\"#依赖管理\" class=\"headerlink\" title=\"依赖管理\"></a>依赖管理</h3><h4 id=\"JUnit\"><a href=\"#JUnit\" class=\"headerlink\" title=\"JUnit\"></a>JUnit</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;!-- junit --&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;junit&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;junit&lt;/artifactId&gt;</span><br><span class=\"line\">    &lt;version&gt;4.11&lt;/version&gt;</span><br><span class=\"line\">    &lt;scope&gt;test&lt;/scope&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>\n<h4 id=\"Spring-Test\"><a href=\"#Spring-Test\" class=\"headerlink\" title=\"Spring Test\"></a>Spring Test</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;!-- spring test --&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;spring-test&lt;/artifactId&gt;</span><br><span class=\"line\">    &lt;version&gt;4.1.2.RELEASE&lt;/version&gt;</span><br><span class=\"line\">    &lt;scope&gt;test&lt;/scope&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"测试用例编写\"><a href=\"#测试用例编写\" class=\"headerlink\" title=\"测试用例编写\"></a>测试用例编写</h3><p>在未使用Spring Test之前, 我们可以用<code>ApplicationContext</code>获取实例, 但该方法不够便捷, 每个单元测试类都需要编写一套初始化代码.<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);</span><br><span class=\"line\">MessageDao messageDao = applicationContext.getBean(&quot;messageDao&quot;);</span><br></pre></td></tr></table></figure></p>\n<p>在此可以使用Spring Test, 以期使用注解注入需要使用到的实例. 如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">@RunWith(SpringJUnit4ClassRunner.class)</span><br><span class=\"line\">@ContextConfiguration(locations=&quot;classpath:applicationContext.xml&quot;)</span><br><span class=\"line\">public class MessageDaoTest &#123;</span><br><span class=\"line\">    @Resource</span><br><span class=\"line\">    private MessageDao messageDao;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>在此, 单元测试类可以选择继承自<code>AbstractJUnit4SpringContextTests</code>或<code>AbstractTransactionalJUnit4SpringContextTests</code>. 关于上述两者的区别:</p>\n<blockquote>\n<p>如果再你的测试类中，需要用到事务管理（比如要在测试结果出来之后回滚测试内容），就可以使用AbstractTransactionalJUnit4SpringTests类。事务管理的使用方法和正常使用Spring事务管理是一样的。再此需要注意的是，如果想要使用声明式事务管理，即使用AbstractTransactionalJUnitSpringContextTests类，请在applicationContext.xml文件中加入transactionManager bean<br>摘至: <a href=\"http://blog.csdn.net/feihong247/article/details/7828143\" target=\"_blank\" rel=\"noopener\">Spring Test 整合 JUnit 4 使用总结</a></p>\n</blockquote>\n<p>在继承 <code>AbstractTransactionalJUnit4SpringContextTests</code> 后, 测试用例执行完成后, 所有涉及的数据库操作都会被回滚,十分方便. 不用再测试完成后再做清理现场的操作.</p>\n<p>在编写测试用例的时候, 一些注解的说明<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">@BeforeClass</span><br><span class=\"line\">public void static beforeClass() &#123;// 做一些测试前置数据的创建工作, 只执行一次&#125;</span><br><span class=\"line\">@Before</span><br><span class=\"line\">public void before() &#123;// 做一些测试前置数据的创建工作, 他对于每一个测试方法都回执行一次&#125;</span><br><span class=\"line\">@AfterClass</span><br><span class=\"line\">public void static afterClass() &#123;//做一些清理现场,释放资源的操作, 只执行一次 &#125;</span><br><span class=\"line\">@After</span><br><span class=\"line\">public void after() &#123; //做一些清理现场,释放资源的操作, 他对于每一个测试方法都回执行一次&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"后记\"><a href=\"#后记\" class=\"headerlink\" title=\"后记\"></a>后记</h3><p>对于使用Spring Test做单元测试并不是十全十美, 因为有一些存储操作, 我们并不希望交由Spring管理,  例如项目中使用redis做一些缓存操作, 在使用单元测试后, 必须删除对应的缓存数据, 这时候只能手动清理现场.<br>(虽然使用Spring-data-redis能交由spring管理事物, 但考虑到其他需求, 没有引入)</p>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><p><a href=\"http://blog.csdn.net/feihong247/article/details/7828143\" target=\"_blank\" rel=\"noopener\">Spring Test 整合 JUnit 4 使用总结</a></p>\n","site":{"data":{}},"excerpt":"<p>在编写单元测试的时候,特别是涉及数据存储的单元测试环境中,我们需要保证测试环境的整洁,避免测试数据污染正常使用的数据库.<br>通常的做法是, 创建一个测试数据库, 使用配置文件控制在测试环境下, 数据持久化到测试环境. 这种方法比较笨拙.<br>如果使用Spring Test的话, 就可以指定在测试用例执行完毕后,对数据库进行回滚操作.</p>","more":"<h3 id=\"依赖管理\"><a href=\"#依赖管理\" class=\"headerlink\" title=\"依赖管理\"></a>依赖管理</h3><h4 id=\"JUnit\"><a href=\"#JUnit\" class=\"headerlink\" title=\"JUnit\"></a>JUnit</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;!-- junit --&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;junit&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;junit&lt;/artifactId&gt;</span><br><span class=\"line\">    &lt;version&gt;4.11&lt;/version&gt;</span><br><span class=\"line\">    &lt;scope&gt;test&lt;/scope&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>\n<h4 id=\"Spring-Test\"><a href=\"#Spring-Test\" class=\"headerlink\" title=\"Spring Test\"></a>Spring Test</h4><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&lt;!-- spring test --&gt;</span><br><span class=\"line\">&lt;dependency&gt;</span><br><span class=\"line\">    &lt;groupId&gt;org.springframework&lt;/groupId&gt;</span><br><span class=\"line\">    &lt;artifactId&gt;spring-test&lt;/artifactId&gt;</span><br><span class=\"line\">    &lt;version&gt;4.1.2.RELEASE&lt;/version&gt;</span><br><span class=\"line\">    &lt;scope&gt;test&lt;/scope&gt;</span><br><span class=\"line\">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>\n<h3 id=\"测试用例编写\"><a href=\"#测试用例编写\" class=\"headerlink\" title=\"测试用例编写\"></a>测试用例编写</h3><p>在未使用Spring Test之前, 我们可以用<code>ApplicationContext</code>获取实例, 但该方法不够便捷, 每个单元测试类都需要编写一套初始化代码.<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);</span><br><span class=\"line\">MessageDao messageDao = applicationContext.getBean(&quot;messageDao&quot;);</span><br></pre></td></tr></table></figure></p>\n<p>在此可以使用Spring Test, 以期使用注解注入需要使用到的实例. 如下:<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">@RunWith(SpringJUnit4ClassRunner.class)</span><br><span class=\"line\">@ContextConfiguration(locations=&quot;classpath:applicationContext.xml&quot;)</span><br><span class=\"line\">public class MessageDaoTest &#123;</span><br><span class=\"line\">    @Resource</span><br><span class=\"line\">    private MessageDao messageDao;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>在此, 单元测试类可以选择继承自<code>AbstractJUnit4SpringContextTests</code>或<code>AbstractTransactionalJUnit4SpringContextTests</code>. 关于上述两者的区别:</p>\n<blockquote>\n<p>如果再你的测试类中，需要用到事务管理（比如要在测试结果出来之后回滚测试内容），就可以使用AbstractTransactionalJUnit4SpringTests类。事务管理的使用方法和正常使用Spring事务管理是一样的。再此需要注意的是，如果想要使用声明式事务管理，即使用AbstractTransactionalJUnitSpringContextTests类，请在applicationContext.xml文件中加入transactionManager bean<br>摘至: <a href=\"http://blog.csdn.net/feihong247/article/details/7828143\" target=\"_blank\" rel=\"noopener\">Spring Test 整合 JUnit 4 使用总结</a></p>\n</blockquote>\n<p>在继承 <code>AbstractTransactionalJUnit4SpringContextTests</code> 后, 测试用例执行完成后, 所有涉及的数据库操作都会被回滚,十分方便. 不用再测试完成后再做清理现场的操作.</p>\n<p>在编写测试用例的时候, 一些注解的说明<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">@BeforeClass</span><br><span class=\"line\">public void static beforeClass() &#123;// 做一些测试前置数据的创建工作, 只执行一次&#125;</span><br><span class=\"line\">@Before</span><br><span class=\"line\">public void before() &#123;// 做一些测试前置数据的创建工作, 他对于每一个测试方法都回执行一次&#125;</span><br><span class=\"line\">@AfterClass</span><br><span class=\"line\">public void static afterClass() &#123;//做一些清理现场,释放资源的操作, 只执行一次 &#125;</span><br><span class=\"line\">@After</span><br><span class=\"line\">public void after() &#123; //做一些清理现场,释放资源的操作, 他对于每一个测试方法都回执行一次&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"后记\"><a href=\"#后记\" class=\"headerlink\" title=\"后记\"></a>后记</h3><p>对于使用Spring Test做单元测试并不是十全十美, 因为有一些存储操作, 我们并不希望交由Spring管理,  例如项目中使用redis做一些缓存操作, 在使用单元测试后, 必须删除对应的缓存数据, 这时候只能手动清理现场.<br>(虽然使用Spring-data-redis能交由spring管理事物, 但考虑到其他需求, 没有引入)</p>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><p><a href=\"http://blog.csdn.net/feihong247/article/details/7828143\" target=\"_blank\" rel=\"noopener\">Spring Test 整合 JUnit 4 使用总结</a></p>"},{"layout":"post","title":"sleep(), wait()的区别","date":"2014-05-18T16:00:00.000Z","_content":"\n\n### sleep(), wait()的区别\n\n#### sleep(milliseconds)\n接收一个参数，使当前线程休眠一段时间。用户线程控制。\n特点：  \n\n* 不释放同步锁。\n\n<!-- more -->\n\n#### wait()\n调用wait()方法将会将调用者的线程挂起，直到其他线程调用同一个对象的notify()方法后，才会重新激活调用者。\n特定：  \n\n* 释放同步锁\n\n#### 总结\n其实两者都可以让线程暂停一段时间,但是本质的区别是一个线程的运行状态控制,一个是线程之间的通讯的问题\n\n\n","source":"_posts/sleep-wait-diff.md","raw":"---\nlayout: post\ntitle: \"sleep(), wait()的区别\"\ndate: 2014-05-19\ncategories:\n- java\ntags:\n- java\n\n---\n\n\n### sleep(), wait()的区别\n\n#### sleep(milliseconds)\n接收一个参数，使当前线程休眠一段时间。用户线程控制。\n特点：  \n\n* 不释放同步锁。\n\n<!-- more -->\n\n#### wait()\n调用wait()方法将会将调用者的线程挂起，直到其他线程调用同一个对象的notify()方法后，才会重新激活调用者。\n特定：  \n\n* 释放同步锁\n\n#### 总结\n其实两者都可以让线程暂停一段时间,但是本质的区别是一个线程的运行状态控制,一个是线程之间的通讯的问题\n\n\n","slug":"sleep-wait-diff","published":1,"updated":"2018-10-11T17:47:50.626Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44u001hl939ju1nkkdf","content":"<h3 id=\"sleep-wait-的区别\"><a href=\"#sleep-wait-的区别\" class=\"headerlink\" title=\"sleep(), wait()的区别\"></a>sleep(), wait()的区别</h3><h4 id=\"sleep-milliseconds\"><a href=\"#sleep-milliseconds\" class=\"headerlink\" title=\"sleep(milliseconds)\"></a>sleep(milliseconds)</h4><p>接收一个参数，使当前线程休眠一段时间。用户线程控制。<br>特点：  </p>\n<ul>\n<li>不释放同步锁。</li>\n</ul>\n<a id=\"more\"></a>\n<h4 id=\"wait\"><a href=\"#wait\" class=\"headerlink\" title=\"wait()\"></a>wait()</h4><p>调用wait()方法将会将调用者的线程挂起，直到其他线程调用同一个对象的notify()方法后，才会重新激活调用者。<br>特定：  </p>\n<ul>\n<li>释放同步锁</li>\n</ul>\n<h4 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h4><p>其实两者都可以让线程暂停一段时间,但是本质的区别是一个线程的运行状态控制,一个是线程之间的通讯的问题</p>\n","site":{"data":{}},"excerpt":"<h3 id=\"sleep-wait-的区别\"><a href=\"#sleep-wait-的区别\" class=\"headerlink\" title=\"sleep(), wait()的区别\"></a>sleep(), wait()的区别</h3><h4 id=\"sleep-milliseconds\"><a href=\"#sleep-milliseconds\" class=\"headerlink\" title=\"sleep(milliseconds)\"></a>sleep(milliseconds)</h4><p>接收一个参数，使当前线程休眠一段时间。用户线程控制。<br>特点：  </p>\n<ul>\n<li>不释放同步锁。</li>\n</ul>","more":"<h4 id=\"wait\"><a href=\"#wait\" class=\"headerlink\" title=\"wait()\"></a>wait()</h4><p>调用wait()方法将会将调用者的线程挂起，直到其他线程调用同一个对象的notify()方法后，才会重新激活调用者。<br>特定：  </p>\n<ul>\n<li>释放同步锁</li>\n</ul>\n<h4 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h4><p>其实两者都可以让线程暂停一段时间,但是本质的区别是一个线程的运行状态控制,一个是线程之间的通讯的问题</p>"},{"layout":"post","title":"Linux常用命令","date":"2014-10-04T16:00:00.000Z","_content":"\n\n**安装右键从终端启动**\n> sudo apt-get install nautilus-open-terminal\n\n**复制文件到远程目录**\n> scp filename  xiezf@192.168.248.124:/home/push\n\n<!-- more -->\n\n**如果是复制文件夹，使用**\n> scp -r filename  xiezf@192.168.248.124:/home/push\n\n**清理dns cache**\n> sudo /etc/init.d/dns-clean start \n\n**查看域名解析**\n> nslookup  api.jpush.cn","source":"_posts/tip-linux-common-command.md","raw":"---\nlayout: post\ntitle: \"Linux常用命令\"\ndate: 2014-10-05\ncategories:\n- tips\ntags:\n- linux \n---\n\n\n**安装右键从终端启动**\n> sudo apt-get install nautilus-open-terminal\n\n**复制文件到远程目录**\n> scp filename  xiezf@192.168.248.124:/home/push\n\n<!-- more -->\n\n**如果是复制文件夹，使用**\n> scp -r filename  xiezf@192.168.248.124:/home/push\n\n**清理dns cache**\n> sudo /etc/init.d/dns-clean start \n\n**查看域名解析**\n> nslookup  api.jpush.cn","slug":"tip-linux-common-command","published":1,"updated":"2018-10-11T17:47:50.627Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44v001il939y1luwgoi","content":"<p><strong>安装右键从终端启动</strong></p>\n<blockquote>\n<p>sudo apt-get install nautilus-open-terminal</p>\n</blockquote>\n<p><strong>复制文件到远程目录</strong></p>\n<blockquote>\n<p>scp filename  <a href=\"mailto:xiezf@192.168.248.124\" target=\"_blank\" rel=\"noopener\">xiezf@192.168.248.124</a>:/home/push</p>\n</blockquote>\n<a id=\"more\"></a>\n<p><strong>如果是复制文件夹，使用</strong></p>\n<blockquote>\n<p>scp -r filename  <a href=\"mailto:xiezf@192.168.248.124\" target=\"_blank\" rel=\"noopener\">xiezf@192.168.248.124</a>:/home/push</p>\n</blockquote>\n<p><strong>清理dns cache</strong></p>\n<blockquote>\n<p>sudo /etc/init.d/dns-clean start </p>\n</blockquote>\n<p><strong>查看域名解析</strong></p>\n<blockquote>\n<p>nslookup  api.jpush.cn</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"<p><strong>安装右键从终端启动</strong></p>\n<blockquote>\n<p>sudo apt-get install nautilus-open-terminal</p>\n</blockquote>\n<p><strong>复制文件到远程目录</strong></p>\n<blockquote>\n<p>scp filename  <a href=\"mailto:xiezf@192.168.248.124\" target=\"_blank\" rel=\"noopener\">xiezf@192.168.248.124</a>:/home/push</p>\n</blockquote>","more":"<p><strong>如果是复制文件夹，使用</strong></p>\n<blockquote>\n<p>scp -r filename  <a href=\"mailto:xiezf@192.168.248.124\" target=\"_blank\" rel=\"noopener\">xiezf@192.168.248.124</a>:/home/push</p>\n</blockquote>\n<p><strong>清理dns cache</strong></p>\n<blockquote>\n<p>sudo /etc/init.d/dns-clean start </p>\n</blockquote>\n<p><strong>查看域名解析</strong></p>\n<blockquote>\n<p>nslookup  api.jpush.cn</p>\n</blockquote>"},{"layout":"post","title":"Ubuntu快速安装Sublime-Text","date":"2014-10-04T16:00:00.000Z","_content":"\n\n### 通过添加PPA安装\n```\nsudo add-apt-repository ppa:webupd8team/sublime-text-2\nsudo apt-get update\nsudo apt-get install sublime-text-2\n```\n\n<!-- more -->\n\n### 安装Soda主题\n安装 Package Control, 按 `Ctrl+~`进入控制台，粘贴以下代码\n> import urllib2,os; pf='Package Control.sublime-package'; ipp=sublime.installed_packages_path(); os.makedirs(ipp) if not os.path.exists(ipp) else None; urllib2.install_opener(urllib2.build_opener(urllib2.ProxyHandler())); open(os.path.join(ipp,pf),'wb').write(urllib2.urlopen('http://sublime.wbond.net/'+pf.replace(' ','%20')).read()); print 'Please restart Sublime Text to finish installation'\n\npreferences -> package control -> 输入install package\n在此打开控制台，输入Soda，选择 Theme-Soda\nPreferences -> Settings – User中修改参数\n```\n{\n    \"ignored_packages\":\n    [\n        \"Vintage\"\n    ],\n    \"theme\": \"Soda Dark.sublime-theme\",\n    \"font_size\": 12,\n    \"font_face\": \"YaHei Consolas Hybrid\"\n}\n```\n重启Sublime Text\n\n\n","source":"_posts/tip-sublime-text-ubuntu.md","raw":"---\nlayout: post\ntitle: \"Ubuntu快速安装Sublime-Text\"\ndate: 2014-10-05\ncategories:\n- tips\ntags:\n- sublime-text\n---\n\n\n### 通过添加PPA安装\n```\nsudo add-apt-repository ppa:webupd8team/sublime-text-2\nsudo apt-get update\nsudo apt-get install sublime-text-2\n```\n\n<!-- more -->\n\n### 安装Soda主题\n安装 Package Control, 按 `Ctrl+~`进入控制台，粘贴以下代码\n> import urllib2,os; pf='Package Control.sublime-package'; ipp=sublime.installed_packages_path(); os.makedirs(ipp) if not os.path.exists(ipp) else None; urllib2.install_opener(urllib2.build_opener(urllib2.ProxyHandler())); open(os.path.join(ipp,pf),'wb').write(urllib2.urlopen('http://sublime.wbond.net/'+pf.replace(' ','%20')).read()); print 'Please restart Sublime Text to finish installation'\n\npreferences -> package control -> 输入install package\n在此打开控制台，输入Soda，选择 Theme-Soda\nPreferences -> Settings – User中修改参数\n```\n{\n    \"ignored_packages\":\n    [\n        \"Vintage\"\n    ],\n    \"theme\": \"Soda Dark.sublime-theme\",\n    \"font_size\": 12,\n    \"font_face\": \"YaHei Consolas Hybrid\"\n}\n```\n重启Sublime Text\n\n\n","slug":"tip-sublime-text-ubuntu","published":1,"updated":"2018-10-12T02:09:57.028Z","comments":1,"photos":[],"link":"","_id":"cjn5dk44x001nl939exb55zn2","content":"<h3 id=\"通过添加PPA安装\"><a href=\"#通过添加PPA安装\" class=\"headerlink\" title=\"通过添加PPA安装\"></a>通过添加PPA安装</h3><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo add-apt-repository ppa:webupd8team/sublime-text-2</span><br><span class=\"line\">sudo apt-get update</span><br><span class=\"line\">sudo apt-get install sublime-text-2</span><br></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<h3 id=\"安装Soda主题\"><a href=\"#安装Soda主题\" class=\"headerlink\" title=\"安装Soda主题\"></a>安装Soda主题</h3><p>安装 Package Control, 按 <code>Ctrl+~</code>进入控制台，粘贴以下代码</p>\n<blockquote>\n<p>import urllib2,os; pf=’Package Control.sublime-package’; ipp=sublime.installed_packages_path(); os.makedirs(ipp) if not os.path.exists(ipp) else None; urllib2.install_opener(urllib2.build_opener(urllib2.ProxyHandler())); open(os.path.join(ipp,pf),’wb’).write(urllib2.urlopen(‘<a href=\"http://sublime.wbond.net/&#39;+pf.replace\" target=\"_blank\" rel=\"noopener\">http://sublime.wbond.net/&#39;+pf.replace</a>(‘ ‘,’%20’)).read()); print ‘Please restart Sublime Text to finish installation’</p>\n</blockquote>\n<p>preferences -&gt; package control -&gt; 输入install package<br>在此打开控制台，输入Soda，选择 Theme-Soda<br>Preferences -&gt; Settings – User中修改参数<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;ignored_packages&quot;:</span><br><span class=\"line\">    [</span><br><span class=\"line\">        &quot;Vintage&quot;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;theme&quot;: &quot;Soda Dark.sublime-theme&quot;,</span><br><span class=\"line\">    &quot;font_size&quot;: 12,</span><br><span class=\"line\">    &quot;font_face&quot;: &quot;YaHei Consolas Hybrid&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>重启Sublime Text</p>\n","site":{"data":{}},"excerpt":"<h3 id=\"通过添加PPA安装\"><a href=\"#通过添加PPA安装\" class=\"headerlink\" title=\"通过添加PPA安装\"></a>通过添加PPA安装</h3><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">sudo add-apt-repository ppa:webupd8team/sublime-text-2</span><br><span class=\"line\">sudo apt-get update</span><br><span class=\"line\">sudo apt-get install sublime-text-2</span><br></pre></td></tr></table></figure>","more":"<h3 id=\"安装Soda主题\"><a href=\"#安装Soda主题\" class=\"headerlink\" title=\"安装Soda主题\"></a>安装Soda主题</h3><p>安装 Package Control, 按 <code>Ctrl+~</code>进入控制台，粘贴以下代码</p>\n<blockquote>\n<p>import urllib2,os; pf=’Package Control.sublime-package’; ipp=sublime.installed_packages_path(); os.makedirs(ipp) if not os.path.exists(ipp) else None; urllib2.install_opener(urllib2.build_opener(urllib2.ProxyHandler())); open(os.path.join(ipp,pf),’wb’).write(urllib2.urlopen(‘<a href=\"http://sublime.wbond.net/&#39;+pf.replace\" target=\"_blank\" rel=\"noopener\">http://sublime.wbond.net/&#39;+pf.replace</a>(‘ ‘,’%20’)).read()); print ‘Please restart Sublime Text to finish installation’</p>\n</blockquote>\n<p>preferences -&gt; package control -&gt; 输入install package<br>在此打开控制台，输入Soda，选择 Theme-Soda<br>Preferences -&gt; Settings – User中修改参数<br><figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">    &quot;ignored_packages&quot;:</span><br><span class=\"line\">    [</span><br><span class=\"line\">        &quot;Vintage&quot;</span><br><span class=\"line\">    ],</span><br><span class=\"line\">    &quot;theme&quot;: &quot;Soda Dark.sublime-theme&quot;,</span><br><span class=\"line\">    &quot;font_size&quot;: 12,</span><br><span class=\"line\">    &quot;font_face&quot;: &quot;YaHei Consolas Hybrid&quot;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<p>重启Sublime Text</p>"},{"layout":"post","title":"Git常用命令集","date":"2014-10-04T16:00:00.000Z","_content":"\n\n<!-- more -->\n\n**生成SSH Key**\n> ssh-keygen -t rsa -C \"committer_email@committermail.com\"  \n\n**查看自己拥有的权限**\n> ssh -lgit <git host>\n> exp: ssh -lgit git.jpushoa.com\n\n<!-- more -->\n\n**添加并提交到本地库**\n> git commit -m 'your comment'\n\n**将本地仓库添加到远程库**\n> git remote add origin <your git.git>\n\n**分支**\n> git branch -r    #查看所有分支\n> git branch [branch_name] #创建新分支\n> git checkout [branch_name] #切换到分支\n> git push origin branch_name #上传分支到远程服务器\n> git branch --set-upstream master origin/master #将本地分支链接到远程分支\n\n**Tag**\n> git tag #显示标签\n> git tag -a v3.1.1 -m 'version 3.1.1'    ＃添加标签\n> git push origin v3.1.1 ＃推送到云端\n> git tag -d v3.1.1 # 删除标签\n> git push origin :refs/tags/v3.1.1 # 将删除操作更新到远程git库\n","source":"_posts/tip-git.md","raw":"---\nlayout: post\ntitle: \"Git常用命令集\"\ndate: 2014-10-05\ncategories:\n- tips\ntags:\n- git\n---\n\n\n<!-- more -->\n\n**生成SSH Key**\n> ssh-keygen -t rsa -C \"committer_email@committermail.com\"  \n\n**查看自己拥有的权限**\n> ssh -lgit <git host>\n> exp: ssh -lgit git.jpushoa.com\n\n<!-- more -->\n\n**添加并提交到本地库**\n> git commit -m 'your comment'\n\n**将本地仓库添加到远程库**\n> git remote add origin <your git.git>\n\n**分支**\n> git branch -r    #查看所有分支\n> git branch [branch_name] #创建新分支\n> git checkout [branch_name] #切换到分支\n> git push origin branch_name #上传分支到远程服务器\n> git branch --set-upstream master origin/master #将本地分支链接到远程分支\n\n**Tag**\n> git tag #显示标签\n> git tag -a v3.1.1 -m 'version 3.1.1'    ＃添加标签\n> git push origin v3.1.1 ＃推送到云端\n> git tag -d v3.1.1 # 删除标签\n> git push origin :refs/tags/v3.1.1 # 将删除操作更新到远程git库\n","slug":"tip-git","published":1,"updated":"2018-10-11T17:47:50.627Z","comments":1,"photos":[],"link":"","_id":"cjn5dk4590031l9394vcambyp","content":"<a id=\"more\"></a>\n<p><strong>生成SSH Key</strong></p>\n<blockquote>\n<p>ssh-keygen -t rsa -C “<a href=\"mailto:committer_email@committermail.com\" target=\"_blank\" rel=\"noopener\">committer_email@committermail.com</a>“  </p>\n</blockquote>\n<p><strong>查看自己拥有的权限</strong></p>\n<blockquote>\n<p>ssh -lgit <git host=\"\"><br>exp: ssh -lgit git.jpushoa.com</git></p>\n</blockquote>\n<!-- more -->\n<p><strong>添加并提交到本地库</strong></p>\n<blockquote>\n<p>git commit -m ‘your comment’</p>\n</blockquote>\n<p><strong>将本地仓库添加到远程库</strong></p>\n<blockquote>\n<p>git remote add origin <your git.git=\"\"></your></p>\n</blockquote>\n<p><strong>分支</strong></p>\n<blockquote>\n<p>git branch -r    #查看所有分支<br>git branch [branch_name] #创建新分支<br>git checkout [branch_name] #切换到分支<br>git push origin branch_name #上传分支到远程服务器<br>git branch –set-upstream master origin/master #将本地分支链接到远程分支</p>\n</blockquote>\n<p><strong>Tag</strong></p>\n<blockquote>\n<p>git tag #显示标签<br>git tag -a v3.1.1 -m ‘version 3.1.1’    ＃添加标签<br>git push origin v3.1.1 ＃推送到云端<br>git tag -d v3.1.1 # 删除标签<br>git push origin :refs/tags/v3.1.1 # 将删除操作更新到远程git库</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>生成SSH Key</strong></p>\n<blockquote>\n<p>ssh-keygen -t rsa -C “<a href=\"mailto:committer_email@committermail.com\" target=\"_blank\" rel=\"noopener\">committer_email@committermail.com</a>“  </p>\n</blockquote>\n<p><strong>查看自己拥有的权限</strong></p>\n<blockquote>\n<p>ssh -lgit <git host=\"\"><br>exp: ssh -lgit git.jpushoa.com</git></p>\n</blockquote>\n<!-- more -->\n<p><strong>添加并提交到本地库</strong></p>\n<blockquote>\n<p>git commit -m ‘your comment’</p>\n</blockquote>\n<p><strong>将本地仓库添加到远程库</strong></p>\n<blockquote>\n<p>git remote add origin <your git.git=\"\"></your></p>\n</blockquote>\n<p><strong>分支</strong></p>\n<blockquote>\n<p>git branch -r    #查看所有分支<br>git branch [branch_name] #创建新分支<br>git checkout [branch_name] #切换到分支<br>git push origin branch_name #上传分支到远程服务器<br>git branch –set-upstream master origin/master #将本地分支链接到远程分支</p>\n</blockquote>\n<p><strong>Tag</strong></p>\n<blockquote>\n<p>git tag #显示标签<br>git tag -a v3.1.1 -m ‘version 3.1.1’    ＃添加标签<br>git push origin v3.1.1 ＃推送到云端<br>git tag -d v3.1.1 # 删除标签<br>git push origin :refs/tags/v3.1.1 # 将删除操作更新到远程git库</p>\n</blockquote>"},{"layout":"post","title":"Redis Cluster 初探(1) - 集群搭建与扩容","date":"2015-12-02T16:00:00.000Z","_content":"\nRedis Cluster是Redis官方的集群实现方案，在此之前已经有一些民间的第三方Redis集群解决方案，如Twitter的Twenproxy，豌豆荚的Codis，与其不同的是，Redis Cluster并非使用Porxy的模式来连接集群节点，而是使用无中心节点的模式来组建集群，有一定性能优势也有缺点，本文主要是我调研Redis Cluster的一些知识整理与经验汇总。\n\n<!-- more -->\n\n首先我们来尝试下搭建一个Redis Cluster集群\n\n#### 前置准备\n\nRedis Cluster需要Redis 3.0及以上版本才支持，此文发布的时候，Redis的最高版本为3.0.5。\n\n```shell\nwget http://download.redis.io/releases/redis-3.0.5.tar.gz\ntar -xvf redis-3.0.5.tar.gz\ncd redis-3.0.5\nmake\n```\n\n编译完Redis，生成的可执行文件在`redis-3.0.5/src`之中，为了方便使用，我们把可执行文件的目录加入PATH之中。\n\n```shell\nvim ~/.bashrc\n\n# 增加以下内容\n\nREDIS_HOME=/home/xiezefan/sofeware/redis-3.0.5/src\nPATH=$REDIS_HOME:$PATH\nexport PATH\n\n# 保存后让修改生效\n\nsource ~/.bashrc\n```\n\n要创建Redis Cluster，我们还需要安装Ruby以及RubyGems。\n\n```shell\nyum install ruby\nyum install gcc g++ make automake autoconf curl-devel openssl-devel zlib-devel httpd-devel apr-devel apr-util-devel sqlite-devel\nyum install ruby-rdoc ruby-devel\nyum install rubygems\ngem install redis\n```\n\n#### 创建集群\n\n此次此时我们需要创建8个节点，端口号7000~7007\n\n复制`redis-3.0.5/redis.conf`，修改一下内容\n\n```shell\nmkdir cluster\ncp ~/sofeware/redis-3.0.5/redis.conf cluster/\nvim cluster/redis.conf\n# 修改以下内容\nport 7000\ncluster-enabled yes\ncluster-config-file nodes.conf\ncluster-node-timeout 5000\nappendonly yes\n```\n\n批量复制7份，修改配置文件的端口号。修改完毕后，分别进入各个节点的目录中启动redis\n\n```shell\ncd 7000\nredis-server redis.conf\n\ncd 7001\nredis-server redis.conf\n\n# 依次启动7000-7007\n...\n\n```\n\n至此，8个Redis全都启动完毕，但是他们还处于彼此互相不知道彼此的阶段。\n\n```shell\nxiezefan@ubuntu:~$ ps -ef | grep redis\nxiezefan 13372     1  0 20:09 ?        00:00:08 redis-server *:7000 [cluster]\nxiezefan 13376     1  0 20:09 ?        00:00:08 redis-server *:7001 [cluster]\nxiezefan 13380     1  0 20:09 ?        00:00:08 redis-server *:7002 [cluster]\nxiezefan 13382     1  0 20:09 ?        00:00:08 redis-server *:7003 [cluster]\nxiezefan 13386     1  0 20:09 ?        00:00:08 redis-server *:7004 [cluster]\nxiezefan 13390     1  0 20:09 ?        00:00:08 redis-server *:7005 [cluster]\nxiezefan 13394     1  0 20:09 ?        00:00:08 redis-server *:7006 [cluster]\nxiezefan 13400     1  0 20:09 ?        00:00:08 redis-server *:7007 [cluster]\n```\n\n下一步，我们要将7000-7005这六个节点连接成一个集群。\n\n```shell\nredis-trib.rb create --replicas 1 10.211.55.4:7000 10.211.55.4:7001 10.211.55.4:7002 10.211.55.4:7003 10.211.55.4:7004 10.211.55.4:7005\n```\n\n该命令表示，将7000-7006节点创建一个集群，冗余为1，就是3主3从。切记，此处指定的IP会在client发送move命令的时候返回，所以一定要指定为客户端能访问到的IP，例如下面这种IP是不可行的，client拿到的IP就位是127.0.0.1导致一直重定向失败。\n\n```shell\nredis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005\n```\n\n输入后，redis-trib自动分配给出一个slot的分配方案\n\n```shell\n>>> Performing hash slots allocation on 6 nodes...\nUsing 3 masters:\n10.211.55.4:7000\n10.211.55.4:7001\n10.211.55.4:7002\nAdding replica 10.211.55.4:7003 to 10.211.55.4:7000\nAdding replica 10.211.55.4:7004 to 10.211.55.4:7001\nAdding replica 10.211.55.4:7005 to 10.211.55.4:7002\nM: 9dfef549f7917794cbabaf96781ed0e19957c1f3 10.211.55.4:7000\n   slots:0-5460 (5461 slots) master\nM: c14485e8d7f1f3ec5c505b41fe727b657c951d8d 10.211.55.4:7001\n   slots:5461-10922 (5462 slots) master\nM: 8b308093e99f4299b8c18ab1dd81c5a83a3528c6 10.211.55.4:7002\n   slots:10923-16383 (5461 slots) master\nS: 632409883570eb5cecf6089583fba64a41d1154f 10.211.55.4:7003\n   replicates 9dfef549f7917794cbabaf96781ed0e19957c1f3\nS: edd31196e2980360b0738c57af95e1a69b0f9c9b 10.211.55.4:7004\n   replicates c14485e8d7f1f3ec5c505b41fe727b657c951d8d\nS: 95063a99c5cf2cc4abc51ca1e8ff0f3b8d60271c 10.211.55.4:7005\n   replicates 8b308093e99f4299b8c18ab1dd81c5a83a3528c6\nCan I set the above configuration? (type 'yes' to accept):\n```\n输入yes后，集群自动创建，创建完毕后，通过redis-cli进入任一节点，使用`cluster nodes`命令可以查看各个节点的状态\n\n```shell\nxiezefan@ubuntu:~$ redis-cli -p 7000\n127.0.0.1:7000>cluster nodes\nc14485e8d7f1f3ec5c505b41fe727b657c951d8d 10.211.55.4:7001 master - 0 1449060968280 2 connected 5461-10922\n95063a99c5cf2cc4abc51ca1e8ff0f3b8d60271c 10.211.55.4:7005 slave 8b308093e99f4299b8c18ab1dd81c5a83a3528c6 0 1449060968280 6 connected\nedd31196e2980360b0738c57af95e1a69b0f9c9b 10.211.55.4:7004 slave c14485e8d7f1f3ec5c505b41fe727b657c951d8d 0 1449060967274 5 connected\n8b308093e99f4299b8c18ab1dd81c5a83a3528c6 10.211.55.4:7002 master - 0 1449060966769 3 connected 10923-16383\n632409883570eb5cecf6089583fba64a41d1154f 10.211.55.4:7003 slave 9dfef549f7917794cbabaf96781ed0e19957c1f3 0 1449060967274 4 connected\n9dfef549f7917794cbabaf96781ed0e19957c1f3 10.211.55.4:7000 myself,master - 0 0 1 connected 0-5460\n```\n\n随便输入一个查询指令`get user.1`\n\n```shell\n127.0.0.1:7000> get user.1\n(error) MOVED 9645 10.211.55.4:7001\n```\n因为user.1所在的solt-9645在7001节点上，cluster给你发送MOVED指令让你去7001节点查找数据，连接redis-cli的时候，使用`-c`参数可以指定查询时接收到MOVED指令自动跳转\n\n```shell\nxiezefan@ubuntu:~$ redis-cli -c -p 7000\n127.0.0.1:7000> get user.1\n-> Redirected to slot [9645] located at 10.211.55.4:7001\n(nil)\n```\n\n#### 集群扩容 \n\n现在我们已经有一个包含6个节点的集群，我写了段[代码](https://gist.github.com/xiezefan/4bd5e0d0c264aadaf061)，往集群写入10W条测试数据。\n现在模拟机器扩容场景，为集群加入一个master节点7006和一个slave节点7007。\n\n```\nredis-trib.rb add-node 10.211.55.4:7006 10.211.55.4:7000\n```\n\n以上命令将7006节点接入7000所在的集群。接下来，我们为7006增加一个slave节点。  \n\n```\nredis-trib.rb add-node --slave 10.211.55.4:7007 10.211.55.4:7000\n```\n  \n以上命令表示增加slave节点，将7006的节点加入7000节点所在的集群中作为slave节点，随机依附现有的master节点中slave最少的节点，如果需要再指定特别的master节点，使用\n\n```shell\nredis-trib.rb add-node --slave --master-id 23b412673af0506df6382353e3a65960d5b7e66d 10.211.55.4:7007 10.211.55.4:7000\n```\n其中的`23b412673af0506df6382353e3a65960d5b7e66d`是7006节点的id，我们可以通过`cluster nodes`命令查看节点的id。\n\n接下来我们用坐负载均衡，Slot是Redis Cluster数据承载的最小单位，我们可以指定将一定范围的Slot转移到新的节点来实现负载均衡。\n\nRedis Cluster转移一个Slot的步骤是:\n\n1. 在目标节点上声明将从源节点上迁入Slot `CLUSTER SETSLOT <slot> IMPORTING <source_node_id>`\n2. 在源节点上声明将往目标节点迁出Slot `CLUSTER SETSLOT <slot> IMPORTING <source_node_id>`\n3. 批量从源节点获取KEY `CLUSTER GETKEYSINSLOT <slot> <count>`\n4. 将获取的Key迁移到目标节点 `MIGRATE <target_ip> <target_port> <key_name> 0 <timeout>`\n5. 重复步骤3，4直到所有数据迁移完毕\n6. 分别向双方节点发送 `CLUSTER SETSLOT <slot> NODE <target_node_id>`，该命令将会广播给集群其他节点，已经将Slot转移到目标节点。\n7. 等待集群状态变为OK `CLUSTER INFO` 中的 `cluster_state = ok`\n\n我编写了一个脚本来批量迁移Slot\n\n```shell\n#!/bin/bash\nsource_host=$1  # 源节点HOST\nsource_port=$2  # 源节点端口\ntarget_host=$3  # 目标节点HOST\ntarget_port=$4  # 目标节点端口\nstart_slot=$5   # 迁移节点的其实范围\nend_slot=$6     # 迁移节点的结束范围\n\n\nfor slot in `seq ${start_slot} ${end_slot}`\ndo\n\tredis-cli -c -h ${target_host} -p ${target_port} cluster setslot ${slot} importing `redis-cli -c -h ${source_host} -p ${source_port} cluster nodes | grep ${source_port} | awk '{print $1}'`\n\techo \"Setslot importing ${slot} to ${target_host}:${target_port} success\"\n\tredis-cli -c -h ${source_host} -p ${source_port} cluster setslot ${slot} migrating `redis-cli -c -h ${target_host} -p ${target_port} cluster nodes | grep ${target_port} | awk '{print $1}'`\n\techo \"Setslot migrating ${slot} from ${source_host}:${source_port} success\"\n\n\twhile [ 1 -eq 1 ]\n\tdo\n\t\tallkeys=`redis-cli -c -h ${source_host} -p ${source_port} cluster getkeysinslot ${slot} 10`\n\t\tif [ -z \"${allkeys}\" ]\n\t\tthen\n\t\t\tredis-cli -c -h ${source_host} -p ${source_port} cluster setslot ${slot} node `redis-cli -c -h ${target_host} -p ${target_port} cluster nodes | grep ${target_port} | awk '{print $1}'`\n\t\t\tredis-cli -c -h ${target_host} -p ${target_port} cluster setslot ${slot} node `redis-cli -c -h ${source_host} -p ${target_port} cluster nodes | grep ${target_port} | awk '{print $1}'`\n\t\t\techo \"Migrate slot ${slot} finish\"\n\t\t\tbreak\n\t\telse \n\t\t\tfor key in ${allkeys}\n\t\t\tdo\n\t\t\t\tredis-cli -c -h ${source_host} -p ${source_port} migrate ${target_host} ${target_port} ${key} 0 5000\n\t\t\t\techo \"Migrate slot ${slot} key ${key} success\"\n\t\t\tdone\n\t\tfi\n\tdone\ndone\n\n```\n执行命令 `bash rebalance-cluster.sh 10.211.55.4 7000 10.211.55.4 7006 0 1000` 将7000节点上0-1000这个范围内的Slot转移到7006节点，通过`cluster nodes`命令我们可以看到0-1000这个区间是slot已经从7000转移到7006\n\n```shell\nxiezefan@ubuntu:~/sheel$ redis-cli -c -p 7000 cluster nodes\n23b412673af0506df6382353e3a65960d5b7e66d 10.211.55.4:7006 master - 0 1449064402389 7 connected 0-1000\n0c2954d21d7bcdae333f4fdecf468ce05aa25544 10.211.55.4:7001 master - 0 1449064400372 2 connected 5461-10922\n384a3bb5bd9ecb2fc7db75c866abc715d7966f82 10.211.55.4:7002 master - 0 1449064401381 3 connected 10923-16383\nc3e09d286ef2dce49843268b20832d65a5d516a1 10.211.55.4:7004 slave 0c2954d21d7bcdae333f4fdecf468ce05aa25544 0 1449064401885 5 connected\n50737b4a91443ab1a34eec4ef99d4f6fe5d358f4 10.211.55.4:7005 slave 384a3bb5bd9ecb2fc7db75c866abc715d7966f82 0 1449064402389 6 connected\n3c62cc6664bba378cceb8ae8e02f5d727deafe9d 10.211.55.4:7007 slave 23b412673af0506df6382353e3a65960d5b7e66d 0 1449064400878 7 connected\nd6441916dcd89cbf431465d92dfc0eb3dd235295 10.211.55.4:7003 slave 6ee21c5d93a6d2f293a2df1b37e8c9c27cb55ad8 0 1449064402389 4 connected\n6ee21c5d93a6d2f293a2df1b37e8c9c27cb55ad8 10.211.55.4:7000 myself,master - 0 0 1 connected 1001-5460\n```\n\n\n### 参考文章\n\n* [全面剖析Redis Cluster原理和应用](http://blog.csdn.net/dc_726/article/details/48552531)\n* [Redis集群功能预览](http://blog.csdn.net/dc_726/article/details/43991905)\n* [Redis-Cluster实战--8.Redis-Cluster水平扩容(redis-cli实现版)](http://carlosfu.iteye.com/blog/2243056)\n* [谈谈陌陌争霸在数据库方面踩过的坑( Redis 篇)](http://blog.codingnow.com/2014/03/mmzb_redis.html)\n\n","source":"_posts/redis_cluster_research_1.md","raw":"---\nlayout: post\ntitle: \"Redis Cluster 初探(1) - 集群搭建与扩容\"\ndate: 2015-12-03\ncategories:\n- Database\ntags:\n- redis\n---\n\nRedis Cluster是Redis官方的集群实现方案，在此之前已经有一些民间的第三方Redis集群解决方案，如Twitter的Twenproxy，豌豆荚的Codis，与其不同的是，Redis Cluster并非使用Porxy的模式来连接集群节点，而是使用无中心节点的模式来组建集群，有一定性能优势也有缺点，本文主要是我调研Redis Cluster的一些知识整理与经验汇总。\n\n<!-- more -->\n\n首先我们来尝试下搭建一个Redis Cluster集群\n\n#### 前置准备\n\nRedis Cluster需要Redis 3.0及以上版本才支持，此文发布的时候，Redis的最高版本为3.0.5。\n\n```shell\nwget http://download.redis.io/releases/redis-3.0.5.tar.gz\ntar -xvf redis-3.0.5.tar.gz\ncd redis-3.0.5\nmake\n```\n\n编译完Redis，生成的可执行文件在`redis-3.0.5/src`之中，为了方便使用，我们把可执行文件的目录加入PATH之中。\n\n```shell\nvim ~/.bashrc\n\n# 增加以下内容\n\nREDIS_HOME=/home/xiezefan/sofeware/redis-3.0.5/src\nPATH=$REDIS_HOME:$PATH\nexport PATH\n\n# 保存后让修改生效\n\nsource ~/.bashrc\n```\n\n要创建Redis Cluster，我们还需要安装Ruby以及RubyGems。\n\n```shell\nyum install ruby\nyum install gcc g++ make automake autoconf curl-devel openssl-devel zlib-devel httpd-devel apr-devel apr-util-devel sqlite-devel\nyum install ruby-rdoc ruby-devel\nyum install rubygems\ngem install redis\n```\n\n#### 创建集群\n\n此次此时我们需要创建8个节点，端口号7000~7007\n\n复制`redis-3.0.5/redis.conf`，修改一下内容\n\n```shell\nmkdir cluster\ncp ~/sofeware/redis-3.0.5/redis.conf cluster/\nvim cluster/redis.conf\n# 修改以下内容\nport 7000\ncluster-enabled yes\ncluster-config-file nodes.conf\ncluster-node-timeout 5000\nappendonly yes\n```\n\n批量复制7份，修改配置文件的端口号。修改完毕后，分别进入各个节点的目录中启动redis\n\n```shell\ncd 7000\nredis-server redis.conf\n\ncd 7001\nredis-server redis.conf\n\n# 依次启动7000-7007\n...\n\n```\n\n至此，8个Redis全都启动完毕，但是他们还处于彼此互相不知道彼此的阶段。\n\n```shell\nxiezefan@ubuntu:~$ ps -ef | grep redis\nxiezefan 13372     1  0 20:09 ?        00:00:08 redis-server *:7000 [cluster]\nxiezefan 13376     1  0 20:09 ?        00:00:08 redis-server *:7001 [cluster]\nxiezefan 13380     1  0 20:09 ?        00:00:08 redis-server *:7002 [cluster]\nxiezefan 13382     1  0 20:09 ?        00:00:08 redis-server *:7003 [cluster]\nxiezefan 13386     1  0 20:09 ?        00:00:08 redis-server *:7004 [cluster]\nxiezefan 13390     1  0 20:09 ?        00:00:08 redis-server *:7005 [cluster]\nxiezefan 13394     1  0 20:09 ?        00:00:08 redis-server *:7006 [cluster]\nxiezefan 13400     1  0 20:09 ?        00:00:08 redis-server *:7007 [cluster]\n```\n\n下一步，我们要将7000-7005这六个节点连接成一个集群。\n\n```shell\nredis-trib.rb create --replicas 1 10.211.55.4:7000 10.211.55.4:7001 10.211.55.4:7002 10.211.55.4:7003 10.211.55.4:7004 10.211.55.4:7005\n```\n\n该命令表示，将7000-7006节点创建一个集群，冗余为1，就是3主3从。切记，此处指定的IP会在client发送move命令的时候返回，所以一定要指定为客户端能访问到的IP，例如下面这种IP是不可行的，client拿到的IP就位是127.0.0.1导致一直重定向失败。\n\n```shell\nredis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005\n```\n\n输入后，redis-trib自动分配给出一个slot的分配方案\n\n```shell\n>>> Performing hash slots allocation on 6 nodes...\nUsing 3 masters:\n10.211.55.4:7000\n10.211.55.4:7001\n10.211.55.4:7002\nAdding replica 10.211.55.4:7003 to 10.211.55.4:7000\nAdding replica 10.211.55.4:7004 to 10.211.55.4:7001\nAdding replica 10.211.55.4:7005 to 10.211.55.4:7002\nM: 9dfef549f7917794cbabaf96781ed0e19957c1f3 10.211.55.4:7000\n   slots:0-5460 (5461 slots) master\nM: c14485e8d7f1f3ec5c505b41fe727b657c951d8d 10.211.55.4:7001\n   slots:5461-10922 (5462 slots) master\nM: 8b308093e99f4299b8c18ab1dd81c5a83a3528c6 10.211.55.4:7002\n   slots:10923-16383 (5461 slots) master\nS: 632409883570eb5cecf6089583fba64a41d1154f 10.211.55.4:7003\n   replicates 9dfef549f7917794cbabaf96781ed0e19957c1f3\nS: edd31196e2980360b0738c57af95e1a69b0f9c9b 10.211.55.4:7004\n   replicates c14485e8d7f1f3ec5c505b41fe727b657c951d8d\nS: 95063a99c5cf2cc4abc51ca1e8ff0f3b8d60271c 10.211.55.4:7005\n   replicates 8b308093e99f4299b8c18ab1dd81c5a83a3528c6\nCan I set the above configuration? (type 'yes' to accept):\n```\n输入yes后，集群自动创建，创建完毕后，通过redis-cli进入任一节点，使用`cluster nodes`命令可以查看各个节点的状态\n\n```shell\nxiezefan@ubuntu:~$ redis-cli -p 7000\n127.0.0.1:7000>cluster nodes\nc14485e8d7f1f3ec5c505b41fe727b657c951d8d 10.211.55.4:7001 master - 0 1449060968280 2 connected 5461-10922\n95063a99c5cf2cc4abc51ca1e8ff0f3b8d60271c 10.211.55.4:7005 slave 8b308093e99f4299b8c18ab1dd81c5a83a3528c6 0 1449060968280 6 connected\nedd31196e2980360b0738c57af95e1a69b0f9c9b 10.211.55.4:7004 slave c14485e8d7f1f3ec5c505b41fe727b657c951d8d 0 1449060967274 5 connected\n8b308093e99f4299b8c18ab1dd81c5a83a3528c6 10.211.55.4:7002 master - 0 1449060966769 3 connected 10923-16383\n632409883570eb5cecf6089583fba64a41d1154f 10.211.55.4:7003 slave 9dfef549f7917794cbabaf96781ed0e19957c1f3 0 1449060967274 4 connected\n9dfef549f7917794cbabaf96781ed0e19957c1f3 10.211.55.4:7000 myself,master - 0 0 1 connected 0-5460\n```\n\n随便输入一个查询指令`get user.1`\n\n```shell\n127.0.0.1:7000> get user.1\n(error) MOVED 9645 10.211.55.4:7001\n```\n因为user.1所在的solt-9645在7001节点上，cluster给你发送MOVED指令让你去7001节点查找数据，连接redis-cli的时候，使用`-c`参数可以指定查询时接收到MOVED指令自动跳转\n\n```shell\nxiezefan@ubuntu:~$ redis-cli -c -p 7000\n127.0.0.1:7000> get user.1\n-> Redirected to slot [9645] located at 10.211.55.4:7001\n(nil)\n```\n\n#### 集群扩容 \n\n现在我们已经有一个包含6个节点的集群，我写了段[代码](https://gist.github.com/xiezefan/4bd5e0d0c264aadaf061)，往集群写入10W条测试数据。\n现在模拟机器扩容场景，为集群加入一个master节点7006和一个slave节点7007。\n\n```\nredis-trib.rb add-node 10.211.55.4:7006 10.211.55.4:7000\n```\n\n以上命令将7006节点接入7000所在的集群。接下来，我们为7006增加一个slave节点。  \n\n```\nredis-trib.rb add-node --slave 10.211.55.4:7007 10.211.55.4:7000\n```\n  \n以上命令表示增加slave节点，将7006的节点加入7000节点所在的集群中作为slave节点，随机依附现有的master节点中slave最少的节点，如果需要再指定特别的master节点，使用\n\n```shell\nredis-trib.rb add-node --slave --master-id 23b412673af0506df6382353e3a65960d5b7e66d 10.211.55.4:7007 10.211.55.4:7000\n```\n其中的`23b412673af0506df6382353e3a65960d5b7e66d`是7006节点的id，我们可以通过`cluster nodes`命令查看节点的id。\n\n接下来我们用坐负载均衡，Slot是Redis Cluster数据承载的最小单位，我们可以指定将一定范围的Slot转移到新的节点来实现负载均衡。\n\nRedis Cluster转移一个Slot的步骤是:\n\n1. 在目标节点上声明将从源节点上迁入Slot `CLUSTER SETSLOT <slot> IMPORTING <source_node_id>`\n2. 在源节点上声明将往目标节点迁出Slot `CLUSTER SETSLOT <slot> IMPORTING <source_node_id>`\n3. 批量从源节点获取KEY `CLUSTER GETKEYSINSLOT <slot> <count>`\n4. 将获取的Key迁移到目标节点 `MIGRATE <target_ip> <target_port> <key_name> 0 <timeout>`\n5. 重复步骤3，4直到所有数据迁移完毕\n6. 分别向双方节点发送 `CLUSTER SETSLOT <slot> NODE <target_node_id>`，该命令将会广播给集群其他节点，已经将Slot转移到目标节点。\n7. 等待集群状态变为OK `CLUSTER INFO` 中的 `cluster_state = ok`\n\n我编写了一个脚本来批量迁移Slot\n\n```shell\n#!/bin/bash\nsource_host=$1  # 源节点HOST\nsource_port=$2  # 源节点端口\ntarget_host=$3  # 目标节点HOST\ntarget_port=$4  # 目标节点端口\nstart_slot=$5   # 迁移节点的其实范围\nend_slot=$6     # 迁移节点的结束范围\n\n\nfor slot in `seq ${start_slot} ${end_slot}`\ndo\n\tredis-cli -c -h ${target_host} -p ${target_port} cluster setslot ${slot} importing `redis-cli -c -h ${source_host} -p ${source_port} cluster nodes | grep ${source_port} | awk '{print $1}'`\n\techo \"Setslot importing ${slot} to ${target_host}:${target_port} success\"\n\tredis-cli -c -h ${source_host} -p ${source_port} cluster setslot ${slot} migrating `redis-cli -c -h ${target_host} -p ${target_port} cluster nodes | grep ${target_port} | awk '{print $1}'`\n\techo \"Setslot migrating ${slot} from ${source_host}:${source_port} success\"\n\n\twhile [ 1 -eq 1 ]\n\tdo\n\t\tallkeys=`redis-cli -c -h ${source_host} -p ${source_port} cluster getkeysinslot ${slot} 10`\n\t\tif [ -z \"${allkeys}\" ]\n\t\tthen\n\t\t\tredis-cli -c -h ${source_host} -p ${source_port} cluster setslot ${slot} node `redis-cli -c -h ${target_host} -p ${target_port} cluster nodes | grep ${target_port} | awk '{print $1}'`\n\t\t\tredis-cli -c -h ${target_host} -p ${target_port} cluster setslot ${slot} node `redis-cli -c -h ${source_host} -p ${target_port} cluster nodes | grep ${target_port} | awk '{print $1}'`\n\t\t\techo \"Migrate slot ${slot} finish\"\n\t\t\tbreak\n\t\telse \n\t\t\tfor key in ${allkeys}\n\t\t\tdo\n\t\t\t\tredis-cli -c -h ${source_host} -p ${source_port} migrate ${target_host} ${target_port} ${key} 0 5000\n\t\t\t\techo \"Migrate slot ${slot} key ${key} success\"\n\t\t\tdone\n\t\tfi\n\tdone\ndone\n\n```\n执行命令 `bash rebalance-cluster.sh 10.211.55.4 7000 10.211.55.4 7006 0 1000` 将7000节点上0-1000这个范围内的Slot转移到7006节点，通过`cluster nodes`命令我们可以看到0-1000这个区间是slot已经从7000转移到7006\n\n```shell\nxiezefan@ubuntu:~/sheel$ redis-cli -c -p 7000 cluster nodes\n23b412673af0506df6382353e3a65960d5b7e66d 10.211.55.4:7006 master - 0 1449064402389 7 connected 0-1000\n0c2954d21d7bcdae333f4fdecf468ce05aa25544 10.211.55.4:7001 master - 0 1449064400372 2 connected 5461-10922\n384a3bb5bd9ecb2fc7db75c866abc715d7966f82 10.211.55.4:7002 master - 0 1449064401381 3 connected 10923-16383\nc3e09d286ef2dce49843268b20832d65a5d516a1 10.211.55.4:7004 slave 0c2954d21d7bcdae333f4fdecf468ce05aa25544 0 1449064401885 5 connected\n50737b4a91443ab1a34eec4ef99d4f6fe5d358f4 10.211.55.4:7005 slave 384a3bb5bd9ecb2fc7db75c866abc715d7966f82 0 1449064402389 6 connected\n3c62cc6664bba378cceb8ae8e02f5d727deafe9d 10.211.55.4:7007 slave 23b412673af0506df6382353e3a65960d5b7e66d 0 1449064400878 7 connected\nd6441916dcd89cbf431465d92dfc0eb3dd235295 10.211.55.4:7003 slave 6ee21c5d93a6d2f293a2df1b37e8c9c27cb55ad8 0 1449064402389 4 connected\n6ee21c5d93a6d2f293a2df1b37e8c9c27cb55ad8 10.211.55.4:7000 myself,master - 0 0 1 connected 1001-5460\n```\n\n\n### 参考文章\n\n* [全面剖析Redis Cluster原理和应用](http://blog.csdn.net/dc_726/article/details/48552531)\n* [Redis集群功能预览](http://blog.csdn.net/dc_726/article/details/43991905)\n* [Redis-Cluster实战--8.Redis-Cluster水平扩容(redis-cli实现版)](http://carlosfu.iteye.com/blog/2243056)\n* [谈谈陌陌争霸在数据库方面踩过的坑( Redis 篇)](http://blog.codingnow.com/2014/03/mmzb_redis.html)\n\n","slug":"redis_cluster_research_1","published":1,"updated":"2018-10-11T17:47:50.626Z","comments":1,"photos":[],"link":"","_id":"cjn5dk45a0032l939seupkeeq","content":"<p>Redis Cluster是Redis官方的集群实现方案，在此之前已经有一些民间的第三方Redis集群解决方案，如Twitter的Twenproxy，豌豆荚的Codis，与其不同的是，Redis Cluster并非使用Porxy的模式来连接集群节点，而是使用无中心节点的模式来组建集群，有一定性能优势也有缺点，本文主要是我调研Redis Cluster的一些知识整理与经验汇总。</p>\n<a id=\"more\"></a>\n<p>首先我们来尝试下搭建一个Redis Cluster集群</p>\n<h4 id=\"前置准备\"><a href=\"#前置准备\" class=\"headerlink\" title=\"前置准备\"></a>前置准备</h4><p>Redis Cluster需要Redis 3.0及以上版本才支持，此文发布的时候，Redis的最高版本为3.0.5。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">wget http://download.redis.io/releases/redis-3.0.5.tar.gz</span><br><span class=\"line\">tar -xvf redis-3.0.5.tar.gz</span><br><span class=\"line\">cd redis-3.0.5</span><br><span class=\"line\">make</span><br></pre></td></tr></table></figure>\n<p>编译完Redis，生成的可执行文件在<code>redis-3.0.5/src</code>之中，为了方便使用，我们把可执行文件的目录加入PATH之中。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">vim ~/.bashrc</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> 增加以下内容</span><br><span class=\"line\"></span><br><span class=\"line\">REDIS_HOME=/home/xiezefan/sofeware/redis-3.0.5/src</span><br><span class=\"line\">PATH=$REDIS_HOME:$PATH</span><br><span class=\"line\">export PATH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> 保存后让修改生效</span><br><span class=\"line\"></span><br><span class=\"line\">source ~/.bashrc</span><br></pre></td></tr></table></figure>\n<p>要创建Redis Cluster，我们还需要安装Ruby以及RubyGems。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">yum install ruby</span><br><span class=\"line\">yum install gcc g++ make automake autoconf curl-devel openssl-devel zlib-devel httpd-devel apr-devel apr-util-devel sqlite-devel</span><br><span class=\"line\">yum install ruby-rdoc ruby-devel</span><br><span class=\"line\">yum install rubygems</span><br><span class=\"line\">gem install redis</span><br></pre></td></tr></table></figure>\n<h4 id=\"创建集群\"><a href=\"#创建集群\" class=\"headerlink\" title=\"创建集群\"></a>创建集群</h4><p>此次此时我们需要创建8个节点，端口号7000~7007</p>\n<p>复制<code>redis-3.0.5/redis.conf</code>，修改一下内容</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">mkdir cluster</span><br><span class=\"line\">cp ~/sofeware/redis-3.0.5/redis.conf cluster/</span><br><span class=\"line\">vim cluster/redis.conf</span><br><span class=\"line\"><span class=\"meta\">#</span> 修改以下内容</span><br><span class=\"line\">port 7000</span><br><span class=\"line\">cluster-enabled yes</span><br><span class=\"line\">cluster-config-file nodes.conf</span><br><span class=\"line\">cluster-node-timeout 5000</span><br><span class=\"line\">appendonly yes</span><br></pre></td></tr></table></figure>\n<p>批量复制7份，修改配置文件的端口号。修改完毕后，分别进入各个节点的目录中启动redis</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">cd 7000</span><br><span class=\"line\">redis-server redis.conf</span><br><span class=\"line\"></span><br><span class=\"line\">cd 7001</span><br><span class=\"line\">redis-server redis.conf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> 依次启动7000-7007</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>至此，8个Redis全都启动完毕，但是他们还处于彼此互相不知道彼此的阶段。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">xiezefan@ubuntu:~$ ps -ef | grep redis</span><br><span class=\"line\">xiezefan 13372     1  0 20:09 ?        00:00:08 redis-server *:7000 [cluster]</span><br><span class=\"line\">xiezefan 13376     1  0 20:09 ?        00:00:08 redis-server *:7001 [cluster]</span><br><span class=\"line\">xiezefan 13380     1  0 20:09 ?        00:00:08 redis-server *:7002 [cluster]</span><br><span class=\"line\">xiezefan 13382     1  0 20:09 ?        00:00:08 redis-server *:7003 [cluster]</span><br><span class=\"line\">xiezefan 13386     1  0 20:09 ?        00:00:08 redis-server *:7004 [cluster]</span><br><span class=\"line\">xiezefan 13390     1  0 20:09 ?        00:00:08 redis-server *:7005 [cluster]</span><br><span class=\"line\">xiezefan 13394     1  0 20:09 ?        00:00:08 redis-server *:7006 [cluster]</span><br><span class=\"line\">xiezefan 13400     1  0 20:09 ?        00:00:08 redis-server *:7007 [cluster]</span><br></pre></td></tr></table></figure>\n<p>下一步，我们要将7000-7005这六个节点连接成一个集群。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">redis-trib.rb create --replicas 1 10.211.55.4:7000 10.211.55.4:7001 10.211.55.4:7002 10.211.55.4:7003 10.211.55.4:7004 10.211.55.4:7005</span><br></pre></td></tr></table></figure>\n<p>该命令表示，将7000-7006节点创建一个集群，冗余为1，就是3主3从。切记，此处指定的IP会在client发送move命令的时候返回，所以一定要指定为客户端能访问到的IP，例如下面这种IP是不可行的，client拿到的IP就位是127.0.0.1导致一直重定向失败。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005</span><br></pre></td></tr></table></figure>\n<p>输入后，redis-trib自动分配给出一个slot的分配方案</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span>&gt;&gt; Performing hash slots allocation on 6 nodes...</span><br><span class=\"line\">Using 3 masters:</span><br><span class=\"line\">10.211.55.4:7000</span><br><span class=\"line\">10.211.55.4:7001</span><br><span class=\"line\">10.211.55.4:7002</span><br><span class=\"line\">Adding replica 10.211.55.4:7003 to 10.211.55.4:7000</span><br><span class=\"line\">Adding replica 10.211.55.4:7004 to 10.211.55.4:7001</span><br><span class=\"line\">Adding replica 10.211.55.4:7005 to 10.211.55.4:7002</span><br><span class=\"line\">M: 9dfef549f7917794cbabaf96781ed0e19957c1f3 10.211.55.4:7000</span><br><span class=\"line\">   slots:0-5460 (5461 slots) master</span><br><span class=\"line\">M: c14485e8d7f1f3ec5c505b41fe727b657c951d8d 10.211.55.4:7001</span><br><span class=\"line\">   slots:5461-10922 (5462 slots) master</span><br><span class=\"line\">M: 8b308093e99f4299b8c18ab1dd81c5a83a3528c6 10.211.55.4:7002</span><br><span class=\"line\">   slots:10923-16383 (5461 slots) master</span><br><span class=\"line\">S: 632409883570eb5cecf6089583fba64a41d1154f 10.211.55.4:7003</span><br><span class=\"line\">   replicates 9dfef549f7917794cbabaf96781ed0e19957c1f3</span><br><span class=\"line\">S: edd31196e2980360b0738c57af95e1a69b0f9c9b 10.211.55.4:7004</span><br><span class=\"line\">   replicates c14485e8d7f1f3ec5c505b41fe727b657c951d8d</span><br><span class=\"line\">S: 95063a99c5cf2cc4abc51ca1e8ff0f3b8d60271c 10.211.55.4:7005</span><br><span class=\"line\">   replicates 8b308093e99f4299b8c18ab1dd81c5a83a3528c6</span><br><span class=\"line\">Can I set the above configuration? (type 'yes' to accept):</span><br></pre></td></tr></table></figure>\n<p>输入yes后，集群自动创建，创建完毕后，通过redis-cli进入任一节点，使用<code>cluster nodes</code>命令可以查看各个节点的状态</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">xiezefan@ubuntu:~$ redis-cli -p 7000</span><br><span class=\"line\">127.0.0.1:7000&gt;cluster nodes</span><br><span class=\"line\">c14485e8d7f1f3ec5c505b41fe727b657c951d8d 10.211.55.4:7001 master - 0 1449060968280 2 connected 5461-10922</span><br><span class=\"line\">95063a99c5cf2cc4abc51ca1e8ff0f3b8d60271c 10.211.55.4:7005 slave 8b308093e99f4299b8c18ab1dd81c5a83a3528c6 0 1449060968280 6 connected</span><br><span class=\"line\">edd31196e2980360b0738c57af95e1a69b0f9c9b 10.211.55.4:7004 slave c14485e8d7f1f3ec5c505b41fe727b657c951d8d 0 1449060967274 5 connected</span><br><span class=\"line\">8b308093e99f4299b8c18ab1dd81c5a83a3528c6 10.211.55.4:7002 master - 0 1449060966769 3 connected 10923-16383</span><br><span class=\"line\">632409883570eb5cecf6089583fba64a41d1154f 10.211.55.4:7003 slave 9dfef549f7917794cbabaf96781ed0e19957c1f3 0 1449060967274 4 connected</span><br><span class=\"line\">9dfef549f7917794cbabaf96781ed0e19957c1f3 10.211.55.4:7000 myself,master - 0 0 1 connected 0-5460</span><br></pre></td></tr></table></figure>\n<p>随便输入一个查询指令<code>get user.1</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">127.0.0.1:7000&gt; get user.1</span><br><span class=\"line\">(error) MOVED 9645 10.211.55.4:7001</span><br></pre></td></tr></table></figure>\n<p>因为user.1所在的solt-9645在7001节点上，cluster给你发送MOVED指令让你去7001节点查找数据，连接redis-cli的时候，使用<code>-c</code>参数可以指定查询时接收到MOVED指令自动跳转</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">xiezefan@ubuntu:~$ redis-cli -c -p 7000</span><br><span class=\"line\">127.0.0.1:7000&gt; get user.1</span><br><span class=\"line\"><span class=\"meta\">-&gt;</span> Redirected to slot [9645] located at 10.211.55.4:7001</span><br><span class=\"line\">(nil)</span><br></pre></td></tr></table></figure>\n<h4 id=\"集群扩容\"><a href=\"#集群扩容\" class=\"headerlink\" title=\"集群扩容\"></a>集群扩容</h4><p>现在我们已经有一个包含6个节点的集群，我写了段<a href=\"https://gist.github.com/xiezefan/4bd5e0d0c264aadaf061\" target=\"_blank\" rel=\"noopener\">代码</a>，往集群写入10W条测试数据。<br>现在模拟机器扩容场景，为集群加入一个master节点7006和一个slave节点7007。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">redis-trib.rb add-node 10.211.55.4:7006 10.211.55.4:7000</span><br></pre></td></tr></table></figure>\n<p>以上命令将7006节点接入7000所在的集群。接下来，我们为7006增加一个slave节点。  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">redis-trib.rb add-node --slave 10.211.55.4:7007 10.211.55.4:7000</span><br></pre></td></tr></table></figure>\n<p>以上命令表示增加slave节点，将7006的节点加入7000节点所在的集群中作为slave节点，随机依附现有的master节点中slave最少的节点，如果需要再指定特别的master节点，使用</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">redis-trib.rb add-node --slave --master-id 23b412673af0506df6382353e3a65960d5b7e66d 10.211.55.4:7007 10.211.55.4:7000</span><br></pre></td></tr></table></figure>\n<p>其中的<code>23b412673af0506df6382353e3a65960d5b7e66d</code>是7006节点的id，我们可以通过<code>cluster nodes</code>命令查看节点的id。</p>\n<p>接下来我们用坐负载均衡，Slot是Redis Cluster数据承载的最小单位，我们可以指定将一定范围的Slot转移到新的节点来实现负载均衡。</p>\n<p>Redis Cluster转移一个Slot的步骤是:</p>\n<ol>\n<li>在目标节点上声明将从源节点上迁入Slot <code>CLUSTER SETSLOT &lt;slot&gt; IMPORTING &lt;source_node_id&gt;</code></li>\n<li>在源节点上声明将往目标节点迁出Slot <code>CLUSTER SETSLOT &lt;slot&gt; IMPORTING &lt;source_node_id&gt;</code></li>\n<li>批量从源节点获取KEY <code>CLUSTER GETKEYSINSLOT &lt;slot&gt; &lt;count&gt;</code></li>\n<li>将获取的Key迁移到目标节点 <code>MIGRATE &lt;target_ip&gt; &lt;target_port&gt; &lt;key_name&gt; 0 &lt;timeout&gt;</code></li>\n<li>重复步骤3，4直到所有数据迁移完毕</li>\n<li>分别向双方节点发送 <code>CLUSTER SETSLOT &lt;slot&gt; NODE &lt;target_node_id&gt;</code>，该命令将会广播给集群其他节点，已经将Slot转移到目标节点。</li>\n<li>等待集群状态变为OK <code>CLUSTER INFO</code> 中的 <code>cluster_state = ok</code></li>\n</ol>\n<p>我编写了一个脚本来批量迁移Slot</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>!/bin/bash</span><br><span class=\"line\">source_host=$1  # 源节点HOST</span><br><span class=\"line\">source_port=$2  # 源节点端口</span><br><span class=\"line\">target_host=$3  # 目标节点HOST</span><br><span class=\"line\">target_port=$4  # 目标节点端口</span><br><span class=\"line\">start_slot=$5   # 迁移节点的其实范围</span><br><span class=\"line\">end_slot=$6     # 迁移节点的结束范围</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">for slot in `seq $&#123;start_slot&#125; $&#123;end_slot&#125;`</span><br><span class=\"line\">do</span><br><span class=\"line\">\tredis-cli -c -h $&#123;target_host&#125; -p $&#123;target_port&#125; cluster setslot $&#123;slot&#125; importing `redis-cli -c -h $&#123;source_host&#125; -p $&#123;source_port&#125; cluster nodes | grep $&#123;source_port&#125; | awk '&#123;print $1&#125;'`</span><br><span class=\"line\">\techo \"Setslot importing $&#123;slot&#125; to $&#123;target_host&#125;:$&#123;target_port&#125; success\"</span><br><span class=\"line\">\tredis-cli -c -h $&#123;source_host&#125; -p $&#123;source_port&#125; cluster setslot $&#123;slot&#125; migrating `redis-cli -c -h $&#123;target_host&#125; -p $&#123;target_port&#125; cluster nodes | grep $&#123;target_port&#125; | awk '&#123;print $1&#125;'`</span><br><span class=\"line\">\techo \"Setslot migrating $&#123;slot&#125; from $&#123;source_host&#125;:$&#123;source_port&#125; success\"</span><br><span class=\"line\"></span><br><span class=\"line\">\twhile [ 1 -eq 1 ]</span><br><span class=\"line\">\tdo</span><br><span class=\"line\">\t\tallkeys=`redis-cli -c -h $&#123;source_host&#125; -p $&#123;source_port&#125; cluster getkeysinslot $&#123;slot&#125; 10`</span><br><span class=\"line\">\t\tif [ -z \"$&#123;allkeys&#125;\" ]</span><br><span class=\"line\">\t\tthen</span><br><span class=\"line\">\t\t\tredis-cli -c -h $&#123;source_host&#125; -p $&#123;source_port&#125; cluster setslot $&#123;slot&#125; node `redis-cli -c -h $&#123;target_host&#125; -p $&#123;target_port&#125; cluster nodes | grep $&#123;target_port&#125; | awk '&#123;print $1&#125;'`</span><br><span class=\"line\">\t\t\tredis-cli -c -h $&#123;target_host&#125; -p $&#123;target_port&#125; cluster setslot $&#123;slot&#125; node `redis-cli -c -h $&#123;source_host&#125; -p $&#123;target_port&#125; cluster nodes | grep $&#123;target_port&#125; | awk '&#123;print $1&#125;'`</span><br><span class=\"line\">\t\t\techo \"Migrate slot $&#123;slot&#125; finish\"</span><br><span class=\"line\">\t\t\tbreak</span><br><span class=\"line\">\t\telse </span><br><span class=\"line\">\t\t\tfor key in $&#123;allkeys&#125;</span><br><span class=\"line\">\t\t\tdo</span><br><span class=\"line\">\t\t\t\tredis-cli -c -h $&#123;source_host&#125; -p $&#123;source_port&#125; migrate $&#123;target_host&#125; $&#123;target_port&#125; $&#123;key&#125; 0 5000</span><br><span class=\"line\">\t\t\t\techo \"Migrate slot $&#123;slot&#125; key $&#123;key&#125; success\"</span><br><span class=\"line\">\t\t\tdone</span><br><span class=\"line\">\t\tfi</span><br><span class=\"line\">\tdone</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<p>执行命令 <code>bash rebalance-cluster.sh 10.211.55.4 7000 10.211.55.4 7006 0 1000</code> 将7000节点上0-1000这个范围内的Slot转移到7006节点，通过<code>cluster nodes</code>命令我们可以看到0-1000这个区间是slot已经从7000转移到7006</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">xiezefan@ubuntu:~/sheel$ redis-cli -c -p 7000 cluster nodes</span><br><span class=\"line\">23b412673af0506df6382353e3a65960d5b7e66d 10.211.55.4:7006 master - 0 1449064402389 7 connected 0-1000</span><br><span class=\"line\">0c2954d21d7bcdae333f4fdecf468ce05aa25544 10.211.55.4:7001 master - 0 1449064400372 2 connected 5461-10922</span><br><span class=\"line\">384a3bb5bd9ecb2fc7db75c866abc715d7966f82 10.211.55.4:7002 master - 0 1449064401381 3 connected 10923-16383</span><br><span class=\"line\">c3e09d286ef2dce49843268b20832d65a5d516a1 10.211.55.4:7004 slave 0c2954d21d7bcdae333f4fdecf468ce05aa25544 0 1449064401885 5 connected</span><br><span class=\"line\">50737b4a91443ab1a34eec4ef99d4f6fe5d358f4 10.211.55.4:7005 slave 384a3bb5bd9ecb2fc7db75c866abc715d7966f82 0 1449064402389 6 connected</span><br><span class=\"line\">3c62cc6664bba378cceb8ae8e02f5d727deafe9d 10.211.55.4:7007 slave 23b412673af0506df6382353e3a65960d5b7e66d 0 1449064400878 7 connected</span><br><span class=\"line\">d6441916dcd89cbf431465d92dfc0eb3dd235295 10.211.55.4:7003 slave 6ee21c5d93a6d2f293a2df1b37e8c9c27cb55ad8 0 1449064402389 4 connected</span><br><span class=\"line\">6ee21c5d93a6d2f293a2df1b37e8c9c27cb55ad8 10.211.55.4:7000 myself,master - 0 0 1 connected 1001-5460</span><br></pre></td></tr></table></figure>\n<h3 id=\"参考文章\"><a href=\"#参考文章\" class=\"headerlink\" title=\"参考文章\"></a>参考文章</h3><ul>\n<li><a href=\"http://blog.csdn.net/dc_726/article/details/48552531\" target=\"_blank\" rel=\"noopener\">全面剖析Redis Cluster原理和应用</a></li>\n<li><a href=\"http://blog.csdn.net/dc_726/article/details/43991905\" target=\"_blank\" rel=\"noopener\">Redis集群功能预览</a></li>\n<li><a href=\"http://carlosfu.iteye.com/blog/2243056\" target=\"_blank\" rel=\"noopener\">Redis-Cluster实战–8.Redis-Cluster水平扩容(redis-cli实现版)</a></li>\n<li><a href=\"http://blog.codingnow.com/2014/03/mmzb_redis.html\" target=\"_blank\" rel=\"noopener\">谈谈陌陌争霸在数据库方面踩过的坑( Redis 篇)</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>Redis Cluster是Redis官方的集群实现方案，在此之前已经有一些民间的第三方Redis集群解决方案，如Twitter的Twenproxy，豌豆荚的Codis，与其不同的是，Redis Cluster并非使用Porxy的模式来连接集群节点，而是使用无中心节点的模式来组建集群，有一定性能优势也有缺点，本文主要是我调研Redis Cluster的一些知识整理与经验汇总。</p>","more":"<p>首先我们来尝试下搭建一个Redis Cluster集群</p>\n<h4 id=\"前置准备\"><a href=\"#前置准备\" class=\"headerlink\" title=\"前置准备\"></a>前置准备</h4><p>Redis Cluster需要Redis 3.0及以上版本才支持，此文发布的时候，Redis的最高版本为3.0.5。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">wget http://download.redis.io/releases/redis-3.0.5.tar.gz</span><br><span class=\"line\">tar -xvf redis-3.0.5.tar.gz</span><br><span class=\"line\">cd redis-3.0.5</span><br><span class=\"line\">make</span><br></pre></td></tr></table></figure>\n<p>编译完Redis，生成的可执行文件在<code>redis-3.0.5/src</code>之中，为了方便使用，我们把可执行文件的目录加入PATH之中。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">vim ~/.bashrc</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> 增加以下内容</span><br><span class=\"line\"></span><br><span class=\"line\">REDIS_HOME=/home/xiezefan/sofeware/redis-3.0.5/src</span><br><span class=\"line\">PATH=$REDIS_HOME:$PATH</span><br><span class=\"line\">export PATH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> 保存后让修改生效</span><br><span class=\"line\"></span><br><span class=\"line\">source ~/.bashrc</span><br></pre></td></tr></table></figure>\n<p>要创建Redis Cluster，我们还需要安装Ruby以及RubyGems。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">yum install ruby</span><br><span class=\"line\">yum install gcc g++ make automake autoconf curl-devel openssl-devel zlib-devel httpd-devel apr-devel apr-util-devel sqlite-devel</span><br><span class=\"line\">yum install ruby-rdoc ruby-devel</span><br><span class=\"line\">yum install rubygems</span><br><span class=\"line\">gem install redis</span><br></pre></td></tr></table></figure>\n<h4 id=\"创建集群\"><a href=\"#创建集群\" class=\"headerlink\" title=\"创建集群\"></a>创建集群</h4><p>此次此时我们需要创建8个节点，端口号7000~7007</p>\n<p>复制<code>redis-3.0.5/redis.conf</code>，修改一下内容</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">mkdir cluster</span><br><span class=\"line\">cp ~/sofeware/redis-3.0.5/redis.conf cluster/</span><br><span class=\"line\">vim cluster/redis.conf</span><br><span class=\"line\"><span class=\"meta\">#</span> 修改以下内容</span><br><span class=\"line\">port 7000</span><br><span class=\"line\">cluster-enabled yes</span><br><span class=\"line\">cluster-config-file nodes.conf</span><br><span class=\"line\">cluster-node-timeout 5000</span><br><span class=\"line\">appendonly yes</span><br></pre></td></tr></table></figure>\n<p>批量复制7份，修改配置文件的端口号。修改完毕后，分别进入各个节点的目录中启动redis</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">cd 7000</span><br><span class=\"line\">redis-server redis.conf</span><br><span class=\"line\"></span><br><span class=\"line\">cd 7001</span><br><span class=\"line\">redis-server redis.conf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> 依次启动7000-7007</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>至此，8个Redis全都启动完毕，但是他们还处于彼此互相不知道彼此的阶段。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">xiezefan@ubuntu:~$ ps -ef | grep redis</span><br><span class=\"line\">xiezefan 13372     1  0 20:09 ?        00:00:08 redis-server *:7000 [cluster]</span><br><span class=\"line\">xiezefan 13376     1  0 20:09 ?        00:00:08 redis-server *:7001 [cluster]</span><br><span class=\"line\">xiezefan 13380     1  0 20:09 ?        00:00:08 redis-server *:7002 [cluster]</span><br><span class=\"line\">xiezefan 13382     1  0 20:09 ?        00:00:08 redis-server *:7003 [cluster]</span><br><span class=\"line\">xiezefan 13386     1  0 20:09 ?        00:00:08 redis-server *:7004 [cluster]</span><br><span class=\"line\">xiezefan 13390     1  0 20:09 ?        00:00:08 redis-server *:7005 [cluster]</span><br><span class=\"line\">xiezefan 13394     1  0 20:09 ?        00:00:08 redis-server *:7006 [cluster]</span><br><span class=\"line\">xiezefan 13400     1  0 20:09 ?        00:00:08 redis-server *:7007 [cluster]</span><br></pre></td></tr></table></figure>\n<p>下一步，我们要将7000-7005这六个节点连接成一个集群。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">redis-trib.rb create --replicas 1 10.211.55.4:7000 10.211.55.4:7001 10.211.55.4:7002 10.211.55.4:7003 10.211.55.4:7004 10.211.55.4:7005</span><br></pre></td></tr></table></figure>\n<p>该命令表示，将7000-7006节点创建一个集群，冗余为1，就是3主3从。切记，此处指定的IP会在client发送move命令的时候返回，所以一定要指定为客户端能访问到的IP，例如下面这种IP是不可行的，client拿到的IP就位是127.0.0.1导致一直重定向失败。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005</span><br></pre></td></tr></table></figure>\n<p>输入后，redis-trib自动分配给出一个slot的分配方案</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&gt;</span>&gt;&gt; Performing hash slots allocation on 6 nodes...</span><br><span class=\"line\">Using 3 masters:</span><br><span class=\"line\">10.211.55.4:7000</span><br><span class=\"line\">10.211.55.4:7001</span><br><span class=\"line\">10.211.55.4:7002</span><br><span class=\"line\">Adding replica 10.211.55.4:7003 to 10.211.55.4:7000</span><br><span class=\"line\">Adding replica 10.211.55.4:7004 to 10.211.55.4:7001</span><br><span class=\"line\">Adding replica 10.211.55.4:7005 to 10.211.55.4:7002</span><br><span class=\"line\">M: 9dfef549f7917794cbabaf96781ed0e19957c1f3 10.211.55.4:7000</span><br><span class=\"line\">   slots:0-5460 (5461 slots) master</span><br><span class=\"line\">M: c14485e8d7f1f3ec5c505b41fe727b657c951d8d 10.211.55.4:7001</span><br><span class=\"line\">   slots:5461-10922 (5462 slots) master</span><br><span class=\"line\">M: 8b308093e99f4299b8c18ab1dd81c5a83a3528c6 10.211.55.4:7002</span><br><span class=\"line\">   slots:10923-16383 (5461 slots) master</span><br><span class=\"line\">S: 632409883570eb5cecf6089583fba64a41d1154f 10.211.55.4:7003</span><br><span class=\"line\">   replicates 9dfef549f7917794cbabaf96781ed0e19957c1f3</span><br><span class=\"line\">S: edd31196e2980360b0738c57af95e1a69b0f9c9b 10.211.55.4:7004</span><br><span class=\"line\">   replicates c14485e8d7f1f3ec5c505b41fe727b657c951d8d</span><br><span class=\"line\">S: 95063a99c5cf2cc4abc51ca1e8ff0f3b8d60271c 10.211.55.4:7005</span><br><span class=\"line\">   replicates 8b308093e99f4299b8c18ab1dd81c5a83a3528c6</span><br><span class=\"line\">Can I set the above configuration? (type 'yes' to accept):</span><br></pre></td></tr></table></figure>\n<p>输入yes后，集群自动创建，创建完毕后，通过redis-cli进入任一节点，使用<code>cluster nodes</code>命令可以查看各个节点的状态</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">xiezefan@ubuntu:~$ redis-cli -p 7000</span><br><span class=\"line\">127.0.0.1:7000&gt;cluster nodes</span><br><span class=\"line\">c14485e8d7f1f3ec5c505b41fe727b657c951d8d 10.211.55.4:7001 master - 0 1449060968280 2 connected 5461-10922</span><br><span class=\"line\">95063a99c5cf2cc4abc51ca1e8ff0f3b8d60271c 10.211.55.4:7005 slave 8b308093e99f4299b8c18ab1dd81c5a83a3528c6 0 1449060968280 6 connected</span><br><span class=\"line\">edd31196e2980360b0738c57af95e1a69b0f9c9b 10.211.55.4:7004 slave c14485e8d7f1f3ec5c505b41fe727b657c951d8d 0 1449060967274 5 connected</span><br><span class=\"line\">8b308093e99f4299b8c18ab1dd81c5a83a3528c6 10.211.55.4:7002 master - 0 1449060966769 3 connected 10923-16383</span><br><span class=\"line\">632409883570eb5cecf6089583fba64a41d1154f 10.211.55.4:7003 slave 9dfef549f7917794cbabaf96781ed0e19957c1f3 0 1449060967274 4 connected</span><br><span class=\"line\">9dfef549f7917794cbabaf96781ed0e19957c1f3 10.211.55.4:7000 myself,master - 0 0 1 connected 0-5460</span><br></pre></td></tr></table></figure>\n<p>随便输入一个查询指令<code>get user.1</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">127.0.0.1:7000&gt; get user.1</span><br><span class=\"line\">(error) MOVED 9645 10.211.55.4:7001</span><br></pre></td></tr></table></figure>\n<p>因为user.1所在的solt-9645在7001节点上，cluster给你发送MOVED指令让你去7001节点查找数据，连接redis-cli的时候，使用<code>-c</code>参数可以指定查询时接收到MOVED指令自动跳转</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">xiezefan@ubuntu:~$ redis-cli -c -p 7000</span><br><span class=\"line\">127.0.0.1:7000&gt; get user.1</span><br><span class=\"line\"><span class=\"meta\">-&gt;</span> Redirected to slot [9645] located at 10.211.55.4:7001</span><br><span class=\"line\">(nil)</span><br></pre></td></tr></table></figure>\n<h4 id=\"集群扩容\"><a href=\"#集群扩容\" class=\"headerlink\" title=\"集群扩容\"></a>集群扩容</h4><p>现在我们已经有一个包含6个节点的集群，我写了段<a href=\"https://gist.github.com/xiezefan/4bd5e0d0c264aadaf061\" target=\"_blank\" rel=\"noopener\">代码</a>，往集群写入10W条测试数据。<br>现在模拟机器扩容场景，为集群加入一个master节点7006和一个slave节点7007。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">redis-trib.rb add-node 10.211.55.4:7006 10.211.55.4:7000</span><br></pre></td></tr></table></figure>\n<p>以上命令将7006节点接入7000所在的集群。接下来，我们为7006增加一个slave节点。  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">redis-trib.rb add-node --slave 10.211.55.4:7007 10.211.55.4:7000</span><br></pre></td></tr></table></figure>\n<p>以上命令表示增加slave节点，将7006的节点加入7000节点所在的集群中作为slave节点，随机依附现有的master节点中slave最少的节点，如果需要再指定特别的master节点，使用</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">redis-trib.rb add-node --slave --master-id 23b412673af0506df6382353e3a65960d5b7e66d 10.211.55.4:7007 10.211.55.4:7000</span><br></pre></td></tr></table></figure>\n<p>其中的<code>23b412673af0506df6382353e3a65960d5b7e66d</code>是7006节点的id，我们可以通过<code>cluster nodes</code>命令查看节点的id。</p>\n<p>接下来我们用坐负载均衡，Slot是Redis Cluster数据承载的最小单位，我们可以指定将一定范围的Slot转移到新的节点来实现负载均衡。</p>\n<p>Redis Cluster转移一个Slot的步骤是:</p>\n<ol>\n<li>在目标节点上声明将从源节点上迁入Slot <code>CLUSTER SETSLOT &lt;slot&gt; IMPORTING &lt;source_node_id&gt;</code></li>\n<li>在源节点上声明将往目标节点迁出Slot <code>CLUSTER SETSLOT &lt;slot&gt; IMPORTING &lt;source_node_id&gt;</code></li>\n<li>批量从源节点获取KEY <code>CLUSTER GETKEYSINSLOT &lt;slot&gt; &lt;count&gt;</code></li>\n<li>将获取的Key迁移到目标节点 <code>MIGRATE &lt;target_ip&gt; &lt;target_port&gt; &lt;key_name&gt; 0 &lt;timeout&gt;</code></li>\n<li>重复步骤3，4直到所有数据迁移完毕</li>\n<li>分别向双方节点发送 <code>CLUSTER SETSLOT &lt;slot&gt; NODE &lt;target_node_id&gt;</code>，该命令将会广播给集群其他节点，已经将Slot转移到目标节点。</li>\n<li>等待集群状态变为OK <code>CLUSTER INFO</code> 中的 <code>cluster_state = ok</code></li>\n</ol>\n<p>我编写了一个脚本来批量迁移Slot</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>!/bin/bash</span><br><span class=\"line\">source_host=$1  # 源节点HOST</span><br><span class=\"line\">source_port=$2  # 源节点端口</span><br><span class=\"line\">target_host=$3  # 目标节点HOST</span><br><span class=\"line\">target_port=$4  # 目标节点端口</span><br><span class=\"line\">start_slot=$5   # 迁移节点的其实范围</span><br><span class=\"line\">end_slot=$6     # 迁移节点的结束范围</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">for slot in `seq $&#123;start_slot&#125; $&#123;end_slot&#125;`</span><br><span class=\"line\">do</span><br><span class=\"line\">\tredis-cli -c -h $&#123;target_host&#125; -p $&#123;target_port&#125; cluster setslot $&#123;slot&#125; importing `redis-cli -c -h $&#123;source_host&#125; -p $&#123;source_port&#125; cluster nodes | grep $&#123;source_port&#125; | awk '&#123;print $1&#125;'`</span><br><span class=\"line\">\techo \"Setslot importing $&#123;slot&#125; to $&#123;target_host&#125;:$&#123;target_port&#125; success\"</span><br><span class=\"line\">\tredis-cli -c -h $&#123;source_host&#125; -p $&#123;source_port&#125; cluster setslot $&#123;slot&#125; migrating `redis-cli -c -h $&#123;target_host&#125; -p $&#123;target_port&#125; cluster nodes | grep $&#123;target_port&#125; | awk '&#123;print $1&#125;'`</span><br><span class=\"line\">\techo \"Setslot migrating $&#123;slot&#125; from $&#123;source_host&#125;:$&#123;source_port&#125; success\"</span><br><span class=\"line\"></span><br><span class=\"line\">\twhile [ 1 -eq 1 ]</span><br><span class=\"line\">\tdo</span><br><span class=\"line\">\t\tallkeys=`redis-cli -c -h $&#123;source_host&#125; -p $&#123;source_port&#125; cluster getkeysinslot $&#123;slot&#125; 10`</span><br><span class=\"line\">\t\tif [ -z \"$&#123;allkeys&#125;\" ]</span><br><span class=\"line\">\t\tthen</span><br><span class=\"line\">\t\t\tredis-cli -c -h $&#123;source_host&#125; -p $&#123;source_port&#125; cluster setslot $&#123;slot&#125; node `redis-cli -c -h $&#123;target_host&#125; -p $&#123;target_port&#125; cluster nodes | grep $&#123;target_port&#125; | awk '&#123;print $1&#125;'`</span><br><span class=\"line\">\t\t\tredis-cli -c -h $&#123;target_host&#125; -p $&#123;target_port&#125; cluster setslot $&#123;slot&#125; node `redis-cli -c -h $&#123;source_host&#125; -p $&#123;target_port&#125; cluster nodes | grep $&#123;target_port&#125; | awk '&#123;print $1&#125;'`</span><br><span class=\"line\">\t\t\techo \"Migrate slot $&#123;slot&#125; finish\"</span><br><span class=\"line\">\t\t\tbreak</span><br><span class=\"line\">\t\telse </span><br><span class=\"line\">\t\t\tfor key in $&#123;allkeys&#125;</span><br><span class=\"line\">\t\t\tdo</span><br><span class=\"line\">\t\t\t\tredis-cli -c -h $&#123;source_host&#125; -p $&#123;source_port&#125; migrate $&#123;target_host&#125; $&#123;target_port&#125; $&#123;key&#125; 0 5000</span><br><span class=\"line\">\t\t\t\techo \"Migrate slot $&#123;slot&#125; key $&#123;key&#125; success\"</span><br><span class=\"line\">\t\t\tdone</span><br><span class=\"line\">\t\tfi</span><br><span class=\"line\">\tdone</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure>\n<p>执行命令 <code>bash rebalance-cluster.sh 10.211.55.4 7000 10.211.55.4 7006 0 1000</code> 将7000节点上0-1000这个范围内的Slot转移到7006节点，通过<code>cluster nodes</code>命令我们可以看到0-1000这个区间是slot已经从7000转移到7006</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"code\"><pre><span class=\"line\">xiezefan@ubuntu:~/sheel$ redis-cli -c -p 7000 cluster nodes</span><br><span class=\"line\">23b412673af0506df6382353e3a65960d5b7e66d 10.211.55.4:7006 master - 0 1449064402389 7 connected 0-1000</span><br><span class=\"line\">0c2954d21d7bcdae333f4fdecf468ce05aa25544 10.211.55.4:7001 master - 0 1449064400372 2 connected 5461-10922</span><br><span class=\"line\">384a3bb5bd9ecb2fc7db75c866abc715d7966f82 10.211.55.4:7002 master - 0 1449064401381 3 connected 10923-16383</span><br><span class=\"line\">c3e09d286ef2dce49843268b20832d65a5d516a1 10.211.55.4:7004 slave 0c2954d21d7bcdae333f4fdecf468ce05aa25544 0 1449064401885 5 connected</span><br><span class=\"line\">50737b4a91443ab1a34eec4ef99d4f6fe5d358f4 10.211.55.4:7005 slave 384a3bb5bd9ecb2fc7db75c866abc715d7966f82 0 1449064402389 6 connected</span><br><span class=\"line\">3c62cc6664bba378cceb8ae8e02f5d727deafe9d 10.211.55.4:7007 slave 23b412673af0506df6382353e3a65960d5b7e66d 0 1449064400878 7 connected</span><br><span class=\"line\">d6441916dcd89cbf431465d92dfc0eb3dd235295 10.211.55.4:7003 slave 6ee21c5d93a6d2f293a2df1b37e8c9c27cb55ad8 0 1449064402389 4 connected</span><br><span class=\"line\">6ee21c5d93a6d2f293a2df1b37e8c9c27cb55ad8 10.211.55.4:7000 myself,master - 0 0 1 connected 1001-5460</span><br></pre></td></tr></table></figure>\n<h3 id=\"参考文章\"><a href=\"#参考文章\" class=\"headerlink\" title=\"参考文章\"></a>参考文章</h3><ul>\n<li><a href=\"http://blog.csdn.net/dc_726/article/details/48552531\" target=\"_blank\" rel=\"noopener\">全面剖析Redis Cluster原理和应用</a></li>\n<li><a href=\"http://blog.csdn.net/dc_726/article/details/43991905\" target=\"_blank\" rel=\"noopener\">Redis集群功能预览</a></li>\n<li><a href=\"http://carlosfu.iteye.com/blog/2243056\" target=\"_blank\" rel=\"noopener\">Redis-Cluster实战–8.Redis-Cluster水平扩容(redis-cli实现版)</a></li>\n<li><a href=\"http://blog.codingnow.com/2014/03/mmzb_redis.html\" target=\"_blank\" rel=\"noopener\">谈谈陌陌争霸在数据库方面踩过的坑( Redis 篇)</a></li>\n</ul>"},{"layout":"post","title":"Redis内存压缩实战","date":"2017-04-30T16:00:00.000Z","_content":"\n在讨论Redis内存压缩的时候，我们需要了解一下几个Redis的相关知识。\n\n<!-- more -->\n\n### 压缩列表 ziplist\n\nRedis的ziplist是用一段连续的内存来存储列表数据的一个数据结构，它的结构示例如下图\n\n![压缩列表组成示例--截图来自《Redis设计与实现》](http://res.xiezefan.me/images/14934574638948.jpg)\n\n1. zlbytes: 记录整个压缩列表使用的内存大小\n2. zltail: 记录压缩列表表尾距离起始位置有多少字节\n3. zllen: 记录压缩列表节点数量，值得注意的一点是，因为它只占了2个字节，所以最大值只能到65535，这意味着压缩列表长度大于65535的时候，就只能通过遍历整个列表来计算长度了\n4. zleng: 压缩列表末端标志位，固定值为`OxFF`\n5. entry1-N: 压缩列表节点, 具体结构如下图\n\n![压缩列表节点组成示例--截图来自《Redis设计与实现》](http://res.xiezefan.me/images/14934575513141.jpg)\n\n其中\n\n1. previous_entry_length: 上一个节点的长度\n2. encoding: content的编码以及长度\n3. content: 节点数据\n\n当我们查找一个节点的时候，主要进行一下操作:\n\n1. 根据zltail获取最后一个节点的位置\n2. 判断当前节点是否是目标节点\n3. 如果是，则返回数据\n4. 如果不是，则根据previous_entry_length计算上一个节点的起始位置，然后重新进行步骤2判断\n\n通过上述的描述，我们可以知道，ziplist每次数据更新的复杂度大约是O(N)，因为它需要对N个节点进行内存重分配，查找一个数据的时候，复杂度是O(N)，最坏情况下需要遍历整个列表。\n\n### 什么情况下会使用到ziplist呢？\n\nRedis会使用到ziplist的数据结构是Hash与List。\n\nHash结构使用ziplist作为底层存储的两个条件是:\n\n1. 所有的键与值的字符串长度都小于64字节的时候\n2. 键与值对数据小于512个\n\n只要上述条件任何一个不满足，Redis就会自动将这个Hash对象从ziplist转换成hashtable。但这两个阈值可以通过修改配置文件中的`hash-max-ziplist-value`与`hash-max-ziplist-entries`来变更。\n\nList结构使用ziplist的条件与Hash结构一样，当条件不满足的时候，会从ziplist转换成linkedlist，同样我们可以修改`list-max-ziplist-value`与`hash-max-ziplist-entries`来使用不同的阈值。\n\n为什么Hash与List会使用ziplist来存储数据呢？\n\n因为\n\n1. ziplist会比hashtable与ziplist节省跟多的内存\n2. 内存中以连续块方式保存的数据比起hashtable与linkedlist使用的链表可以更快的载入缓存中\n3. 当ziplist的长度比较小的时候，从ziplist读写数据的效率比hashtable或者linkedlist的差异并不大。\n\n本质上，使用ziplist就是以时间换空间的一种优化，但是他的时间损坏小到几乎可以忽略不计，但却能带来可观的内存减少，所以满足条件时，Redis会使用ziplist作为Hash与List的存储结构。\n\n \n\n\n### 实战\n\n我们先抛出问题，在广告程序化交易的过程中，我们经常需要为一个广告投放计划定制人群包，其存储的形式如下:\n\n```\n人群包ID => [设备ID_1, 设备ID_2 ... 设备ID_N]\n```\n\n其中，人群包ID是Long型整数，设备ID是经过MD5处理，长度为32。\n在业务场景中，我们需要判断一个设备ID是否在一个人群包中，来决定是否投放广告。\n\n在传统的使用Redis的场景, 我们可以使用标准的KV结构来存储定向包数据，则存储方式如下:\n\n```\n{人群包ID}_{设备ID_1} => true\n{人群包ID}_{设备ID_2} => true\n```\n\n\n如果我们想使用ziplist来继续内存压缩的话，我们必须保证Hash对象的长度小于512，并且键值的长度小于64字节。 我们可以将KV结构的数据，存储到预先分配好的bucket中。\n\n我们先预估下，整个Redis集群预计容纳的数据条数为10亿，那么Bucket的数量的计算公式如下:\n\n```\nbucket_count = 10亿 / 512 = 195W \n```\n\n那么我们大概需要200W个Bucket(预估Bucket数量需要多预估一点，以防触发临界值问题）\n我们先以下公式计算BucketID:\n\n```\nbucket_id = CRC32(人群包ID + \"_\" + 设备ID) % 200W\n```\n\n那么数据在Redis的存储结构就变成\n\n```\nbucket_id => {\n   {人群包ID}_{设备ID_1} => true\n   {人群包ID}_{设备ID_2} => true\n}\n```\n\n这样我们保证每个bucket中的数据项都小于512，并且长度均小于64字节。\n\n我们以2000W数据进行测试，前后两者的内存使用情况如下:\n\n|数据集大小|存储模式|Bucket数量|所用内存|碎片率|Redis占用的内存|\n|----|----|----|----|----|----|\n|2000W|压缩列表|200W|928M|1.38|1.25G|\n|2000W|压缩列表|5W|785M|1.48|1.14G|\n|2000W|直接存储|-|1.44G|1.03|1.48G|\n\n在这里需要额外引入一个概念 -- 内存碎片率。\n\n```\n内存碎片率 = 操作系统给Redis分配的内存 / Redis存储对象占用的内存\n```\n \n因为压缩列表在更新节点的时候，经常需要进行内存重分配，所以导致比较高的内存碎片率。我们在做技术方案比较的时候，内存碎片率也是非常需要关注的指标之一。 \n\n但有很多手段可以减少内存碎片率，比如内存对其，甚至更极端的直接重做整个Redis内存（利用快照或者从节点来重做内存）都能有效的减低内存碎片率。\n\n我们在本次实验中，因为存储的数值比较大（单个KEY约34个字节），所以实际节省内存不是很多，但依然能节约35%-50%的内存使用。\n\n在实际的生产环境中，我们根据应用场景合理的设计压缩存储结构，部分业务甚至能达到节约70%的内存使用的效果。\n\n\n### 压缩列表能节省多少内存？\n\n我们现在知道压缩列表是通过将节点紧凑的排列在内存中，从而节省掉内存的。但他究竟节省了哪些内存从而能达到惊人的压缩率呢？\n\n首先为了明白这个细节，我们需要知道普通Key-Value结构在Redis中是如何存储的。\n\n```\ntypedef struct redisObject {\n    unsigned type:4;        // 对象的类型\n    unsigned encoding:4;    // 对象的编码\n    unsigned lru:LRU_BITS;  // LRU类型\n    int refcount;           // 引用计数\n    void *ptr;              // 指向底层数据结构的指针\n} robj;\n```\nRedis所有的对象都是通过上述结构来存储, 假设我存储Hello=>World这样一个健值对到Redis中，除了存储本身键值的数据外，还需要额外的24个字节来存储redisObject对象。\n\n而Redis存储字符串使用的SDS数据结构\n\n```\nstruct sdshdr8 {\n    uint8_t len;        // 所保存字符串的长度\n    uint8_t alloc;      // 分配的内存数量\n    unsigned char flags;// 标志位，用于判断sdshdr类型    \n    char buf[];         // 字节数组，用户保存字符串\n};\n```\n\n假如字符串的长度无法用unsigned int8来表示的话，Redis会使用能表达更大长度的sdshdr16结构来存储字符串。\n\n并且，为了减少修改字符串带来的内存重分类问题，Redis会进行内存预分配，所以可能你仅仅为了保存五个字符，但Redis会为你预分配10 bytes的内存。\n\n这意味着当我们存储Hello这个字符串的时候，你需要额外的3个以上的字节。\n\nOh~~~，我只想保存Hello=>World这十个字符的数据，竟然需要的30~40个字节的数据来存储额外的信息，比存储数据本身的大小还多一些。这还没包括Redis维护字典表所需要的额外的内存空间。\n\n那么假设我们用ziplist来存储这个数据，我们仅仅需要额外的2个字节用于存储previous_entry_length与encoding。具体的计算方式可以参考Redis源码或者《Redis设计与实现》第一部分第7章压缩列表。\n\n### 总结\n\n从以上对比，我们可以看出，在存储越小的数据的时候，使用ziplist来进行数据压缩能得到更好的压缩率。\n但副作用也很明显，ziplist的更新效率远远低于普通K-V模式，并且会造成额外的内存碎片率。\n\n在Redis中存储大量数据的实践过程中，我们经常会做一些小技巧来尽可能压榨Redis的存储能力。接下来准备写一篇Redis内存压缩的小技巧。\n\n\n\n\n\n\n\n\n","source":"_posts/redis_in_action_ziplist.md","raw":"---\nlayout: post\ntitle: \"Redis内存压缩实战\"\ndate: 2017-05-01\ncategories:\n- redis\ntags:\n- redis\n- ziplist\n\n---\n\n在讨论Redis内存压缩的时候，我们需要了解一下几个Redis的相关知识。\n\n<!-- more -->\n\n### 压缩列表 ziplist\n\nRedis的ziplist是用一段连续的内存来存储列表数据的一个数据结构，它的结构示例如下图\n\n![压缩列表组成示例--截图来自《Redis设计与实现》](http://res.xiezefan.me/images/14934574638948.jpg)\n\n1. zlbytes: 记录整个压缩列表使用的内存大小\n2. zltail: 记录压缩列表表尾距离起始位置有多少字节\n3. zllen: 记录压缩列表节点数量，值得注意的一点是，因为它只占了2个字节，所以最大值只能到65535，这意味着压缩列表长度大于65535的时候，就只能通过遍历整个列表来计算长度了\n4. zleng: 压缩列表末端标志位，固定值为`OxFF`\n5. entry1-N: 压缩列表节点, 具体结构如下图\n\n![压缩列表节点组成示例--截图来自《Redis设计与实现》](http://res.xiezefan.me/images/14934575513141.jpg)\n\n其中\n\n1. previous_entry_length: 上一个节点的长度\n2. encoding: content的编码以及长度\n3. content: 节点数据\n\n当我们查找一个节点的时候，主要进行一下操作:\n\n1. 根据zltail获取最后一个节点的位置\n2. 判断当前节点是否是目标节点\n3. 如果是，则返回数据\n4. 如果不是，则根据previous_entry_length计算上一个节点的起始位置，然后重新进行步骤2判断\n\n通过上述的描述，我们可以知道，ziplist每次数据更新的复杂度大约是O(N)，因为它需要对N个节点进行内存重分配，查找一个数据的时候，复杂度是O(N)，最坏情况下需要遍历整个列表。\n\n### 什么情况下会使用到ziplist呢？\n\nRedis会使用到ziplist的数据结构是Hash与List。\n\nHash结构使用ziplist作为底层存储的两个条件是:\n\n1. 所有的键与值的字符串长度都小于64字节的时候\n2. 键与值对数据小于512个\n\n只要上述条件任何一个不满足，Redis就会自动将这个Hash对象从ziplist转换成hashtable。但这两个阈值可以通过修改配置文件中的`hash-max-ziplist-value`与`hash-max-ziplist-entries`来变更。\n\nList结构使用ziplist的条件与Hash结构一样，当条件不满足的时候，会从ziplist转换成linkedlist，同样我们可以修改`list-max-ziplist-value`与`hash-max-ziplist-entries`来使用不同的阈值。\n\n为什么Hash与List会使用ziplist来存储数据呢？\n\n因为\n\n1. ziplist会比hashtable与ziplist节省跟多的内存\n2. 内存中以连续块方式保存的数据比起hashtable与linkedlist使用的链表可以更快的载入缓存中\n3. 当ziplist的长度比较小的时候，从ziplist读写数据的效率比hashtable或者linkedlist的差异并不大。\n\n本质上，使用ziplist就是以时间换空间的一种优化，但是他的时间损坏小到几乎可以忽略不计，但却能带来可观的内存减少，所以满足条件时，Redis会使用ziplist作为Hash与List的存储结构。\n\n \n\n\n### 实战\n\n我们先抛出问题，在广告程序化交易的过程中，我们经常需要为一个广告投放计划定制人群包，其存储的形式如下:\n\n```\n人群包ID => [设备ID_1, 设备ID_2 ... 设备ID_N]\n```\n\n其中，人群包ID是Long型整数，设备ID是经过MD5处理，长度为32。\n在业务场景中，我们需要判断一个设备ID是否在一个人群包中，来决定是否投放广告。\n\n在传统的使用Redis的场景, 我们可以使用标准的KV结构来存储定向包数据，则存储方式如下:\n\n```\n{人群包ID}_{设备ID_1} => true\n{人群包ID}_{设备ID_2} => true\n```\n\n\n如果我们想使用ziplist来继续内存压缩的话，我们必须保证Hash对象的长度小于512，并且键值的长度小于64字节。 我们可以将KV结构的数据，存储到预先分配好的bucket中。\n\n我们先预估下，整个Redis集群预计容纳的数据条数为10亿，那么Bucket的数量的计算公式如下:\n\n```\nbucket_count = 10亿 / 512 = 195W \n```\n\n那么我们大概需要200W个Bucket(预估Bucket数量需要多预估一点，以防触发临界值问题）\n我们先以下公式计算BucketID:\n\n```\nbucket_id = CRC32(人群包ID + \"_\" + 设备ID) % 200W\n```\n\n那么数据在Redis的存储结构就变成\n\n```\nbucket_id => {\n   {人群包ID}_{设备ID_1} => true\n   {人群包ID}_{设备ID_2} => true\n}\n```\n\n这样我们保证每个bucket中的数据项都小于512，并且长度均小于64字节。\n\n我们以2000W数据进行测试，前后两者的内存使用情况如下:\n\n|数据集大小|存储模式|Bucket数量|所用内存|碎片率|Redis占用的内存|\n|----|----|----|----|----|----|\n|2000W|压缩列表|200W|928M|1.38|1.25G|\n|2000W|压缩列表|5W|785M|1.48|1.14G|\n|2000W|直接存储|-|1.44G|1.03|1.48G|\n\n在这里需要额外引入一个概念 -- 内存碎片率。\n\n```\n内存碎片率 = 操作系统给Redis分配的内存 / Redis存储对象占用的内存\n```\n \n因为压缩列表在更新节点的时候，经常需要进行内存重分配，所以导致比较高的内存碎片率。我们在做技术方案比较的时候，内存碎片率也是非常需要关注的指标之一。 \n\n但有很多手段可以减少内存碎片率，比如内存对其，甚至更极端的直接重做整个Redis内存（利用快照或者从节点来重做内存）都能有效的减低内存碎片率。\n\n我们在本次实验中，因为存储的数值比较大（单个KEY约34个字节），所以实际节省内存不是很多，但依然能节约35%-50%的内存使用。\n\n在实际的生产环境中，我们根据应用场景合理的设计压缩存储结构，部分业务甚至能达到节约70%的内存使用的效果。\n\n\n### 压缩列表能节省多少内存？\n\n我们现在知道压缩列表是通过将节点紧凑的排列在内存中，从而节省掉内存的。但他究竟节省了哪些内存从而能达到惊人的压缩率呢？\n\n首先为了明白这个细节，我们需要知道普通Key-Value结构在Redis中是如何存储的。\n\n```\ntypedef struct redisObject {\n    unsigned type:4;        // 对象的类型\n    unsigned encoding:4;    // 对象的编码\n    unsigned lru:LRU_BITS;  // LRU类型\n    int refcount;           // 引用计数\n    void *ptr;              // 指向底层数据结构的指针\n} robj;\n```\nRedis所有的对象都是通过上述结构来存储, 假设我存储Hello=>World这样一个健值对到Redis中，除了存储本身键值的数据外，还需要额外的24个字节来存储redisObject对象。\n\n而Redis存储字符串使用的SDS数据结构\n\n```\nstruct sdshdr8 {\n    uint8_t len;        // 所保存字符串的长度\n    uint8_t alloc;      // 分配的内存数量\n    unsigned char flags;// 标志位，用于判断sdshdr类型    \n    char buf[];         // 字节数组，用户保存字符串\n};\n```\n\n假如字符串的长度无法用unsigned int8来表示的话，Redis会使用能表达更大长度的sdshdr16结构来存储字符串。\n\n并且，为了减少修改字符串带来的内存重分类问题，Redis会进行内存预分配，所以可能你仅仅为了保存五个字符，但Redis会为你预分配10 bytes的内存。\n\n这意味着当我们存储Hello这个字符串的时候，你需要额外的3个以上的字节。\n\nOh~~~，我只想保存Hello=>World这十个字符的数据，竟然需要的30~40个字节的数据来存储额外的信息，比存储数据本身的大小还多一些。这还没包括Redis维护字典表所需要的额外的内存空间。\n\n那么假设我们用ziplist来存储这个数据，我们仅仅需要额外的2个字节用于存储previous_entry_length与encoding。具体的计算方式可以参考Redis源码或者《Redis设计与实现》第一部分第7章压缩列表。\n\n### 总结\n\n从以上对比，我们可以看出，在存储越小的数据的时候，使用ziplist来进行数据压缩能得到更好的压缩率。\n但副作用也很明显，ziplist的更新效率远远低于普通K-V模式，并且会造成额外的内存碎片率。\n\n在Redis中存储大量数据的实践过程中，我们经常会做一些小技巧来尽可能压榨Redis的存储能力。接下来准备写一篇Redis内存压缩的小技巧。\n\n\n\n\n\n\n\n\n","slug":"redis_in_action_ziplist","published":1,"updated":"2018-10-12T02:09:56.027Z","comments":1,"photos":[],"link":"","_id":"cjn5dk45b0034l939lgbetfb9","content":"<p>在讨论Redis内存压缩的时候，我们需要了解一下几个Redis的相关知识。</p>\n<a id=\"more\"></a>\n<h3 id=\"压缩列表-ziplist\"><a href=\"#压缩列表-ziplist\" class=\"headerlink\" title=\"压缩列表 ziplist\"></a>压缩列表 ziplist</h3><p>Redis的ziplist是用一段连续的内存来存储列表数据的一个数据结构，它的结构示例如下图</p>\n<p><img src=\"http://res.xiezefan.me/images/14934574638948.jpg\" alt=\"压缩列表组成示例--截图来自《Redis设计与实现》\"></p>\n<ol>\n<li>zlbytes: 记录整个压缩列表使用的内存大小</li>\n<li>zltail: 记录压缩列表表尾距离起始位置有多少字节</li>\n<li>zllen: 记录压缩列表节点数量，值得注意的一点是，因为它只占了2个字节，所以最大值只能到65535，这意味着压缩列表长度大于65535的时候，就只能通过遍历整个列表来计算长度了</li>\n<li>zleng: 压缩列表末端标志位，固定值为<code>OxFF</code></li>\n<li>entry1-N: 压缩列表节点, 具体结构如下图</li>\n</ol>\n<p><img src=\"http://res.xiezefan.me/images/14934575513141.jpg\" alt=\"压缩列表节点组成示例--截图来自《Redis设计与实现》\"></p>\n<p>其中</p>\n<ol>\n<li>previous_entry_length: 上一个节点的长度</li>\n<li>encoding: content的编码以及长度</li>\n<li>content: 节点数据</li>\n</ol>\n<p>当我们查找一个节点的时候，主要进行一下操作:</p>\n<ol>\n<li>根据zltail获取最后一个节点的位置</li>\n<li>判断当前节点是否是目标节点</li>\n<li>如果是，则返回数据</li>\n<li>如果不是，则根据previous_entry_length计算上一个节点的起始位置，然后重新进行步骤2判断</li>\n</ol>\n<p>通过上述的描述，我们可以知道，ziplist每次数据更新的复杂度大约是O(N)，因为它需要对N个节点进行内存重分配，查找一个数据的时候，复杂度是O(N)，最坏情况下需要遍历整个列表。</p>\n<h3 id=\"什么情况下会使用到ziplist呢？\"><a href=\"#什么情况下会使用到ziplist呢？\" class=\"headerlink\" title=\"什么情况下会使用到ziplist呢？\"></a>什么情况下会使用到ziplist呢？</h3><p>Redis会使用到ziplist的数据结构是Hash与List。</p>\n<p>Hash结构使用ziplist作为底层存储的两个条件是:</p>\n<ol>\n<li>所有的键与值的字符串长度都小于64字节的时候</li>\n<li>键与值对数据小于512个</li>\n</ol>\n<p>只要上述条件任何一个不满足，Redis就会自动将这个Hash对象从ziplist转换成hashtable。但这两个阈值可以通过修改配置文件中的<code>hash-max-ziplist-value</code>与<code>hash-max-ziplist-entries</code>来变更。</p>\n<p>List结构使用ziplist的条件与Hash结构一样，当条件不满足的时候，会从ziplist转换成linkedlist，同样我们可以修改<code>list-max-ziplist-value</code>与<code>hash-max-ziplist-entries</code>来使用不同的阈值。</p>\n<p>为什么Hash与List会使用ziplist来存储数据呢？</p>\n<p>因为</p>\n<ol>\n<li>ziplist会比hashtable与ziplist节省跟多的内存</li>\n<li>内存中以连续块方式保存的数据比起hashtable与linkedlist使用的链表可以更快的载入缓存中</li>\n<li>当ziplist的长度比较小的时候，从ziplist读写数据的效率比hashtable或者linkedlist的差异并不大。</li>\n</ol>\n<p>本质上，使用ziplist就是以时间换空间的一种优化，但是他的时间损坏小到几乎可以忽略不计，但却能带来可观的内存减少，所以满足条件时，Redis会使用ziplist作为Hash与List的存储结构。</p>\n<h3 id=\"实战\"><a href=\"#实战\" class=\"headerlink\" title=\"实战\"></a>实战</h3><p>我们先抛出问题，在广告程序化交易的过程中，我们经常需要为一个广告投放计划定制人群包，其存储的形式如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">人群包ID =&gt; [设备ID_1, 设备ID_2 ... 设备ID_N]</span><br></pre></td></tr></table></figure>\n<p>其中，人群包ID是Long型整数，设备ID是经过MD5处理，长度为32。<br>在业务场景中，我们需要判断一个设备ID是否在一个人群包中，来决定是否投放广告。</p>\n<p>在传统的使用Redis的场景, 我们可以使用标准的KV结构来存储定向包数据，则存储方式如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;人群包ID&#125;_&#123;设备ID_1&#125; =&gt; true</span><br><span class=\"line\">&#123;人群包ID&#125;_&#123;设备ID_2&#125; =&gt; true</span><br></pre></td></tr></table></figure>\n<p>如果我们想使用ziplist来继续内存压缩的话，我们必须保证Hash对象的长度小于512，并且键值的长度小于64字节。 我们可以将KV结构的数据，存储到预先分配好的bucket中。</p>\n<p>我们先预估下，整个Redis集群预计容纳的数据条数为10亿，那么Bucket的数量的计算公式如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">bucket_count = 10亿 / 512 = 195W</span><br></pre></td></tr></table></figure>\n<p>那么我们大概需要200W个Bucket(预估Bucket数量需要多预估一点，以防触发临界值问题）<br>我们先以下公式计算BucketID:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">bucket_id = CRC32(人群包ID + &quot;_&quot; + 设备ID) % 200W</span><br></pre></td></tr></table></figure>\n<p>那么数据在Redis的存储结构就变成</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">bucket_id =&gt; &#123;</span><br><span class=\"line\">   &#123;人群包ID&#125;_&#123;设备ID_1&#125; =&gt; true</span><br><span class=\"line\">   &#123;人群包ID&#125;_&#123;设备ID_2&#125; =&gt; true</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这样我们保证每个bucket中的数据项都小于512，并且长度均小于64字节。</p>\n<p>我们以2000W数据进行测试，前后两者的内存使用情况如下:</p>\n<table>\n<thead>\n<tr>\n<th>数据集大小</th>\n<th>存储模式</th>\n<th>Bucket数量</th>\n<th>所用内存</th>\n<th>碎片率</th>\n<th>Redis占用的内存</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2000W</td>\n<td>压缩列表</td>\n<td>200W</td>\n<td>928M</td>\n<td>1.38</td>\n<td>1.25G</td>\n</tr>\n<tr>\n<td>2000W</td>\n<td>压缩列表</td>\n<td>5W</td>\n<td>785M</td>\n<td>1.48</td>\n<td>1.14G</td>\n</tr>\n<tr>\n<td>2000W</td>\n<td>直接存储</td>\n<td>-</td>\n<td>1.44G</td>\n<td>1.03</td>\n<td>1.48G</td>\n</tr>\n</tbody>\n</table>\n<p>在这里需要额外引入一个概念 – 内存碎片率。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">内存碎片率 = 操作系统给Redis分配的内存 / Redis存储对象占用的内存</span><br></pre></td></tr></table></figure>\n<p>因为压缩列表在更新节点的时候，经常需要进行内存重分配，所以导致比较高的内存碎片率。我们在做技术方案比较的时候，内存碎片率也是非常需要关注的指标之一。 </p>\n<p>但有很多手段可以减少内存碎片率，比如内存对其，甚至更极端的直接重做整个Redis内存（利用快照或者从节点来重做内存）都能有效的减低内存碎片率。</p>\n<p>我们在本次实验中，因为存储的数值比较大（单个KEY约34个字节），所以实际节省内存不是很多，但依然能节约35%-50%的内存使用。</p>\n<p>在实际的生产环境中，我们根据应用场景合理的设计压缩存储结构，部分业务甚至能达到节约70%的内存使用的效果。</p>\n<h3 id=\"压缩列表能节省多少内存？\"><a href=\"#压缩列表能节省多少内存？\" class=\"headerlink\" title=\"压缩列表能节省多少内存？\"></a>压缩列表能节省多少内存？</h3><p>我们现在知道压缩列表是通过将节点紧凑的排列在内存中，从而节省掉内存的。但他究竟节省了哪些内存从而能达到惊人的压缩率呢？</p>\n<p>首先为了明白这个细节，我们需要知道普通Key-Value结构在Redis中是如何存储的。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">typedef struct redisObject &#123;</span><br><span class=\"line\">    unsigned type:4;        // 对象的类型</span><br><span class=\"line\">    unsigned encoding:4;    // 对象的编码</span><br><span class=\"line\">    unsigned lru:LRU_BITS;  // LRU类型</span><br><span class=\"line\">    int refcount;           // 引用计数</span><br><span class=\"line\">    void *ptr;              // 指向底层数据结构的指针</span><br><span class=\"line\">&#125; robj;</span><br></pre></td></tr></table></figure>\n<p>Redis所有的对象都是通过上述结构来存储, 假设我存储Hello=&gt;World这样一个健值对到Redis中，除了存储本身键值的数据外，还需要额外的24个字节来存储redisObject对象。</p>\n<p>而Redis存储字符串使用的SDS数据结构</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">struct sdshdr8 &#123;</span><br><span class=\"line\">    uint8_t len;        // 所保存字符串的长度</span><br><span class=\"line\">    uint8_t alloc;      // 分配的内存数量</span><br><span class=\"line\">    unsigned char flags;// 标志位，用于判断sdshdr类型    </span><br><span class=\"line\">    char buf[];         // 字节数组，用户保存字符串</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>假如字符串的长度无法用unsigned int8来表示的话，Redis会使用能表达更大长度的sdshdr16结构来存储字符串。</p>\n<p>并且，为了减少修改字符串带来的内存重分类问题，Redis会进行内存预分配，所以可能你仅仅为了保存五个字符，但Redis会为你预分配10 bytes的内存。</p>\n<p>这意味着当我们存储Hello这个字符串的时候，你需要额外的3个以上的字节。</p>\n<p>Oh~~~，我只想保存Hello=&gt;World这十个字符的数据，竟然需要的30~40个字节的数据来存储额外的信息，比存储数据本身的大小还多一些。这还没包括Redis维护字典表所需要的额外的内存空间。</p>\n<p>那么假设我们用ziplist来存储这个数据，我们仅仅需要额外的2个字节用于存储previous_entry_length与encoding。具体的计算方式可以参考Redis源码或者《Redis设计与实现》第一部分第7章压缩列表。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>从以上对比，我们可以看出，在存储越小的数据的时候，使用ziplist来进行数据压缩能得到更好的压缩率。<br>但副作用也很明显，ziplist的更新效率远远低于普通K-V模式，并且会造成额外的内存碎片率。</p>\n<p>在Redis中存储大量数据的实践过程中，我们经常会做一些小技巧来尽可能压榨Redis的存储能力。接下来准备写一篇Redis内存压缩的小技巧。</p>\n","site":{"data":{}},"excerpt":"<p>在讨论Redis内存压缩的时候，我们需要了解一下几个Redis的相关知识。</p>","more":"<h3 id=\"压缩列表-ziplist\"><a href=\"#压缩列表-ziplist\" class=\"headerlink\" title=\"压缩列表 ziplist\"></a>压缩列表 ziplist</h3><p>Redis的ziplist是用一段连续的内存来存储列表数据的一个数据结构，它的结构示例如下图</p>\n<p><img src=\"http://res.xiezefan.me/images/14934574638948.jpg\" alt=\"压缩列表组成示例--截图来自《Redis设计与实现》\"></p>\n<ol>\n<li>zlbytes: 记录整个压缩列表使用的内存大小</li>\n<li>zltail: 记录压缩列表表尾距离起始位置有多少字节</li>\n<li>zllen: 记录压缩列表节点数量，值得注意的一点是，因为它只占了2个字节，所以最大值只能到65535，这意味着压缩列表长度大于65535的时候，就只能通过遍历整个列表来计算长度了</li>\n<li>zleng: 压缩列表末端标志位，固定值为<code>OxFF</code></li>\n<li>entry1-N: 压缩列表节点, 具体结构如下图</li>\n</ol>\n<p><img src=\"http://res.xiezefan.me/images/14934575513141.jpg\" alt=\"压缩列表节点组成示例--截图来自《Redis设计与实现》\"></p>\n<p>其中</p>\n<ol>\n<li>previous_entry_length: 上一个节点的长度</li>\n<li>encoding: content的编码以及长度</li>\n<li>content: 节点数据</li>\n</ol>\n<p>当我们查找一个节点的时候，主要进行一下操作:</p>\n<ol>\n<li>根据zltail获取最后一个节点的位置</li>\n<li>判断当前节点是否是目标节点</li>\n<li>如果是，则返回数据</li>\n<li>如果不是，则根据previous_entry_length计算上一个节点的起始位置，然后重新进行步骤2判断</li>\n</ol>\n<p>通过上述的描述，我们可以知道，ziplist每次数据更新的复杂度大约是O(N)，因为它需要对N个节点进行内存重分配，查找一个数据的时候，复杂度是O(N)，最坏情况下需要遍历整个列表。</p>\n<h3 id=\"什么情况下会使用到ziplist呢？\"><a href=\"#什么情况下会使用到ziplist呢？\" class=\"headerlink\" title=\"什么情况下会使用到ziplist呢？\"></a>什么情况下会使用到ziplist呢？</h3><p>Redis会使用到ziplist的数据结构是Hash与List。</p>\n<p>Hash结构使用ziplist作为底层存储的两个条件是:</p>\n<ol>\n<li>所有的键与值的字符串长度都小于64字节的时候</li>\n<li>键与值对数据小于512个</li>\n</ol>\n<p>只要上述条件任何一个不满足，Redis就会自动将这个Hash对象从ziplist转换成hashtable。但这两个阈值可以通过修改配置文件中的<code>hash-max-ziplist-value</code>与<code>hash-max-ziplist-entries</code>来变更。</p>\n<p>List结构使用ziplist的条件与Hash结构一样，当条件不满足的时候，会从ziplist转换成linkedlist，同样我们可以修改<code>list-max-ziplist-value</code>与<code>hash-max-ziplist-entries</code>来使用不同的阈值。</p>\n<p>为什么Hash与List会使用ziplist来存储数据呢？</p>\n<p>因为</p>\n<ol>\n<li>ziplist会比hashtable与ziplist节省跟多的内存</li>\n<li>内存中以连续块方式保存的数据比起hashtable与linkedlist使用的链表可以更快的载入缓存中</li>\n<li>当ziplist的长度比较小的时候，从ziplist读写数据的效率比hashtable或者linkedlist的差异并不大。</li>\n</ol>\n<p>本质上，使用ziplist就是以时间换空间的一种优化，但是他的时间损坏小到几乎可以忽略不计，但却能带来可观的内存减少，所以满足条件时，Redis会使用ziplist作为Hash与List的存储结构。</p>\n<h3 id=\"实战\"><a href=\"#实战\" class=\"headerlink\" title=\"实战\"></a>实战</h3><p>我们先抛出问题，在广告程序化交易的过程中，我们经常需要为一个广告投放计划定制人群包，其存储的形式如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">人群包ID =&gt; [设备ID_1, 设备ID_2 ... 设备ID_N]</span><br></pre></td></tr></table></figure>\n<p>其中，人群包ID是Long型整数，设备ID是经过MD5处理，长度为32。<br>在业务场景中，我们需要判断一个设备ID是否在一个人群包中，来决定是否投放广告。</p>\n<p>在传统的使用Redis的场景, 我们可以使用标准的KV结构来存储定向包数据，则存储方式如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">&#123;人群包ID&#125;_&#123;设备ID_1&#125; =&gt; true</span><br><span class=\"line\">&#123;人群包ID&#125;_&#123;设备ID_2&#125; =&gt; true</span><br></pre></td></tr></table></figure>\n<p>如果我们想使用ziplist来继续内存压缩的话，我们必须保证Hash对象的长度小于512，并且键值的长度小于64字节。 我们可以将KV结构的数据，存储到预先分配好的bucket中。</p>\n<p>我们先预估下，整个Redis集群预计容纳的数据条数为10亿，那么Bucket的数量的计算公式如下:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">bucket_count = 10亿 / 512 = 195W</span><br></pre></td></tr></table></figure>\n<p>那么我们大概需要200W个Bucket(预估Bucket数量需要多预估一点，以防触发临界值问题）<br>我们先以下公式计算BucketID:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">bucket_id = CRC32(人群包ID + &quot;_&quot; + 设备ID) % 200W</span><br></pre></td></tr></table></figure>\n<p>那么数据在Redis的存储结构就变成</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">bucket_id =&gt; &#123;</span><br><span class=\"line\">   &#123;人群包ID&#125;_&#123;设备ID_1&#125; =&gt; true</span><br><span class=\"line\">   &#123;人群包ID&#125;_&#123;设备ID_2&#125; =&gt; true</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>这样我们保证每个bucket中的数据项都小于512，并且长度均小于64字节。</p>\n<p>我们以2000W数据进行测试，前后两者的内存使用情况如下:</p>\n<table>\n<thead>\n<tr>\n<th>数据集大小</th>\n<th>存储模式</th>\n<th>Bucket数量</th>\n<th>所用内存</th>\n<th>碎片率</th>\n<th>Redis占用的内存</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>2000W</td>\n<td>压缩列表</td>\n<td>200W</td>\n<td>928M</td>\n<td>1.38</td>\n<td>1.25G</td>\n</tr>\n<tr>\n<td>2000W</td>\n<td>压缩列表</td>\n<td>5W</td>\n<td>785M</td>\n<td>1.48</td>\n<td>1.14G</td>\n</tr>\n<tr>\n<td>2000W</td>\n<td>直接存储</td>\n<td>-</td>\n<td>1.44G</td>\n<td>1.03</td>\n<td>1.48G</td>\n</tr>\n</tbody>\n</table>\n<p>在这里需要额外引入一个概念 – 内存碎片率。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">内存碎片率 = 操作系统给Redis分配的内存 / Redis存储对象占用的内存</span><br></pre></td></tr></table></figure>\n<p>因为压缩列表在更新节点的时候，经常需要进行内存重分配，所以导致比较高的内存碎片率。我们在做技术方案比较的时候，内存碎片率也是非常需要关注的指标之一。 </p>\n<p>但有很多手段可以减少内存碎片率，比如内存对其，甚至更极端的直接重做整个Redis内存（利用快照或者从节点来重做内存）都能有效的减低内存碎片率。</p>\n<p>我们在本次实验中，因为存储的数值比较大（单个KEY约34个字节），所以实际节省内存不是很多，但依然能节约35%-50%的内存使用。</p>\n<p>在实际的生产环境中，我们根据应用场景合理的设计压缩存储结构，部分业务甚至能达到节约70%的内存使用的效果。</p>\n<h3 id=\"压缩列表能节省多少内存？\"><a href=\"#压缩列表能节省多少内存？\" class=\"headerlink\" title=\"压缩列表能节省多少内存？\"></a>压缩列表能节省多少内存？</h3><p>我们现在知道压缩列表是通过将节点紧凑的排列在内存中，从而节省掉内存的。但他究竟节省了哪些内存从而能达到惊人的压缩率呢？</p>\n<p>首先为了明白这个细节，我们需要知道普通Key-Value结构在Redis中是如何存储的。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">typedef struct redisObject &#123;</span><br><span class=\"line\">    unsigned type:4;        // 对象的类型</span><br><span class=\"line\">    unsigned encoding:4;    // 对象的编码</span><br><span class=\"line\">    unsigned lru:LRU_BITS;  // LRU类型</span><br><span class=\"line\">    int refcount;           // 引用计数</span><br><span class=\"line\">    void *ptr;              // 指向底层数据结构的指针</span><br><span class=\"line\">&#125; robj;</span><br></pre></td></tr></table></figure>\n<p>Redis所有的对象都是通过上述结构来存储, 假设我存储Hello=&gt;World这样一个健值对到Redis中，除了存储本身键值的数据外，还需要额外的24个字节来存储redisObject对象。</p>\n<p>而Redis存储字符串使用的SDS数据结构</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"code\"><pre><span class=\"line\">struct sdshdr8 &#123;</span><br><span class=\"line\">    uint8_t len;        // 所保存字符串的长度</span><br><span class=\"line\">    uint8_t alloc;      // 分配的内存数量</span><br><span class=\"line\">    unsigned char flags;// 标志位，用于判断sdshdr类型    </span><br><span class=\"line\">    char buf[];         // 字节数组，用户保存字符串</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n<p>假如字符串的长度无法用unsigned int8来表示的话，Redis会使用能表达更大长度的sdshdr16结构来存储字符串。</p>\n<p>并且，为了减少修改字符串带来的内存重分类问题，Redis会进行内存预分配，所以可能你仅仅为了保存五个字符，但Redis会为你预分配10 bytes的内存。</p>\n<p>这意味着当我们存储Hello这个字符串的时候，你需要额外的3个以上的字节。</p>\n<p>Oh~~~，我只想保存Hello=&gt;World这十个字符的数据，竟然需要的30~40个字节的数据来存储额外的信息，比存储数据本身的大小还多一些。这还没包括Redis维护字典表所需要的额外的内存空间。</p>\n<p>那么假设我们用ziplist来存储这个数据，我们仅仅需要额外的2个字节用于存储previous_entry_length与encoding。具体的计算方式可以参考Redis源码或者《Redis设计与实现》第一部分第7章压缩列表。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>从以上对比，我们可以看出，在存储越小的数据的时候，使用ziplist来进行数据压缩能得到更好的压缩率。<br>但副作用也很明显，ziplist的更新效率远远低于普通K-V模式，并且会造成额外的内存碎片率。</p>\n<p>在Redis中存储大量数据的实践过程中，我们经常会做一些小技巧来尽可能压榨Redis的存储能力。接下来准备写一篇Redis内存压缩的小技巧。</p>"},{"layout":"post","title":"Druid 几种数据摄入方式的区别","date":"2018-04-05T16:00:00.000Z","_content":"\n\n我们在从Kafka，RabbitMQ，Storm 中摄入实时数据流时到Druid的时候，可以使用Realtime Node，Index Server，Tranquility进行数据摄入。\n\n本文主要探索这几种数据摄入方式的区别。\n\n<!-- more -->\n\n\n## Realtime Node\n\nRealtime Node 可以直接配置Firehose从Kafka，RabbitMQ等消息队列中获取数据，数据一旦被摄入，很快就可以被查询到， 同时Realtime Node还会周期性的将摄入的数据合并成Segment，提交给DeepStorage并交由Historical Node加载，以达到提供实时数据的查询的功能。\n\n### Realtime Node的局限性\n\n但这种模式有一些缺陷\n\n#### Kafka 摄入缺陷\n\n一旦Realtime Node宕机，那么该节点上未提交的数据将全部丢失。 \n\n正常这种时候我们需要使用创建 replica 副本以保证高可用，但在使用Kafka摄入数据的场景会有一些缺陷， 这里涉及到Segment的[Shard机制](http://druid.io/docs/0.12.0/ingestion/stream-pull.html#sharding)。\n\n简单讲，在大量数据的摄入的场景，通常一个Segment会分为多个Shard分片，每一个分片会有不同的`partitionNum `分区号。当设置了副本的时候，某个分片的副本将会拥有该分片相同的分区号。在数据查询的时候，Druid在相同分区号的分片中知会随机选择一个进行数据查询数据。\n\n而举一个具体的场景，假如在你有一个Kafka的Topic有编号为1，2，3的partitions，并且你有2个实时节点去消费这个Topic，节点1消费了partitions 1与2， 节点2消费了partitions 3。他们拥有相同的Group。\n这时候你需要进行Replication以保证高可用，所以你启动了另外2个实时节点并以新的Kafka Topic去消费数据。 这时候看节点3可能消费了partitons 1，节点4可能消费了partitions 2与3。\n前文提到Segment partitionNum查询的特性，这时候Druid会认为节点3与4是同一个分区，所以数据查询只会从中挑选一个节点进行查询，但很明显他们数据是不一样的。\n\n![Druid Realtime Node缺陷](http://res.xiezefan.me/images/Druid Realtime Node defects.png)\n\n\n#### 数据丢失风险\n\n另外，假设你当前正在执行一个任务计算今日每个小时的数据汇总，同时你有一个批处理任务从离线集群获取数据重做Segment，并覆盖当前的Segment。\n如果你在执行计算任务期间发生了Segment覆盖，那么在这个场景下很可能出现数据丢失。\n\n#### Schema更新需重启节点\n\n在Schema更新的时候，你需要重启Realtime Node以生效新的配置，这在大规模集群管理上效率非常低。\n\n## Indexing Service\n\n以下是Druid官方的Indexing Service架构图\n\n![Druid Indexing Service Architecture](http://res.xiezefan.me/images/indexing_service.png)\n\nIndexing Service分为以下几个部分:\n\n1. Overload : 负责接收请求，分配任务给Middle Manager执行\n2. Middle Manager :  执行提交的任务的工作者节点，会将任务分发给运行在单独的JVM的Peon\n3. Peon : 指定Task的容器\n4. Task : 在Middle Manager管理的Peon下执行的任务，支持各种各样的任务如Hadoop摄入，Kafka摄入。同时开发者可以自己定制Task以满足业务需求\n5. ZooKeeper: 维护任务的信息\n\n简单讲Indexing Service是一套分布式任务调度系统，按计划执行数据摄入，Segment合并，压缩，删除等任务。同时支持自定义任务扩展。\n\n甚至你可以通过扩展将Indexing Service接入Autoscaling自动伸缩服务，在任务排队过长的时候，自动创建Middle Manager节点，再节点空闲的时候，自动进行缩容。\n\n### 锁机制\n\n[Task的锁机制](http://druid.io/docs/0.12.0/ingestion/tasks.html#locking)可以在我们进行publish segment等时候获取指定时间段的segment的排他锁或共享锁，以避免上文描述的Realtime Node Segment覆盖的时候可能产生的数据丢失风险\n\n### Kafka Indexing Service\n\n[Kafka Indexing Service](http://druid.io/docs/0.12.0/development/extensions-core/kafka-ingestion.html) 是在Indexing Service上封装的一个扩展，使用Kafka自己的分区和偏移机制来读取数据，因此能够提供准确一次的服务保证。 解决Realtime Node摄入Kafka数据的缺陷。\n\n与 Tranquility 对比的好处是，他能够读取来自Kafka的非近期的数据，并且不受窗口期(window period )对其他摄取机制的影响。支持管理索引任务的状态，以协调切换，管理故障，并确保维护可扩展性和复制要求。\n\n截止至当前Druid 0.11.0 Kafka Indexing server还未完全Release，需要谨慎在生产上使用。\n\n## Tranquility\nTranquility 是在 Index Service 封装的一个类库，帮助我们从Kafka，Hadoop，HTTP，Storm，Samza，Spark Streaming或者自己的JVM程序发送数据给Indexing Service。\n\n### Tranquility 实现原理\n\nTranquility 帮助我们解决Indexing Service在Partitioning分区， Replication副本，Service Discover服务发现，Schema rollover Schema平滑变更上的一些难题。\n\nTranquility基于Indexing Service的EventReceiverFirehose来实现，该Firehose会暴露一个HTTP API供Tranquility实时Push数据给Indexing Service。\n\n在解决分区与副本问题上，Tranquility会给每一个Segment+ partitionNum指派一个Task来进行数据摄入，在超过Window Period后，Task将会停止接收数据并合并Segment，然后提交到Deep Storage。\n\n而副本的实现上，Tranquility将每个副本创建不同Task，相同的Segment与partitionNum，相同Segment与partitionNum的数据将会同事发给相同的副本的Task，副本的Task之间乎不通讯。\n\n当Schema发生改变的时候，在Indexing Service必须重启任务才生效。 而Tranquility的做法是只会应用到新的时间段生成的Segment，旧的Segment讲保持不变。由此时间不停机修改Schema。\n\n最后，我们通常需要启动实例进行数据处理并发送给Druid，Tranquility使用Zookeeper管理不同实例的任务协调，保证数据被正确想到相应的Task中。\n\n### Tranquility的缺陷\n\n1. 超过Window Period的数据将会被丢弃，必须定时从离线集群中重做Segment来实现数据互补。\n2. Tranquility与Indexing Service的通讯异常会导致重试，无论是重试成功或失败，都可能导致数据丢失或者重复数据\n\n## 总结\n\n1. Kafka Indexing Service 与 Tranquility 是官方推荐的安全的Kafka摄入数据的方式。\n2. 更多使用Indexing Service起替代Realtime Node\n\n\n\n","source":"_posts/druid_data_ingestion_different.md","raw":"---\nlayout: post\ntitle: \"Druid 几种数据摄入方式的区别\"\ndate: 2018-04-06\ncategories:\n- druid\ntags:\n- druid\n---\n\n\n我们在从Kafka，RabbitMQ，Storm 中摄入实时数据流时到Druid的时候，可以使用Realtime Node，Index Server，Tranquility进行数据摄入。\n\n本文主要探索这几种数据摄入方式的区别。\n\n<!-- more -->\n\n\n## Realtime Node\n\nRealtime Node 可以直接配置Firehose从Kafka，RabbitMQ等消息队列中获取数据，数据一旦被摄入，很快就可以被查询到， 同时Realtime Node还会周期性的将摄入的数据合并成Segment，提交给DeepStorage并交由Historical Node加载，以达到提供实时数据的查询的功能。\n\n### Realtime Node的局限性\n\n但这种模式有一些缺陷\n\n#### Kafka 摄入缺陷\n\n一旦Realtime Node宕机，那么该节点上未提交的数据将全部丢失。 \n\n正常这种时候我们需要使用创建 replica 副本以保证高可用，但在使用Kafka摄入数据的场景会有一些缺陷， 这里涉及到Segment的[Shard机制](http://druid.io/docs/0.12.0/ingestion/stream-pull.html#sharding)。\n\n简单讲，在大量数据的摄入的场景，通常一个Segment会分为多个Shard分片，每一个分片会有不同的`partitionNum `分区号。当设置了副本的时候，某个分片的副本将会拥有该分片相同的分区号。在数据查询的时候，Druid在相同分区号的分片中知会随机选择一个进行数据查询数据。\n\n而举一个具体的场景，假如在你有一个Kafka的Topic有编号为1，2，3的partitions，并且你有2个实时节点去消费这个Topic，节点1消费了partitions 1与2， 节点2消费了partitions 3。他们拥有相同的Group。\n这时候你需要进行Replication以保证高可用，所以你启动了另外2个实时节点并以新的Kafka Topic去消费数据。 这时候看节点3可能消费了partitons 1，节点4可能消费了partitions 2与3。\n前文提到Segment partitionNum查询的特性，这时候Druid会认为节点3与4是同一个分区，所以数据查询只会从中挑选一个节点进行查询，但很明显他们数据是不一样的。\n\n![Druid Realtime Node缺陷](http://res.xiezefan.me/images/Druid Realtime Node defects.png)\n\n\n#### 数据丢失风险\n\n另外，假设你当前正在执行一个任务计算今日每个小时的数据汇总，同时你有一个批处理任务从离线集群获取数据重做Segment，并覆盖当前的Segment。\n如果你在执行计算任务期间发生了Segment覆盖，那么在这个场景下很可能出现数据丢失。\n\n#### Schema更新需重启节点\n\n在Schema更新的时候，你需要重启Realtime Node以生效新的配置，这在大规模集群管理上效率非常低。\n\n## Indexing Service\n\n以下是Druid官方的Indexing Service架构图\n\n![Druid Indexing Service Architecture](http://res.xiezefan.me/images/indexing_service.png)\n\nIndexing Service分为以下几个部分:\n\n1. Overload : 负责接收请求，分配任务给Middle Manager执行\n2. Middle Manager :  执行提交的任务的工作者节点，会将任务分发给运行在单独的JVM的Peon\n3. Peon : 指定Task的容器\n4. Task : 在Middle Manager管理的Peon下执行的任务，支持各种各样的任务如Hadoop摄入，Kafka摄入。同时开发者可以自己定制Task以满足业务需求\n5. ZooKeeper: 维护任务的信息\n\n简单讲Indexing Service是一套分布式任务调度系统，按计划执行数据摄入，Segment合并，压缩，删除等任务。同时支持自定义任务扩展。\n\n甚至你可以通过扩展将Indexing Service接入Autoscaling自动伸缩服务，在任务排队过长的时候，自动创建Middle Manager节点，再节点空闲的时候，自动进行缩容。\n\n### 锁机制\n\n[Task的锁机制](http://druid.io/docs/0.12.0/ingestion/tasks.html#locking)可以在我们进行publish segment等时候获取指定时间段的segment的排他锁或共享锁，以避免上文描述的Realtime Node Segment覆盖的时候可能产生的数据丢失风险\n\n### Kafka Indexing Service\n\n[Kafka Indexing Service](http://druid.io/docs/0.12.0/development/extensions-core/kafka-ingestion.html) 是在Indexing Service上封装的一个扩展，使用Kafka自己的分区和偏移机制来读取数据，因此能够提供准确一次的服务保证。 解决Realtime Node摄入Kafka数据的缺陷。\n\n与 Tranquility 对比的好处是，他能够读取来自Kafka的非近期的数据，并且不受窗口期(window period )对其他摄取机制的影响。支持管理索引任务的状态，以协调切换，管理故障，并确保维护可扩展性和复制要求。\n\n截止至当前Druid 0.11.0 Kafka Indexing server还未完全Release，需要谨慎在生产上使用。\n\n## Tranquility\nTranquility 是在 Index Service 封装的一个类库，帮助我们从Kafka，Hadoop，HTTP，Storm，Samza，Spark Streaming或者自己的JVM程序发送数据给Indexing Service。\n\n### Tranquility 实现原理\n\nTranquility 帮助我们解决Indexing Service在Partitioning分区， Replication副本，Service Discover服务发现，Schema rollover Schema平滑变更上的一些难题。\n\nTranquility基于Indexing Service的EventReceiverFirehose来实现，该Firehose会暴露一个HTTP API供Tranquility实时Push数据给Indexing Service。\n\n在解决分区与副本问题上，Tranquility会给每一个Segment+ partitionNum指派一个Task来进行数据摄入，在超过Window Period后，Task将会停止接收数据并合并Segment，然后提交到Deep Storage。\n\n而副本的实现上，Tranquility将每个副本创建不同Task，相同的Segment与partitionNum，相同Segment与partitionNum的数据将会同事发给相同的副本的Task，副本的Task之间乎不通讯。\n\n当Schema发生改变的时候，在Indexing Service必须重启任务才生效。 而Tranquility的做法是只会应用到新的时间段生成的Segment，旧的Segment讲保持不变。由此时间不停机修改Schema。\n\n最后，我们通常需要启动实例进行数据处理并发送给Druid，Tranquility使用Zookeeper管理不同实例的任务协调，保证数据被正确想到相应的Task中。\n\n### Tranquility的缺陷\n\n1. 超过Window Period的数据将会被丢弃，必须定时从离线集群中重做Segment来实现数据互补。\n2. Tranquility与Indexing Service的通讯异常会导致重试，无论是重试成功或失败，都可能导致数据丢失或者重复数据\n\n## 总结\n\n1. Kafka Indexing Service 与 Tranquility 是官方推荐的安全的Kafka摄入数据的方式。\n2. 更多使用Indexing Service起替代Realtime Node\n\n\n\n","slug":"druid_data_ingestion_different","published":1,"updated":"2019-02-24T12:36:15.082Z","comments":1,"photos":[],"link":"","_id":"cjsiwethy0000su395kr2su00","content":"<p>我们在从Kafka，RabbitMQ，Storm 中摄入实时数据流时到Druid的时候，可以使用Realtime Node，Index Server，Tranquility进行数据摄入。</p>\n<p>本文主要探索这几种数据摄入方式的区别。</p>\n<a id=\"more\"></a>\n<h2 id=\"Realtime-Node\"><a href=\"#Realtime-Node\" class=\"headerlink\" title=\"Realtime Node\"></a>Realtime Node</h2><p>Realtime Node 可以直接配置Firehose从Kafka，RabbitMQ等消息队列中获取数据，数据一旦被摄入，很快就可以被查询到， 同时Realtime Node还会周期性的将摄入的数据合并成Segment，提交给DeepStorage并交由Historical Node加载，以达到提供实时数据的查询的功能。</p>\n<h3 id=\"Realtime-Node的局限性\"><a href=\"#Realtime-Node的局限性\" class=\"headerlink\" title=\"Realtime Node的局限性\"></a>Realtime Node的局限性</h3><p>但这种模式有一些缺陷</p>\n<h4 id=\"Kafka-摄入缺陷\"><a href=\"#Kafka-摄入缺陷\" class=\"headerlink\" title=\"Kafka 摄入缺陷\"></a>Kafka 摄入缺陷</h4><p>一旦Realtime Node宕机，那么该节点上未提交的数据将全部丢失。 </p>\n<p>正常这种时候我们需要使用创建 replica 副本以保证高可用，但在使用Kafka摄入数据的场景会有一些缺陷， 这里涉及到Segment的<a href=\"http://druid.io/docs/0.12.0/ingestion/stream-pull.html#sharding\" target=\"_blank\" rel=\"noopener\">Shard机制</a>。</p>\n<p>简单讲，在大量数据的摄入的场景，通常一个Segment会分为多个Shard分片，每一个分片会有不同的<code>partitionNum</code>分区号。当设置了副本的时候，某个分片的副本将会拥有该分片相同的分区号。在数据查询的时候，Druid在相同分区号的分片中知会随机选择一个进行数据查询数据。</p>\n<p>而举一个具体的场景，假如在你有一个Kafka的Topic有编号为1，2，3的partitions，并且你有2个实时节点去消费这个Topic，节点1消费了partitions 1与2， 节点2消费了partitions 3。他们拥有相同的Group。<br>这时候你需要进行Replication以保证高可用，所以你启动了另外2个实时节点并以新的Kafka Topic去消费数据。 这时候看节点3可能消费了partitons 1，节点4可能消费了partitions 2与3。<br>前文提到Segment partitionNum查询的特性，这时候Druid会认为节点3与4是同一个分区，所以数据查询只会从中挑选一个节点进行查询，但很明显他们数据是不一样的。</p>\n<p><img src=\"http://res.xiezefan.me/images/Druid Realtime Node defects.png\" alt=\"Druid Realtime Node缺陷\"></p>\n<h4 id=\"数据丢失风险\"><a href=\"#数据丢失风险\" class=\"headerlink\" title=\"数据丢失风险\"></a>数据丢失风险</h4><p>另外，假设你当前正在执行一个任务计算今日每个小时的数据汇总，同时你有一个批处理任务从离线集群获取数据重做Segment，并覆盖当前的Segment。<br>如果你在执行计算任务期间发生了Segment覆盖，那么在这个场景下很可能出现数据丢失。</p>\n<h4 id=\"Schema更新需重启节点\"><a href=\"#Schema更新需重启节点\" class=\"headerlink\" title=\"Schema更新需重启节点\"></a>Schema更新需重启节点</h4><p>在Schema更新的时候，你需要重启Realtime Node以生效新的配置，这在大规模集群管理上效率非常低。</p>\n<h2 id=\"Indexing-Service\"><a href=\"#Indexing-Service\" class=\"headerlink\" title=\"Indexing Service\"></a>Indexing Service</h2><p>以下是Druid官方的Indexing Service架构图</p>\n<p><img src=\"http://res.xiezefan.me/images/indexing_service.png\" alt=\"Druid Indexing Service Architecture\"></p>\n<p>Indexing Service分为以下几个部分:</p>\n<ol>\n<li>Overload : 负责接收请求，分配任务给Middle Manager执行</li>\n<li>Middle Manager :  执行提交的任务的工作者节点，会将任务分发给运行在单独的JVM的Peon</li>\n<li>Peon : 指定Task的容器</li>\n<li>Task : 在Middle Manager管理的Peon下执行的任务，支持各种各样的任务如Hadoop摄入，Kafka摄入。同时开发者可以自己定制Task以满足业务需求</li>\n<li>ZooKeeper: 维护任务的信息</li>\n</ol>\n<p>简单讲Indexing Service是一套分布式任务调度系统，按计划执行数据摄入，Segment合并，压缩，删除等任务。同时支持自定义任务扩展。</p>\n<p>甚至你可以通过扩展将Indexing Service接入Autoscaling自动伸缩服务，在任务排队过长的时候，自动创建Middle Manager节点，再节点空闲的时候，自动进行缩容。</p>\n<h3 id=\"锁机制\"><a href=\"#锁机制\" class=\"headerlink\" title=\"锁机制\"></a>锁机制</h3><p><a href=\"http://druid.io/docs/0.12.0/ingestion/tasks.html#locking\" target=\"_blank\" rel=\"noopener\">Task的锁机制</a>可以在我们进行publish segment等时候获取指定时间段的segment的排他锁或共享锁，以避免上文描述的Realtime Node Segment覆盖的时候可能产生的数据丢失风险</p>\n<h3 id=\"Kafka-Indexing-Service\"><a href=\"#Kafka-Indexing-Service\" class=\"headerlink\" title=\"Kafka Indexing Service\"></a>Kafka Indexing Service</h3><p><a href=\"http://druid.io/docs/0.12.0/development/extensions-core/kafka-ingestion.html\" target=\"_blank\" rel=\"noopener\">Kafka Indexing Service</a> 是在Indexing Service上封装的一个扩展，使用Kafka自己的分区和偏移机制来读取数据，因此能够提供准确一次的服务保证。 解决Realtime Node摄入Kafka数据的缺陷。</p>\n<p>与 Tranquility 对比的好处是，他能够读取来自Kafka的非近期的数据，并且不受窗口期(window period )对其他摄取机制的影响。支持管理索引任务的状态，以协调切换，管理故障，并确保维护可扩展性和复制要求。</p>\n<p>截止至当前Druid 0.11.0 Kafka Indexing server还未完全Release，需要谨慎在生产上使用。</p>\n<h2 id=\"Tranquility\"><a href=\"#Tranquility\" class=\"headerlink\" title=\"Tranquility\"></a>Tranquility</h2><p>Tranquility 是在 Index Service 封装的一个类库，帮助我们从Kafka，Hadoop，HTTP，Storm，Samza，Spark Streaming或者自己的JVM程序发送数据给Indexing Service。</p>\n<h3 id=\"Tranquility-实现原理\"><a href=\"#Tranquility-实现原理\" class=\"headerlink\" title=\"Tranquility 实现原理\"></a>Tranquility 实现原理</h3><p>Tranquility 帮助我们解决Indexing Service在Partitioning分区， Replication副本，Service Discover服务发现，Schema rollover Schema平滑变更上的一些难题。</p>\n<p>Tranquility基于Indexing Service的EventReceiverFirehose来实现，该Firehose会暴露一个HTTP API供Tranquility实时Push数据给Indexing Service。</p>\n<p>在解决分区与副本问题上，Tranquility会给每一个Segment+ partitionNum指派一个Task来进行数据摄入，在超过Window Period后，Task将会停止接收数据并合并Segment，然后提交到Deep Storage。</p>\n<p>而副本的实现上，Tranquility将每个副本创建不同Task，相同的Segment与partitionNum，相同Segment与partitionNum的数据将会同事发给相同的副本的Task，副本的Task之间乎不通讯。</p>\n<p>当Schema发生改变的时候，在Indexing Service必须重启任务才生效。 而Tranquility的做法是只会应用到新的时间段生成的Segment，旧的Segment讲保持不变。由此时间不停机修改Schema。</p>\n<p>最后，我们通常需要启动实例进行数据处理并发送给Druid，Tranquility使用Zookeeper管理不同实例的任务协调，保证数据被正确想到相应的Task中。</p>\n<h3 id=\"Tranquility的缺陷\"><a href=\"#Tranquility的缺陷\" class=\"headerlink\" title=\"Tranquility的缺陷\"></a>Tranquility的缺陷</h3><ol>\n<li>超过Window Period的数据将会被丢弃，必须定时从离线集群中重做Segment来实现数据互补。</li>\n<li>Tranquility与Indexing Service的通讯异常会导致重试，无论是重试成功或失败，都可能导致数据丢失或者重复数据</li>\n</ol>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ol>\n<li>Kafka Indexing Service 与 Tranquility 是官方推荐的安全的Kafka摄入数据的方式。</li>\n<li>更多使用Indexing Service起替代Realtime Node</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>我们在从Kafka，RabbitMQ，Storm 中摄入实时数据流时到Druid的时候，可以使用Realtime Node，Index Server，Tranquility进行数据摄入。</p>\n<p>本文主要探索这几种数据摄入方式的区别。</p>","more":"<h2 id=\"Realtime-Node\"><a href=\"#Realtime-Node\" class=\"headerlink\" title=\"Realtime Node\"></a>Realtime Node</h2><p>Realtime Node 可以直接配置Firehose从Kafka，RabbitMQ等消息队列中获取数据，数据一旦被摄入，很快就可以被查询到， 同时Realtime Node还会周期性的将摄入的数据合并成Segment，提交给DeepStorage并交由Historical Node加载，以达到提供实时数据的查询的功能。</p>\n<h3 id=\"Realtime-Node的局限性\"><a href=\"#Realtime-Node的局限性\" class=\"headerlink\" title=\"Realtime Node的局限性\"></a>Realtime Node的局限性</h3><p>但这种模式有一些缺陷</p>\n<h4 id=\"Kafka-摄入缺陷\"><a href=\"#Kafka-摄入缺陷\" class=\"headerlink\" title=\"Kafka 摄入缺陷\"></a>Kafka 摄入缺陷</h4><p>一旦Realtime Node宕机，那么该节点上未提交的数据将全部丢失。 </p>\n<p>正常这种时候我们需要使用创建 replica 副本以保证高可用，但在使用Kafka摄入数据的场景会有一些缺陷， 这里涉及到Segment的<a href=\"http://druid.io/docs/0.12.0/ingestion/stream-pull.html#sharding\" target=\"_blank\" rel=\"noopener\">Shard机制</a>。</p>\n<p>简单讲，在大量数据的摄入的场景，通常一个Segment会分为多个Shard分片，每一个分片会有不同的<code>partitionNum</code>分区号。当设置了副本的时候，某个分片的副本将会拥有该分片相同的分区号。在数据查询的时候，Druid在相同分区号的分片中知会随机选择一个进行数据查询数据。</p>\n<p>而举一个具体的场景，假如在你有一个Kafka的Topic有编号为1，2，3的partitions，并且你有2个实时节点去消费这个Topic，节点1消费了partitions 1与2， 节点2消费了partitions 3。他们拥有相同的Group。<br>这时候你需要进行Replication以保证高可用，所以你启动了另外2个实时节点并以新的Kafka Topic去消费数据。 这时候看节点3可能消费了partitons 1，节点4可能消费了partitions 2与3。<br>前文提到Segment partitionNum查询的特性，这时候Druid会认为节点3与4是同一个分区，所以数据查询只会从中挑选一个节点进行查询，但很明显他们数据是不一样的。</p>\n<p><img src=\"http://res.xiezefan.me/images/Druid Realtime Node defects.png\" alt=\"Druid Realtime Node缺陷\"></p>\n<h4 id=\"数据丢失风险\"><a href=\"#数据丢失风险\" class=\"headerlink\" title=\"数据丢失风险\"></a>数据丢失风险</h4><p>另外，假设你当前正在执行一个任务计算今日每个小时的数据汇总，同时你有一个批处理任务从离线集群获取数据重做Segment，并覆盖当前的Segment。<br>如果你在执行计算任务期间发生了Segment覆盖，那么在这个场景下很可能出现数据丢失。</p>\n<h4 id=\"Schema更新需重启节点\"><a href=\"#Schema更新需重启节点\" class=\"headerlink\" title=\"Schema更新需重启节点\"></a>Schema更新需重启节点</h4><p>在Schema更新的时候，你需要重启Realtime Node以生效新的配置，这在大规模集群管理上效率非常低。</p>\n<h2 id=\"Indexing-Service\"><a href=\"#Indexing-Service\" class=\"headerlink\" title=\"Indexing Service\"></a>Indexing Service</h2><p>以下是Druid官方的Indexing Service架构图</p>\n<p><img src=\"http://res.xiezefan.me/images/indexing_service.png\" alt=\"Druid Indexing Service Architecture\"></p>\n<p>Indexing Service分为以下几个部分:</p>\n<ol>\n<li>Overload : 负责接收请求，分配任务给Middle Manager执行</li>\n<li>Middle Manager :  执行提交的任务的工作者节点，会将任务分发给运行在单独的JVM的Peon</li>\n<li>Peon : 指定Task的容器</li>\n<li>Task : 在Middle Manager管理的Peon下执行的任务，支持各种各样的任务如Hadoop摄入，Kafka摄入。同时开发者可以自己定制Task以满足业务需求</li>\n<li>ZooKeeper: 维护任务的信息</li>\n</ol>\n<p>简单讲Indexing Service是一套分布式任务调度系统，按计划执行数据摄入，Segment合并，压缩，删除等任务。同时支持自定义任务扩展。</p>\n<p>甚至你可以通过扩展将Indexing Service接入Autoscaling自动伸缩服务，在任务排队过长的时候，自动创建Middle Manager节点，再节点空闲的时候，自动进行缩容。</p>\n<h3 id=\"锁机制\"><a href=\"#锁机制\" class=\"headerlink\" title=\"锁机制\"></a>锁机制</h3><p><a href=\"http://druid.io/docs/0.12.0/ingestion/tasks.html#locking\" target=\"_blank\" rel=\"noopener\">Task的锁机制</a>可以在我们进行publish segment等时候获取指定时间段的segment的排他锁或共享锁，以避免上文描述的Realtime Node Segment覆盖的时候可能产生的数据丢失风险</p>\n<h3 id=\"Kafka-Indexing-Service\"><a href=\"#Kafka-Indexing-Service\" class=\"headerlink\" title=\"Kafka Indexing Service\"></a>Kafka Indexing Service</h3><p><a href=\"http://druid.io/docs/0.12.0/development/extensions-core/kafka-ingestion.html\" target=\"_blank\" rel=\"noopener\">Kafka Indexing Service</a> 是在Indexing Service上封装的一个扩展，使用Kafka自己的分区和偏移机制来读取数据，因此能够提供准确一次的服务保证。 解决Realtime Node摄入Kafka数据的缺陷。</p>\n<p>与 Tranquility 对比的好处是，他能够读取来自Kafka的非近期的数据，并且不受窗口期(window period )对其他摄取机制的影响。支持管理索引任务的状态，以协调切换，管理故障，并确保维护可扩展性和复制要求。</p>\n<p>截止至当前Druid 0.11.0 Kafka Indexing server还未完全Release，需要谨慎在生产上使用。</p>\n<h2 id=\"Tranquility\"><a href=\"#Tranquility\" class=\"headerlink\" title=\"Tranquility\"></a>Tranquility</h2><p>Tranquility 是在 Index Service 封装的一个类库，帮助我们从Kafka，Hadoop，HTTP，Storm，Samza，Spark Streaming或者自己的JVM程序发送数据给Indexing Service。</p>\n<h3 id=\"Tranquility-实现原理\"><a href=\"#Tranquility-实现原理\" class=\"headerlink\" title=\"Tranquility 实现原理\"></a>Tranquility 实现原理</h3><p>Tranquility 帮助我们解决Indexing Service在Partitioning分区， Replication副本，Service Discover服务发现，Schema rollover Schema平滑变更上的一些难题。</p>\n<p>Tranquility基于Indexing Service的EventReceiverFirehose来实现，该Firehose会暴露一个HTTP API供Tranquility实时Push数据给Indexing Service。</p>\n<p>在解决分区与副本问题上，Tranquility会给每一个Segment+ partitionNum指派一个Task来进行数据摄入，在超过Window Period后，Task将会停止接收数据并合并Segment，然后提交到Deep Storage。</p>\n<p>而副本的实现上，Tranquility将每个副本创建不同Task，相同的Segment与partitionNum，相同Segment与partitionNum的数据将会同事发给相同的副本的Task，副本的Task之间乎不通讯。</p>\n<p>当Schema发生改变的时候，在Indexing Service必须重启任务才生效。 而Tranquility的做法是只会应用到新的时间段生成的Segment，旧的Segment讲保持不变。由此时间不停机修改Schema。</p>\n<p>最后，我们通常需要启动实例进行数据处理并发送给Druid，Tranquility使用Zookeeper管理不同实例的任务协调，保证数据被正确想到相应的Task中。</p>\n<h3 id=\"Tranquility的缺陷\"><a href=\"#Tranquility的缺陷\" class=\"headerlink\" title=\"Tranquility的缺陷\"></a>Tranquility的缺陷</h3><ol>\n<li>超过Window Period的数据将会被丢弃，必须定时从离线集群中重做Segment来实现数据互补。</li>\n<li>Tranquility与Indexing Service的通讯异常会导致重试，无论是重试成功或失败，都可能导致数据丢失或者重复数据</li>\n</ol>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ol>\n<li>Kafka Indexing Service 与 Tranquility 是官方推荐的安全的Kafka摄入数据的方式。</li>\n<li>更多使用Indexing Service起替代Realtime Node</li>\n</ol>"}],"PostAsset":[],"PostCategory":[{"post_id":"cjn5dk4430000l9398i90y5kz","category_id":"cjn5dk44a0002l939wusdwq2s","_id":"cjn5dk44i000dl939wkt9es0m"},{"post_id":"cjn5dk4480001l939lzgva60p","category_id":"cjn5dk44a0002l939wusdwq2s","_id":"cjn5dk44l000jl939m5aes4s9"},{"post_id":"cjn5dk44g000bl939s9blb3oj","category_id":"cjn5dk44a0002l939wusdwq2s","_id":"cjn5dk44m000ol939sh1w3o0b"},{"post_id":"cjn5dk44i000gl93906kdubvl","category_id":"cjn5dk44a0002l939wusdwq2s","_id":"cjn5dk44n000rl93907g8oazx"},{"post_id":"cjn5dk44b0004l939kyyr2a32","category_id":"cjn5dk44i000cl9391jtnbkeg","_id":"cjn5dk44o000wl939cljyjdl0"},{"post_id":"cjn5dk44j000il939hq2qp727","category_id":"cjn5dk44a0002l939wusdwq2s","_id":"cjn5dk44p000zl939rzip5a6f"},{"post_id":"cjn5dk44c0005l9394xox6043","category_id":"cjn5dk44l000kl93954pjgumq","_id":"cjn5dk44q0013l939ncuafvc8"},{"post_id":"cjn5dk44m000ql9394z1uaniy","category_id":"cjn5dk44a0002l939wusdwq2s","_id":"cjn5dk44r0015l939rf1ctfs1"},{"post_id":"cjn5dk44d0006l939drfbjx0a","category_id":"cjn5dk44n000sl939fj0ey1dp","_id":"cjn5dk44s0018l939co7ah1ox"},{"post_id":"cjn5dk44f000al939agknp4gv","category_id":"cjn5dk44n000sl939fj0ey1dp","_id":"cjn5dk44t001cl939f5fsj1j3"},{"post_id":"cjn5dk44l000nl93921r9eacx","category_id":"cjn5dk44r0016l939wg8md1nd","_id":"cjn5dk44w001jl939j75fo4mg"},{"post_id":"cjn5dk44t001el9394osacpph","category_id":"cjn5dk44a0002l939wusdwq2s","_id":"cjn5dk44x001ol9394p7hobbe"},{"post_id":"cjn5dk44u001hl939ju1nkkdf","category_id":"cjn5dk44a0002l939wusdwq2s","_id":"cjn5dk44y001ql939av1i9juu"},{"post_id":"cjn5dk44o000vl939zvmwtaem","category_id":"cjn5dk44u001fl9390c55rlcd","_id":"cjn5dk44y001ul9391r1fbxq8"},{"post_id":"cjn5dk44o000yl9399devyki9","category_id":"cjn5dk44x001ll939r8fw2v7a","_id":"cjn5dk44y001vl939ke3emom0"},{"post_id":"cjn5dk44q0012l939ec2yolbz","category_id":"cjn5dk44y001sl939bidmy4kw","_id":"cjn5dk44z001yl939tetclm2k"},{"post_id":"cjn5dk44r0014l939bldcc3b9","category_id":"cjn5dk44z001xl939mf7y6fsx","_id":"cjn5dk4500024l939csvbl4t3"},{"post_id":"cjn5dk44r0017l9394gnhfk4d","category_id":"cjn5dk44z0020l939n8fjd4no","_id":"cjn5dk4500029l9399eupfwdm"},{"post_id":"cjn5dk44t001bl939ki1gmbqc","category_id":"cjn5dk4500025l939ieiqnv4k","_id":"cjn5dk451002cl939amu0i3hr"},{"post_id":"cjn5dk44v001il939y1luwgoi","category_id":"cjn5dk450002al939jiy9rquc","_id":"cjn5dk452002hl9393thc3b2a"},{"post_id":"cjn5dk44x001nl939exb55zn2","category_id":"cjn5dk450002al939jiy9rquc","_id":"cjn5dk452002jl939wt3ignzi"},{"post_id":"cjn5dk4590031l9394vcambyp","category_id":"cjn5dk450002al939jiy9rquc","_id":"cjn5dk45c0036l939mw9uqaau"},{"post_id":"cjn5dk45a0032l939seupkeeq","category_id":"cjn5dk4500025l939ieiqnv4k","_id":"cjn5dk45d0039l939uf589z8c"},{"post_id":"cjn5dk45b0034l939lgbetfb9","category_id":"cjn5dk45d0037l939xcbeati3","_id":"cjn5dk45e003cl93984zydk9u"},{"post_id":"cjsiwethy0000su395kr2su00","category_id":"cjsiweti50001su39luukrzy4","_id":"cjsiwetii0004su39ygldetsa"}],"PostTag":[{"post_id":"cjn5dk4430000l9398i90y5kz","tag_id":"cjn5dk44b0003l9391rtd22me","_id":"cjn5dk44f0009l939atcqovwe"},{"post_id":"cjn5dk4480001l939lzgva60p","tag_id":"cjn5dk44b0003l9391rtd22me","_id":"cjn5dk44i000fl939thmumyfp"},{"post_id":"cjn5dk44g000bl939s9blb3oj","tag_id":"cjn5dk44b0003l9391rtd22me","_id":"cjn5dk44j000hl939ove7qsrd"},{"post_id":"cjn5dk44i000gl93906kdubvl","tag_id":"cjn5dk44b0003l9391rtd22me","_id":"cjn5dk44l000ml939gmminnl3"},{"post_id":"cjn5dk44b0004l939kyyr2a32","tag_id":"cjn5dk44i000el939o3ekc9ge","_id":"cjn5dk44m000pl939ynaq049a"},{"post_id":"cjn5dk44j000il939hq2qp727","tag_id":"cjn5dk44b0003l9391rtd22me","_id":"cjn5dk44n000ul9394sn6ozjr"},{"post_id":"cjn5dk44c0005l9394xox6043","tag_id":"cjn5dk44l000ll939eofettjs","_id":"cjn5dk44o000xl939gx7fzvp8"},{"post_id":"cjn5dk44d0006l939drfbjx0a","tag_id":"cjn5dk44n000tl939el4w884w","_id":"cjn5dk44s001al939opu6aglm"},{"post_id":"cjn5dk44d0006l939drfbjx0a","tag_id":"cjn5dk44p0011l9397phvo6ou","_id":"cjn5dk44t001dl93950t8o955"},{"post_id":"cjn5dk44u001hl939ju1nkkdf","tag_id":"cjn5dk44b0003l9391rtd22me","_id":"cjn5dk44x001ml939cjh4q4ep"},{"post_id":"cjn5dk44f000al939agknp4gv","tag_id":"cjn5dk44n000tl939el4w884w","_id":"cjn5dk44y001pl9398qdkiggi"},{"post_id":"cjn5dk44f000al939agknp4gv","tag_id":"cjn5dk44p0011l9397phvo6ou","_id":"cjn5dk44y001tl9397qm93vov"},{"post_id":"cjn5dk44l000nl93921r9eacx","tag_id":"cjn5dk44w001kl9396c769poe","_id":"cjn5dk44z0021l939fbgcoj19"},{"post_id":"cjn5dk44l000nl93921r9eacx","tag_id":"cjn5dk44y001rl939zxde98ee","_id":"cjn5dk4500022l939kgpo40le"},{"post_id":"cjn5dk44l000nl93921r9eacx","tag_id":"cjn5dk44z001wl939eqltgqpa","_id":"cjn5dk4500026l939hcf9gcio"},{"post_id":"cjn5dk44m000ql9394z1uaniy","tag_id":"cjn5dk44y001rl939zxde98ee","_id":"cjn5dk4500027l939d55ehd17"},{"post_id":"cjn5dk44o000vl939zvmwtaem","tag_id":"cjn5dk44y001rl939zxde98ee","_id":"cjn5dk451002el9394p2l8v2h"},{"post_id":"cjn5dk44o000vl939zvmwtaem","tag_id":"cjn5dk4500028l939qc0phw1s","_id":"cjn5dk451002fl939w4u1aiim"},{"post_id":"cjn5dk44o000yl9399devyki9","tag_id":"cjn5dk451002bl9393jm8hqnj","_id":"cjn5dk452002kl939w2uuxned"},{"post_id":"cjn5dk44o000yl9399devyki9","tag_id":"cjn5dk451002gl939euopthgh","_id":"cjn5dk452002ll9393ll1k5g9"},{"post_id":"cjn5dk44q0012l939ec2yolbz","tag_id":"cjn5dk452002il939iurbzxjw","_id":"cjn5dk452002ol939zichh4kg"},{"post_id":"cjn5dk44q0012l939ec2yolbz","tag_id":"cjn5dk452002ml939m9java8h","_id":"cjn5dk453002pl939i51ryvf3"},{"post_id":"cjn5dk44r0014l939bldcc3b9","tag_id":"cjn5dk452002nl939xzeuzvfc","_id":"cjn5dk453002rl939v6nezeoa"},{"post_id":"cjn5dk44r0017l9394gnhfk4d","tag_id":"cjn5dk453002ql939aq1y99rc","_id":"cjn5dk453002tl93927o7o6sf"},{"post_id":"cjn5dk44t001bl939ki1gmbqc","tag_id":"cjn5dk453002sl939ujqprard","_id":"cjn5dk453002vl939xe1v2lam"},{"post_id":"cjn5dk44t001el9394osacpph","tag_id":"cjn5dk453002ul939j4zpjslf","_id":"cjn5dk454002xl939rufuxl94"},{"post_id":"cjn5dk44v001il939y1luwgoi","tag_id":"cjn5dk44w001kl9396c769poe","_id":"cjn5dk454002zl939zf62p6yn"},{"post_id":"cjn5dk44x001nl939exb55zn2","tag_id":"cjn5dk454002yl939vtdm1mt6","_id":"cjn5dk4540030l93903uu2l70"},{"post_id":"cjn5dk4590031l9394vcambyp","tag_id":"cjn5dk4500028l939qc0phw1s","_id":"cjn5dk45b0033l939sejmbpc6"},{"post_id":"cjn5dk45a0032l939seupkeeq","tag_id":"cjn5dk453002sl939ujqprard","_id":"cjn5dk45c0035l939s31xfwpt"},{"post_id":"cjn5dk45b0034l939lgbetfb9","tag_id":"cjn5dk453002sl939ujqprard","_id":"cjn5dk45e003al939291ojqv3"},{"post_id":"cjn5dk45b0034l939lgbetfb9","tag_id":"cjn5dk45d0038l939c9xnfbda","_id":"cjn5dk45e003bl939fwpo0eye"},{"post_id":"cjsiwethy0000su395kr2su00","tag_id":"cjsiwetie0002su392cyjl2ac","_id":"cjsiwetig0003su39h7oo13ye"}],"Tag":[{"name":"java","_id":"cjn5dk44b0003l9391rtd22me"},{"name":"agenda","_id":"cjn5dk44i000el939o3ekc9ge"},{"name":"android","_id":"cjn5dk44l000ll939eofettjs"},{"name":"elk","_id":"cjn5dk44n000tl939el4w884w"},{"name":"gork","_id":"cjn5dk44p0011l9397phvo6ou"},{"name":"linux","_id":"cjn5dk44w001kl9396c769poe"},{"name":"maven","_id":"cjn5dk44y001rl939zxde98ee"},{"name":"jdk","_id":"cjn5dk44z001wl939eqltgqpa"},{"name":"git","_id":"cjn5dk4500028l939qc0phw1s"},{"name":"mqtt","_id":"cjn5dk451002bl9393jm8hqnj"},{"name":"im","_id":"cjn5dk451002gl939euopthgh"},{"name":"nginx","_id":"cjn5dk452002il939iurbzxjw"},{"name":"keepalive","_id":"cjn5dk452002ml939m9java8h"},{"name":"tools","_id":"cjn5dk452002nl939xzeuzvfc"},{"name":"mysql","_id":"cjn5dk453002ql939aq1y99rc"},{"name":"redis","_id":"cjn5dk453002sl939ujqprard"},{"name":"spring-test","_id":"cjn5dk453002ul939j4zpjslf"},{"name":"sublime-text","_id":"cjn5dk454002yl939vtdm1mt6"},{"name":"ziplist","_id":"cjn5dk45d0038l939c9xnfbda"},{"name":"druid","_id":"cjsiwetie0002su392cyjl2ac"}]}}